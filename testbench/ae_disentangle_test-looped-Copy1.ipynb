{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baed00ee-9461-4560-8813-31a571c86877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 09:40:15.911950: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import setigen as stg\n",
    "from blimpy import Waterfall\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from astropy import units as u\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import silhouette_score\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f020ec-5663-42ab-8527-2b5d37948ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e00c928-f039-4774-8477-10c9e940e2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def painting(data):\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    for c in range(num_classes):\n",
    "        drift = 2*random.random()*(-1)**random.randint(0,2)\n",
    "        snr = random.randint(100, 150)\n",
    "        width = random.randint(20, 50)\n",
    "        for s in range(num_samples_per_class):\n",
    "            index = random.randint(0, data.shape[0]-1)\n",
    "            window = data[index, :,:]\n",
    "            \n",
    "            start = random.randint(50, 180)\n",
    "            \n",
    "            frame = stg.Frame.from_data(df=2.7939677238464355*u.Hz,\n",
    "                                        dt=18.253611008*u.s,\n",
    "                                        fch1=1289*u.MHz,\n",
    "                                        ascending=True,\n",
    "                                        data=window)\n",
    "            frame.add_signal(stg.constant_path(\n",
    "                                        f_start=frame.get_frequency(index=start),\n",
    "                                       drift_rate=drift*u.Hz/u.s),\n",
    "                                      stg.constant_t_profile(level=frame.get_intensity(snr=snr)),\n",
    "                                      stg.gaussian_f_profile(width=width*u.Hz),\n",
    "                                      stg.constant_bp_profile(level=1))\n",
    "            all_data.append(frame.data)\n",
    "            labels.append(c)\n",
    "    all_data = np.array(all_data)\n",
    "    labels = np.vstack(labels)\n",
    "    return all_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e49e4f-15bd-4a32-a6d5-7a3274be3b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from AE import AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531b40be-4015-40db-926c-0e681083194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 09:40:18.090826: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 09:40:18.494644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13888 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16, 256, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 256, 3)        30        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 128, 3)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 128, 3)       12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 128, 64)       1792      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 64, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 8, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 8, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2097408   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " latent (Dense)              (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,229,428\n",
      "Trainable params: 2,228,270\n",
      "Non-trainable params: 1,158\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "time_samples = 16\n",
    "freq_sample =  256\n",
    "encoder_inputs = keras.Input(shape=(time_samples, freq_sample, 1))\n",
    "x = layers.Conv2D(3, 3, activation=\"relu\", strides=1, padding=\"same\")(encoder_inputs)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x_shape = x.shape\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "z = layers.Dense(latent_dim, name=\"latent\", activation=\"linear\")(x)\n",
    "encoder = keras.Model(encoder_inputs, z, name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7131cf6f-ba9a-43ea-8b45-d3f79bd5acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                704       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8192)              2105344   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 8192)             32768     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 8, 64)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 16, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 64)       36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 16, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 64, 64)       36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 16, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 16, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 32, 128, 64)      36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 128, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 16, 128, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 32, 256, 3)       1731      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 16, 256, 3)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 16, 256, 3)       12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 16, 256, 1)       28        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,306,987\n",
      "Trainable params: 2,289,573\n",
      "Non-trainable params: 17,414\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(x_shape[1]* x_shape[2]* x_shape[3], activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Reshape((x_shape[1], x_shape[2], x_shape[3]))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(3, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"linear\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58ade6b-b495-49c2-b248-63bfadd8ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = 8\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"kl_loss\"\n",
    "        )\n",
    "        self.kl_additional = tf.keras.losses.KLDivergence()\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "        ]\n",
    "    def gaussanity_loss(self, data, base):\n",
    "        return self.kl_additional(data, base)\n",
    "    \n",
    "    def train_step(self, data_in):\n",
    "        data = data_in\n",
    "        print(data.shape)\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            \n",
    "            \n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        \n",
    "        mse_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(mse_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "        }\n",
    "    def test_step(self, data_in):\n",
    "        data, _ = data_in\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss \n",
    "        \n",
    "        mse_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(mse_loss)\n",
    "        return {\n",
    "            \"test_loss\": self.total_loss_tracker.result(),\n",
    "            \"test_kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"test_reconstruction_loss\": self.reconstruction_loss_tracker.result()\n",
    "        }\n",
    "    def __call__ (self, inputs):\n",
    "        return self.decoder(self.encoder(inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0074643-eba7-4961-aa51-3916eb75c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7ff624537df0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = VAE(encoder, decoder)\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3))\n",
    "autoencoder.load_weights(\"../autoencoder/models/full-weights-\"+'07-02-2023-11-08-47')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df2f403c-1e31-45be-9f8b-44277bc1bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    epsilon = 1\n",
    "    min_val = data.min()\n",
    "    data = data - min_val + epsilon\n",
    "    new_data = np.log(data)\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    final_data = (data - min_val) / (max_val - min_val)\n",
    "    return final_data\n",
    "    \n",
    "def normalize_data(data):\n",
    "    for i in tqdm(range(data.shape[0])):\n",
    "        data[i,:,:] = normalize(data[i,:,:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "218b0964-8671-484c-b24f-e9081b651743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def idealized(num=10_000):\n",
    "    drift = drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "    snr = 50*random.random() +20\n",
    "    width = 50*random.random() +20\n",
    "    start = random.randint(50, 180)\n",
    "    data = []\n",
    "    labels = []\n",
    "    for tag in range(4):\n",
    "        label_vec = np.zeros(4)\n",
    "        label_vec[tag] = 1\n",
    "        for i in range(num):\n",
    "            if tag == 0:\n",
    "#             everything but drif\n",
    "                snr = 50*random.random() +20\n",
    "                width = 50*random.random() +20\n",
    "                start = random.randint(50, 180)\n",
    "            elif tag == 1:\n",
    "#             everything but snr\n",
    "                drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "                width = 50*random.random() +20\n",
    "                start = random.randint(50, 180)\n",
    "            elif tag == 2:\n",
    "#             everything but width\n",
    "                drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "                snr = 50*random.random() +20\n",
    "                start = random.randint(50, 180)\n",
    "            elif tag == 3:\n",
    "#             everything but start\n",
    "                drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "                snr = 50*random.random() +20\n",
    "                width = 50*random.random() +20\n",
    "\n",
    "            frame = stg.Frame(fchans=256*u.pixel,\n",
    "                              tchans=16*u.pixel,\n",
    "                              df=2.7939677238464355*u.Hz,\n",
    "                              dt=18.253611008*u.s,\n",
    "                              fch1=6095.214842353016*u.MHz)\n",
    "            noise = frame.add_noise(x_mean=1, noise_type='chi2')\n",
    "            frame.add_signal(stg.constant_path(\n",
    "                                        f_start=frame.get_frequency(index=start),\n",
    "                                       drift_rate=drift*u.Hz/u.s),\n",
    "                                      stg.constant_t_profile(level=frame.get_intensity(snr=snr)),\n",
    "                                      stg.gaussian_f_profile(width=width*u.Hz),\n",
    "                                      stg.constant_bp_profile(level=1))\n",
    "            data.append(frame.data)\n",
    "            labels.append(label_vec)\n",
    "    data = np.array(data)\n",
    "    labels = np.vstack(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "840a6870-c527-4ab5-9bc4-ff56ca7e8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_diff(X, labels):\n",
    "    new_x = []\n",
    "    new_labels = []\n",
    "    one = np.arange(0,10000)\n",
    "    two = np.arange(10000,20000)\n",
    "    three = np.arange(20000,30000)\n",
    "    four = np.arange(30000,40000)\n",
    "    for i in range(X.shape[0] -1):\n",
    "        if np.argmax(labels[i,:]) == np.argmax(labels[i+1,:]): \n",
    "            index = np.argmax(labels[i,:])\n",
    "            if index == 0:\n",
    "                sample = np.random.choice(one, size = 1000)\n",
    "            elif index == 1:\n",
    "                sample = np.random.choice(two, size = 1000)\n",
    "            elif index == 2:\n",
    "                sample = np.random.choice(three, size = 1000)\n",
    "            elif index == 3:\n",
    "                sample = np.random.choice(four, size = 1000)\n",
    "            diff = abs(X[i,:] - X[sample,:])\n",
    "            diff = np.mean(diff, axis = 0)\n",
    "            new_x.append(diff)\n",
    "            new_labels.append(labels[i,:])\n",
    "            \n",
    "    return np.array(new_x), np.vstack(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9549969-98f3-4658-a0f7-ff09b604ff4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/10 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1173/40000 [00:00<00:03, 11718.05it/s]\u001b[A\n",
      "  6%|████▌                                                                        | 2345/40000 [00:00<00:03, 11151.33it/s]\u001b[A\n",
      "  9%|██████▋                                                                      | 3462/40000 [00:00<00:03, 10923.66it/s]\u001b[A\n",
      " 11%|████████▊                                                                    | 4556/40000 [00:00<00:03, 10825.95it/s]\u001b[A\n",
      " 14%|██████████▊                                                                  | 5640/40000 [00:00<00:03, 10770.56it/s]\u001b[A\n",
      " 17%|████████████▉                                                                | 6718/40000 [00:00<00:03, 10733.93it/s]\u001b[A\n",
      " 19%|██████████████▉                                                              | 7792/40000 [00:00<00:03, 10696.51it/s]\u001b[A\n",
      " 22%|█████████████████                                                            | 8862/40000 [00:00<00:02, 10685.29it/s]\u001b[A\n",
      " 25%|███████████████████                                                          | 9931/40000 [00:00<00:02, 10539.48it/s]\u001b[A\n",
      " 27%|████████████████████▉                                                       | 10995/40000 [00:01<00:02, 10567.68it/s]\u001b[A\n",
      " 30%|██████████████████████▉                                                     | 12060/40000 [00:01<00:02, 10590.33it/s]\u001b[A\n",
      " 33%|████████████████████████▉                                                   | 13120/40000 [00:01<00:02, 10469.97it/s]\u001b[A\n",
      " 35%|██████████████████████████▉                                                 | 14187/40000 [00:01<00:02, 10529.20it/s]\u001b[A\n",
      " 38%|████████████████████████████▉                                               | 15251/40000 [00:01<00:02, 10560.29it/s]\u001b[A\n",
      " 41%|███████████████████████████████                                             | 16318/40000 [00:01<00:02, 10591.62it/s]\u001b[A\n",
      " 43%|█████████████████████████████████                                           | 17386/40000 [00:01<00:02, 10615.57it/s]\u001b[A\n",
      " 46%|███████████████████████████████████                                         | 18450/40000 [00:01<00:02, 10621.66it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████                                       | 19519/40000 [00:01<00:01, 10641.41it/s]\u001b[A\n",
      " 51%|███████████████████████████████████████                                     | 20588/40000 [00:01<00:01, 10655.90it/s]\u001b[A\n",
      " 54%|█████████████████████████████████████████▏                                  | 21654/40000 [00:02<00:01, 10452.69it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████▏                                | 22721/40000 [00:02<00:01, 10516.11it/s]\u001b[A\n",
      " 59%|█████████████████████████████████████████████▏                              | 23797/40000 [00:02<00:01, 10586.46it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▎                            | 24870/40000 [00:02<00:01, 10627.82it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▎                          | 25941/40000 [00:02<00:01, 10650.45it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▎                        | 27007/40000 [00:02<00:01, 10499.79it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████▎                      | 28074/40000 [00:02<00:01, 10547.79it/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████▎                    | 29130/40000 [00:02<00:01, 10297.07it/s]\u001b[A\n",
      " 76%|█████████████████████████████████████████████████████████▍                  | 30255/40000 [00:02<00:00, 10575.38it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████▌                | 31350/40000 [00:02<00:00, 10684.72it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▋              | 32446/40000 [00:03<00:00, 10763.57it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▉            | 33624/40000 [00:03<00:00, 11064.86it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▉          | 34732/40000 [00:03<00:00, 11064.90it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████        | 35840/40000 [00:03<00:00, 11025.91it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████▏     | 36944/40000 [00:03<00:00, 10998.86it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████▎   | 38047/40000 [00:03<00:00, 11007.68it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 10724.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 09:40:57.986044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2023-08-24 09:41:00.189214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 10)\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 09:41:05.201995: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7ff4d401fb50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-24 09:41:05.202086: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2023-08-24 09:41:05.209653: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-24 09:41:05.397801: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 3ms/step - loss: 39.0078 - accuracy: 0.3269 - val_loss: 14.0372 - val_accuracy: 0.2664\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 9.9232 - accuracy: 0.2675 - val_loss: 8.5379 - val_accuracy: 0.2828\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 7.0191 - accuracy: 0.3117 - val_loss: 5.8610 - val_accuracy: 0.3507\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.8924 - accuracy: 0.3956 - val_loss: 4.1338 - val_accuracy: 0.4672\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.6980 - accuracy: 0.4782 - val_loss: 3.2961 - val_accuracy: 0.5131\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.0609 - accuracy: 0.5140 - val_loss: 2.7973 - val_accuracy: 0.5399\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.6139 - accuracy: 0.5321 - val_loss: 2.4308 - val_accuracy: 0.5590\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.2515 - accuracy: 0.5466 - val_loss: 2.1172 - val_accuracy: 0.5705\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.9463 - accuracy: 0.5597 - val_loss: 1.8410 - val_accuracy: 0.5847\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.6972 - accuracy: 0.5793 - val_loss: 1.6010 - val_accuracy: 0.5854\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.5054 - accuracy: 0.6020 - val_loss: 1.4329 - val_accuracy: 0.5955\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.3620 - accuracy: 0.6215 - val_loss: 1.3142 - val_accuracy: 0.6451\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.2461 - accuracy: 0.6436 - val_loss: 1.1983 - val_accuracy: 0.6474\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.1501 - accuracy: 0.6564 - val_loss: 1.1061 - val_accuracy: 0.6418\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.0689 - accuracy: 0.6644 - val_loss: 1.0177 - val_accuracy: 0.6728\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9985 - accuracy: 0.6766 - val_loss: 0.9491 - val_accuracy: 0.6757\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9441 - accuracy: 0.6876 - val_loss: 0.9081 - val_accuracy: 0.6739\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9016 - accuracy: 0.6926 - val_loss: 0.8680 - val_accuracy: 0.7007\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8732 - accuracy: 0.6969 - val_loss: 0.8410 - val_accuracy: 0.7019\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8542 - accuracy: 0.7005 - val_loss: 0.8278 - val_accuracy: 0.6862\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8386 - accuracy: 0.7062 - val_loss: 0.7992 - val_accuracy: 0.7209\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8261 - accuracy: 0.7100 - val_loss: 0.7922 - val_accuracy: 0.7116\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8187 - accuracy: 0.7119 - val_loss: 0.7784 - val_accuracy: 0.7280\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8086 - accuracy: 0.7159 - val_loss: 0.7697 - val_accuracy: 0.7291\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8002 - accuracy: 0.7214 - val_loss: 0.7610 - val_accuracy: 0.7351\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7944 - accuracy: 0.7198 - val_loss: 0.7715 - val_accuracy: 0.7313\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7909 - accuracy: 0.7199 - val_loss: 0.7611 - val_accuracy: 0.7317\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7822 - accuracy: 0.7264 - val_loss: 0.7456 - val_accuracy: 0.7410\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7787 - accuracy: 0.7248 - val_loss: 0.7481 - val_accuracy: 0.7377\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7797 - accuracy: 0.7265 - val_loss: 0.7370 - val_accuracy: 0.7444\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7715 - accuracy: 0.7289 - val_loss: 0.7367 - val_accuracy: 0.7440\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7679 - accuracy: 0.7292 - val_loss: 0.7399 - val_accuracy: 0.7410\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7616 - accuracy: 0.7338 - val_loss: 0.7255 - val_accuracy: 0.7515\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7607 - accuracy: 0.7318 - val_loss: 0.7292 - val_accuracy: 0.7507\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7602 - accuracy: 0.7325 - val_loss: 0.7212 - val_accuracy: 0.7500\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7531 - accuracy: 0.7339 - val_loss: 0.7155 - val_accuracy: 0.7507\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7499 - accuracy: 0.7365 - val_loss: 0.7272 - val_accuracy: 0.7466\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7461 - accuracy: 0.7366 - val_loss: 0.7146 - val_accuracy: 0.7526\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7443 - accuracy: 0.7384 - val_loss: 0.7125 - val_accuracy: 0.7474\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7410 - accuracy: 0.7391 - val_loss: 0.7263 - val_accuracy: 0.7250\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7416 - accuracy: 0.7363 - val_loss: 0.7042 - val_accuracy: 0.7530\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7359 - accuracy: 0.7368 - val_loss: 0.7089 - val_accuracy: 0.7511\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7338 - accuracy: 0.7396 - val_loss: 0.7035 - val_accuracy: 0.7586\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7313 - accuracy: 0.7398 - val_loss: 0.6943 - val_accuracy: 0.7586\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7304 - accuracy: 0.7406 - val_loss: 0.6946 - val_accuracy: 0.7507\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7265 - accuracy: 0.7405 - val_loss: 0.6893 - val_accuracy: 0.7575\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7249 - accuracy: 0.7400 - val_loss: 0.6877 - val_accuracy: 0.7593\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7220 - accuracy: 0.7427 - val_loss: 0.6899 - val_accuracy: 0.7675\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7186 - accuracy: 0.7442 - val_loss: 0.6892 - val_accuracy: 0.7563\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.7404 - val_loss: 0.7032 - val_accuracy: 0.7552\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7171 - accuracy: 0.7435 - val_loss: 0.6903 - val_accuracy: 0.7328\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7120 - accuracy: 0.7433 - val_loss: 0.6797 - val_accuracy: 0.7646\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.7439 - val_loss: 0.6894 - val_accuracy: 0.7481\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.7451 - val_loss: 0.6815 - val_accuracy: 0.7418\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7103 - accuracy: 0.7425 - val_loss: 0.6721 - val_accuracy: 0.7649\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.7447 - val_loss: 0.6833 - val_accuracy: 0.7541\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.7452 - val_loss: 0.6688 - val_accuracy: 0.7713\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.7477 - val_loss: 0.6701 - val_accuracy: 0.7664\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.7423 - val_loss: 0.6814 - val_accuracy: 0.7325\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.7482 - val_loss: 0.6656 - val_accuracy: 0.7698\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.7443 - val_loss: 0.6636 - val_accuracy: 0.7739\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.7476 - val_loss: 0.6626 - val_accuracy: 0.7646\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.7507 - val_loss: 0.6795 - val_accuracy: 0.7646\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.7475 - val_loss: 0.6705 - val_accuracy: 0.7593\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.7448 - val_loss: 0.6606 - val_accuracy: 0.7705\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.7503 - val_loss: 0.6624 - val_accuracy: 0.7720\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.7484 - val_loss: 0.6667 - val_accuracy: 0.7384\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.7459 - val_loss: 0.6632 - val_accuracy: 0.7701\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.7491 - val_loss: 0.6533 - val_accuracy: 0.7690\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.7480 - val_loss: 0.6539 - val_accuracy: 0.7720\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.7474 - val_loss: 0.6497 - val_accuracy: 0.7668\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.7479 - val_loss: 0.6658 - val_accuracy: 0.7321\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.7506 - val_loss: 0.6495 - val_accuracy: 0.7761\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.7476 - val_loss: 0.6486 - val_accuracy: 0.7765\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.7508 - val_loss: 0.6475 - val_accuracy: 0.7724\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.7525 - val_loss: 0.6514 - val_accuracy: 0.7690\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.7513 - val_loss: 0.6561 - val_accuracy: 0.7575\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.7530 - val_loss: 0.6530 - val_accuracy: 0.7660\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.7508 - val_loss: 0.6455 - val_accuracy: 0.7750\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.7513 - val_loss: 0.6503 - val_accuracy: 0.7481\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.7509 - val_loss: 0.6691 - val_accuracy: 0.7526\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.7516 - val_loss: 0.6421 - val_accuracy: 0.7657\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.7515 - val_loss: 0.6407 - val_accuracy: 0.7799\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.7522 - val_loss: 0.6525 - val_accuracy: 0.7746\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.7489 - val_loss: 0.6517 - val_accuracy: 0.7757\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.7498 - val_loss: 0.6377 - val_accuracy: 0.7757\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.7528 - val_loss: 0.6539 - val_accuracy: 0.7440\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.7535 - val_loss: 0.6391 - val_accuracy: 0.7687\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.7532 - val_loss: 0.6380 - val_accuracy: 0.7552\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.7531 - val_loss: 0.6382 - val_accuracy: 0.7739\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.7538 - val_loss: 0.6346 - val_accuracy: 0.7668\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.7518 - val_loss: 0.6347 - val_accuracy: 0.7660\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.7516 - val_loss: 0.6433 - val_accuracy: 0.7728\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.7569 - val_loss: 0.6486 - val_accuracy: 0.7597\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.7524 - val_loss: 0.6319 - val_accuracy: 0.7694\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.7533 - val_loss: 0.6313 - val_accuracy: 0.7780\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.7538 - val_loss: 0.6301 - val_accuracy: 0.7705\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.7530 - val_loss: 0.6292 - val_accuracy: 0.7787\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.7498 - val_loss: 0.6300 - val_accuracy: 0.7724\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.7545 - val_loss: 0.6303 - val_accuracy: 0.7701\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.7537 - val_loss: 0.6329 - val_accuracy: 0.7545\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.7546 - val_loss: 0.6324 - val_accuracy: 0.7754\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.7566 - val_loss: 0.6279 - val_accuracy: 0.7731\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.7523 - val_loss: 0.6291 - val_accuracy: 0.7683\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.7548 - val_loss: 0.6257 - val_accuracy: 0.7769\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.7537 - val_loss: 0.6281 - val_accuracy: 0.7784\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.7552 - val_loss: 0.6350 - val_accuracy: 0.7403\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.7538 - val_loss: 0.6304 - val_accuracy: 0.7657\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.7558 - val_loss: 0.6235 - val_accuracy: 0.7735\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.7541 - val_loss: 0.6237 - val_accuracy: 0.7724\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.7520 - val_loss: 0.6306 - val_accuracy: 0.7765\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.7577 - val_loss: 0.6346 - val_accuracy: 0.7634\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.7546 - val_loss: 0.6276 - val_accuracy: 0.7563\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.7529 - val_loss: 0.6308 - val_accuracy: 0.7743\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.7552 - val_loss: 0.6327 - val_accuracy: 0.7750\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.7537 - val_loss: 0.6228 - val_accuracy: 0.7791\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.7557 - val_loss: 0.6239 - val_accuracy: 0.7743\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.7542 - val_loss: 0.6424 - val_accuracy: 0.7705\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.7547 - val_loss: 0.6287 - val_accuracy: 0.7746\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.7561 - val_loss: 0.6328 - val_accuracy: 0.7780\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.7550 - val_loss: 0.6231 - val_accuracy: 0.7642\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.7547 - val_loss: 0.6279 - val_accuracy: 0.7713\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.7563 - val_loss: 0.6177 - val_accuracy: 0.7709\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.7573 - val_loss: 0.6255 - val_accuracy: 0.7776\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.7555 - val_loss: 0.6194 - val_accuracy: 0.7769\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.7575 - val_loss: 0.6281 - val_accuracy: 0.7761\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.7554 - val_loss: 0.6234 - val_accuracy: 0.7813\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.7571 - val_loss: 0.6173 - val_accuracy: 0.7705\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.7556 - val_loss: 0.6198 - val_accuracy: 0.7731\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.7534 - val_loss: 0.6170 - val_accuracy: 0.7769\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.7555 - val_loss: 0.6169 - val_accuracy: 0.7679\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.7563 - val_loss: 0.6161 - val_accuracy: 0.7649\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.7574 - val_loss: 0.6281 - val_accuracy: 0.7459\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.7556 - val_loss: 0.6153 - val_accuracy: 0.7769\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.7569 - val_loss: 0.6164 - val_accuracy: 0.7739\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.7549 - val_loss: 0.6154 - val_accuracy: 0.7765\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.7568 - val_loss: 0.6157 - val_accuracy: 0.7713\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.7561 - val_loss: 0.6143 - val_accuracy: 0.7769\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.7582 - val_loss: 0.6141 - val_accuracy: 0.7735\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.7578 - val_loss: 0.6254 - val_accuracy: 0.7757\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.7560 - val_loss: 0.6175 - val_accuracy: 0.7679\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.7543 - val_loss: 0.6145 - val_accuracy: 0.7776\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.7585 - val_loss: 0.6164 - val_accuracy: 0.7806\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.7559 - val_loss: 0.6193 - val_accuracy: 0.7780\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.7532 - val_loss: 0.6149 - val_accuracy: 0.7608\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.7569 - val_loss: 0.6200 - val_accuracy: 0.7716\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.7555 - val_loss: 0.6170 - val_accuracy: 0.7556\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.7576 - val_loss: 0.6160 - val_accuracy: 0.7552\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.7559 - val_loss: 0.6208 - val_accuracy: 0.7776\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.7589 - val_loss: 0.6173 - val_accuracy: 0.7638\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.6380 - accuracy: 0.7560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                            | 1/10 [01:45<15:50, 105.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6379538178443909, 0.7560421228408813]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██                                                                           | 1046/40000 [00:00<00:03, 10457.77it/s]\u001b[A\n",
      "  5%|████                                                                         | 2116/40000 [00:00<00:03, 10599.67it/s]\u001b[A\n",
      "  8%|██████▏                                                                      | 3183/40000 [00:00<00:03, 10627.76it/s]\u001b[A\n",
      " 11%|████████▏                                                                    | 4246/40000 [00:00<00:03, 10528.57it/s]\u001b[A\n",
      " 13%|██████████▏                                                                  | 5310/40000 [00:00<00:03, 10567.23it/s]\u001b[A\n",
      " 16%|████████████▎                                                                | 6367/40000 [00:00<00:03, 10556.60it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7433/40000 [00:00<00:03, 10589.82it/s]\u001b[A\n",
      " 21%|████████████████▎                                                            | 8493/40000 [00:00<00:03, 10342.00it/s]\u001b[A\n",
      " 24%|██████████████████▍                                                          | 9556/40000 [00:00<00:02, 10427.65it/s]\u001b[A\n",
      " 27%|████████████████████▏                                                       | 10622/40000 [00:01<00:02, 10495.57it/s]\u001b[A\n",
      " 29%|██████████████████████▏                                                     | 11683/40000 [00:01<00:02, 10527.38it/s]\u001b[A\n",
      " 32%|████████████████████████▏                                                   | 12737/40000 [00:01<00:02, 10524.06it/s]\u001b[A\n",
      " 34%|██████████████████████████▏                                                 | 13790/40000 [00:01<00:02, 10463.62it/s]\u001b[A\n",
      " 37%|████████████████████████████▏                                               | 14847/40000 [00:01<00:02, 10493.05it/s]\u001b[A\n",
      " 40%|██████████████████████████████▏                                             | 15897/40000 [00:01<00:02, 10434.53it/s]\u001b[A\n",
      " 42%|████████████████████████████████▏                                           | 16966/40000 [00:01<00:02, 10508.36it/s]\u001b[A\n",
      " 45%|██████████████████████████████████▏                                         | 18018/40000 [00:01<00:02, 10421.46it/s]\u001b[A\n",
      " 48%|████████████████████████████████████▎                                       | 19088/40000 [00:01<00:01, 10503.20it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████▎                                     | 20184/40000 [00:01<00:01, 10636.34it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▍                                   | 21293/40000 [00:02<00:01, 10769.23it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▌                                 | 22371/40000 [00:02<00:01, 10601.50it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▌                               | 23444/40000 [00:02<00:01, 10638.94it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████▌                             | 24509/40000 [00:02<00:01, 10631.68it/s]\u001b[A\n",
      " 64%|████████████████████████████████████████████████▌                           | 25573/40000 [00:02<00:01, 10615.07it/s]\u001b[A\n",
      " 67%|██████████████████████████████████████████████████▌                         | 26635/40000 [00:02<00:01, 10599.09it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████▌                       | 27696/40000 [00:02<00:01, 10578.71it/s]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████████▋                     | 28754/40000 [00:02<00:01, 10575.34it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████▋                   | 29812/40000 [00:02<00:00, 10566.31it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▋                 | 30869/40000 [00:02<00:00, 10554.30it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▋               | 31925/40000 [00:03<00:00, 10540.78it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████▋             | 33010/40000 [00:03<00:00, 10517.77it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████▋           | 34062/40000 [00:03<00:00, 10309.01it/s]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████▊         | 35133/40000 [00:03<00:00, 10426.50it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████▉       | 36260/40000 [00:03<00:00, 10673.22it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▉     | 37329/40000 [00:03<00:00, 10639.61it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▉   | 38401/40000 [00:03<00:00, 10660.11it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 10553.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 25.2856 - accuracy: 0.2369 - val_loss: 11.6768 - val_accuracy: 0.2481\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 9.3536 - accuracy: 0.2833 - val_loss: 7.5998 - val_accuracy: 0.3276\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 6.4696 - accuracy: 0.3842 - val_loss: 5.5120 - val_accuracy: 0.4354\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.7159 - accuracy: 0.4803 - val_loss: 4.0454 - val_accuracy: 0.5216\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.3907 - accuracy: 0.5430 - val_loss: 2.8399 - val_accuracy: 0.5638\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.3141 - accuracy: 0.5800 - val_loss: 1.8974 - val_accuracy: 0.5937\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.5247 - accuracy: 0.6094 - val_loss: 1.2738 - val_accuracy: 0.6160\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.0756 - accuracy: 0.6339 - val_loss: 0.9563 - val_accuracy: 0.6515\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.6706 - val_loss: 0.8278 - val_accuracy: 0.6821\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7921 - accuracy: 0.7121 - val_loss: 0.7923 - val_accuracy: 0.6746\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7501 - accuracy: 0.7202 - val_loss: 0.7444 - val_accuracy: 0.7201\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7209 - accuracy: 0.7264 - val_loss: 0.7197 - val_accuracy: 0.7366\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.7300 - val_loss: 0.7039 - val_accuracy: 0.7090\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.7319 - val_loss: 0.6819 - val_accuracy: 0.7351\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.7321 - val_loss: 0.6781 - val_accuracy: 0.7388\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.7258 - val_loss: 0.6794 - val_accuracy: 0.7243\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.7433 - val_loss: 0.6641 - val_accuracy: 0.7437\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.7454 - val_loss: 0.6620 - val_accuracy: 0.7321\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.7415 - val_loss: 0.6715 - val_accuracy: 0.7007\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.7513 - val_loss: 0.6660 - val_accuracy: 0.7463\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.7515 - val_loss: 0.6677 - val_accuracy: 0.7067\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.7535 - val_loss: 0.6519 - val_accuracy: 0.7470\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.7425 - val_loss: 0.6385 - val_accuracy: 0.7519\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.7514 - val_loss: 0.6443 - val_accuracy: 0.7571\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.7537 - val_loss: 0.6326 - val_accuracy: 0.7612\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.7513 - val_loss: 0.6310 - val_accuracy: 0.7545\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.7560 - val_loss: 0.6387 - val_accuracy: 0.7172\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.7518 - val_loss: 0.6357 - val_accuracy: 0.7597\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.7552 - val_loss: 0.6225 - val_accuracy: 0.7590\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.7590 - val_loss: 0.6229 - val_accuracy: 0.7634\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.7593 - val_loss: 0.6240 - val_accuracy: 0.7481\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.7545 - val_loss: 0.6189 - val_accuracy: 0.7448\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.7525 - val_loss: 0.6148 - val_accuracy: 0.7396\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.7559 - val_loss: 0.6122 - val_accuracy: 0.7608\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.7604 - val_loss: 0.6096 - val_accuracy: 0.7735\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.7558 - val_loss: 0.6202 - val_accuracy: 0.7172\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.7587 - val_loss: 0.6124 - val_accuracy: 0.7675\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.7596 - val_loss: 0.6024 - val_accuracy: 0.7590\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.7595 - val_loss: 0.6331 - val_accuracy: 0.7157\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.7559 - val_loss: 0.6004 - val_accuracy: 0.7746\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7576 - val_loss: 0.5991 - val_accuracy: 0.7735\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.7596 - val_loss: 0.6085 - val_accuracy: 0.7313\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.7607 - val_loss: 0.5946 - val_accuracy: 0.7672\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.7624 - val_loss: 0.5987 - val_accuracy: 0.7481\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.7593 - val_loss: 0.5943 - val_accuracy: 0.7601\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.7605 - val_loss: 0.6008 - val_accuracy: 0.7642\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7618 - val_loss: 0.5908 - val_accuracy: 0.7653\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.7615 - val_loss: 0.5902 - val_accuracy: 0.7780\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.7615 - val_loss: 0.5904 - val_accuracy: 0.7646\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.7651 - val_loss: 0.5878 - val_accuracy: 0.7810\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7581 - val_loss: 0.5876 - val_accuracy: 0.7746\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7608 - val_loss: 0.6009 - val_accuracy: 0.7746\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7625 - val_loss: 0.6032 - val_accuracy: 0.7675\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.7566 - val_loss: 0.5889 - val_accuracy: 0.7657\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7593 - val_loss: 0.5894 - val_accuracy: 0.7772\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7624 - val_loss: 0.5883 - val_accuracy: 0.7563\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7628 - val_loss: 0.5922 - val_accuracy: 0.7765\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7612 - val_loss: 0.5905 - val_accuracy: 0.7396\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7606 - val_loss: 0.5836 - val_accuracy: 0.7757\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7615 - val_loss: 0.5820 - val_accuracy: 0.7552\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7633 - val_loss: 0.5852 - val_accuracy: 0.7754\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7632 - val_loss: 0.5797 - val_accuracy: 0.7750\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7615 - val_loss: 0.5839 - val_accuracy: 0.7743\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7617 - val_loss: 0.5767 - val_accuracy: 0.7780\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7612 - val_loss: 0.5823 - val_accuracy: 0.7709\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7616 - val_loss: 0.5831 - val_accuracy: 0.7739\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7594 - val_loss: 0.5732 - val_accuracy: 0.7642\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7636 - val_loss: 0.5739 - val_accuracy: 0.7675\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7584 - val_loss: 0.5805 - val_accuracy: 0.7731\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7626 - val_loss: 0.5850 - val_accuracy: 0.7724\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7616 - val_loss: 0.5712 - val_accuracy: 0.7817\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7616 - val_loss: 0.5717 - val_accuracy: 0.7619\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7638 - val_loss: 0.5741 - val_accuracy: 0.7724\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7603 - val_loss: 0.5768 - val_accuracy: 0.7575\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7631 - val_loss: 0.5783 - val_accuracy: 0.7649\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7617 - val_loss: 0.5774 - val_accuracy: 0.7750\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7649 - val_loss: 0.5681 - val_accuracy: 0.7784\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7620 - val_loss: 0.5717 - val_accuracy: 0.7653\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7654 - val_loss: 0.5744 - val_accuracy: 0.7754\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7600 - val_loss: 0.5701 - val_accuracy: 0.7601\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7612 - val_loss: 0.5684 - val_accuracy: 0.7601\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7640 - val_loss: 0.5757 - val_accuracy: 0.7496\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7632 - val_loss: 0.5698 - val_accuracy: 0.7799\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7644 - val_loss: 0.5689 - val_accuracy: 0.7679\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7604 - val_loss: 0.5651 - val_accuracy: 0.7690\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7623 - val_loss: 0.5799 - val_accuracy: 0.7388\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7626 - val_loss: 0.5680 - val_accuracy: 0.7701\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7634 - val_loss: 0.5657 - val_accuracy: 0.7646\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7623 - val_loss: 0.5765 - val_accuracy: 0.7687\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7644 - val_loss: 0.5708 - val_accuracy: 0.7638\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7615 - val_loss: 0.5827 - val_accuracy: 0.7429\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7625 - val_loss: 0.5629 - val_accuracy: 0.7705\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7608 - val_loss: 0.5688 - val_accuracy: 0.7761\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7629 - val_loss: 0.5661 - val_accuracy: 0.7619\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7630 - val_loss: 0.5681 - val_accuracy: 0.7687\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7627 - val_loss: 0.5718 - val_accuracy: 0.7836\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7651 - val_loss: 0.5633 - val_accuracy: 0.7705\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7606 - val_loss: 0.5632 - val_accuracy: 0.7679\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7627 - val_loss: 0.5817 - val_accuracy: 0.7399\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7620 - val_loss: 0.5640 - val_accuracy: 0.7694\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7617 - val_loss: 0.5663 - val_accuracy: 0.7493\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7632 - val_loss: 0.5637 - val_accuracy: 0.7799\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7621 - val_loss: 0.5832 - val_accuracy: 0.7384\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7649 - val_loss: 0.5834 - val_accuracy: 0.7388\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7628 - val_loss: 0.5612 - val_accuracy: 0.7675\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7620 - val_loss: 0.5742 - val_accuracy: 0.7780\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7645 - val_loss: 0.5610 - val_accuracy: 0.7772\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7625 - val_loss: 0.5605 - val_accuracy: 0.7761\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7649 - val_loss: 0.5603 - val_accuracy: 0.7713\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7625 - val_loss: 0.5732 - val_accuracy: 0.7418\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7649 - val_loss: 0.5668 - val_accuracy: 0.7649\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7640 - val_loss: 0.5692 - val_accuracy: 0.7511\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7621 - val_loss: 0.5660 - val_accuracy: 0.7795\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7639 - val_loss: 0.5885 - val_accuracy: 0.7429\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7620 - val_loss: 0.5622 - val_accuracy: 0.7556\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7636 - val_loss: 0.5597 - val_accuracy: 0.7601\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7642 - val_loss: 0.5603 - val_accuracy: 0.7664\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7636 - val_loss: 0.5661 - val_accuracy: 0.7687\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7644 - val_loss: 0.5704 - val_accuracy: 0.7664\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7632 - val_loss: 0.5773 - val_accuracy: 0.7496\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7621 - val_loss: 0.5642 - val_accuracy: 0.7679\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7651 - val_loss: 0.5789 - val_accuracy: 0.7362\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7640 - val_loss: 0.5686 - val_accuracy: 0.7675\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7641 - val_loss: 0.5680 - val_accuracy: 0.7493\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7641 - val_loss: 0.5606 - val_accuracy: 0.7664\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7641 - val_loss: 0.5630 - val_accuracy: 0.7832\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7589 - val_loss: 0.5643 - val_accuracy: 0.7821\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7634 - val_loss: 0.5575 - val_accuracy: 0.7728\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7644 - val_loss: 0.5661 - val_accuracy: 0.7623\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7630 - val_loss: 0.5641 - val_accuracy: 0.7780\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7623 - val_loss: 0.5681 - val_accuracy: 0.7522\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7633 - val_loss: 0.5589 - val_accuracy: 0.7657\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7644 - val_loss: 0.5657 - val_accuracy: 0.7519\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7615 - val_loss: 0.5623 - val_accuracy: 0.7728\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7641 - val_loss: 0.5596 - val_accuracy: 0.7619\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7620 - val_loss: 0.5599 - val_accuracy: 0.7571\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7615 - val_loss: 0.5599 - val_accuracy: 0.7664\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7620 - val_loss: 0.5591 - val_accuracy: 0.7795\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7630 - val_loss: 0.5715 - val_accuracy: 0.7660\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7625 - val_loss: 0.5610 - val_accuracy: 0.7522\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7668 - val_loss: 0.5691 - val_accuracy: 0.7530\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7622 - val_loss: 0.5591 - val_accuracy: 0.7597\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7638 - val_loss: 0.5603 - val_accuracy: 0.7679\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7625 - val_loss: 0.5591 - val_accuracy: 0.7791\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7617 - val_loss: 0.5692 - val_accuracy: 0.7799\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7628 - val_loss: 0.5628 - val_accuracy: 0.7731\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7630 - val_loss: 0.5655 - val_accuracy: 0.7507\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7641 - val_loss: 0.5563 - val_accuracy: 0.7720\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7646 - val_loss: 0.5625 - val_accuracy: 0.7586\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7621 - val_loss: 0.5586 - val_accuracy: 0.7619\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.5541 - accuracy: 0.7696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████                                                                    | 2/10 [03:28<13:53, 104.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5540688633918762, 0.7696037292480469]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▉                                                                           | 1026/40000 [00:00<00:03, 10249.72it/s]\u001b[A\n",
      "  5%|████                                                                         | 2093/40000 [00:00<00:03, 10495.19it/s]\u001b[A\n",
      "  8%|██████                                                                       | 3161/40000 [00:00<00:03, 10575.46it/s]\u001b[A\n",
      " 11%|████████                                                                     | 4219/40000 [00:00<00:03, 10511.92it/s]\u001b[A\n",
      " 13%|██████████▏                                                                  | 5319/40000 [00:00<00:03, 10685.71it/s]\u001b[A\n",
      " 16%|████████████▎                                                                | 6416/40000 [00:00<00:03, 10779.94it/s]\u001b[A\n",
      " 19%|██████████████▍                                                              | 7518/40000 [00:00<00:02, 10857.53it/s]\u001b[A\n",
      " 22%|████████████████▌                                                            | 8610/40000 [00:00<00:02, 10876.77it/s]\u001b[A\n",
      " 24%|██████████████████▋                                                          | 9704/40000 [00:00<00:02, 10893.89it/s]\u001b[A\n",
      " 27%|████████████████████▌                                                       | 10802/40000 [00:01<00:02, 10919.36it/s]\u001b[A\n",
      " 30%|██████████████████████▌                                                     | 11895/40000 [00:01<00:02, 10921.55it/s]\u001b[A\n",
      " 32%|████████████████████████▋                                                   | 12988/40000 [00:01<00:02, 10908.57it/s]\u001b[A\n",
      " 35%|██████████████████████████▊                                                 | 14079/40000 [00:01<00:02, 10902.05it/s]\u001b[A\n",
      " 38%|████████████████████████████▊                                               | 15170/40000 [00:01<00:02, 10904.02it/s]\u001b[A\n",
      " 41%|██████████████████████████████▉                                             | 16267/40000 [00:01<00:02, 10921.86it/s]\u001b[A\n",
      " 43%|████████████████████████████████▉                                           | 17361/40000 [00:01<00:02, 10927.10it/s]\u001b[A\n",
      " 46%|███████████████████████████████████                                         | 18457/40000 [00:01<00:01, 10936.22it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▏                                      | 19551/40000 [00:01<00:01, 10932.02it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▏                                    | 20645/40000 [00:01<00:01, 10879.25it/s]\u001b[A\n",
      " 54%|█████████████████████████████████████████▎                                  | 21733/40000 [00:02<00:01, 10805.93it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████▎                                | 22814/40000 [00:02<00:01, 10576.79it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████▍                              | 23902/40000 [00:02<00:01, 10664.24it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▍                            | 24999/40000 [00:02<00:01, 10752.16it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▌                          | 26090/40000 [00:02<00:01, 10797.75it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▌                        | 27171/40000 [00:02<00:01, 10724.36it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▋                      | 28244/40000 [00:02<00:01, 10676.65it/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████▋                    | 29312/40000 [00:02<00:01, 10626.00it/s]\u001b[A\n",
      " 76%|█████████████████████████████████████████████████████████▋                  | 30375/40000 [00:02<00:00, 10519.65it/s]\u001b[A\n",
      " 79%|███████████████████████████████████████████████████████████▊                | 31466/40000 [00:02<00:00, 10632.15it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▊              | 32557/40000 [00:03<00:00, 10712.80it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▉            | 33629/40000 [00:03<00:00, 10475.19it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▉          | 34732/40000 [00:03<00:00, 10636.25it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████        | 35840/40000 [00:03<00:00, 10764.48it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████▏     | 36943/40000 [00:03<00:00, 10842.31it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████▎   | 38047/40000 [00:03<00:00, 10900.04it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 10779.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 8.7662 - accuracy: 0.3217 - val_loss: 5.1878 - val_accuracy: 0.4116\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.4233 - accuracy: 0.4754 - val_loss: 3.6820 - val_accuracy: 0.5272\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.2324 - accuracy: 0.5700 - val_loss: 2.7463 - val_accuracy: 0.6022\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.4435 - accuracy: 0.6272 - val_loss: 2.1220 - val_accuracy: 0.6526\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.8792 - accuracy: 0.6701 - val_loss: 1.6292 - val_accuracy: 0.6862\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.4727 - accuracy: 0.7091 - val_loss: 1.3083 - val_accuracy: 0.7332\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.1799 - accuracy: 0.7401 - val_loss: 1.0851 - val_accuracy: 0.7504\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9851 - accuracy: 0.7618 - val_loss: 0.9523 - val_accuracy: 0.7776\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8681 - accuracy: 0.7769 - val_loss: 0.8669 - val_accuracy: 0.7873\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7973 - accuracy: 0.7916 - val_loss: 0.8201 - val_accuracy: 0.7892\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7576 - accuracy: 0.7995 - val_loss: 0.7769 - val_accuracy: 0.7989\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7256 - accuracy: 0.8095 - val_loss: 0.7599 - val_accuracy: 0.8078\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.8140 - val_loss: 0.7253 - val_accuracy: 0.8205\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.8173 - val_loss: 0.6995 - val_accuracy: 0.8138\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.8210 - val_loss: 0.6799 - val_accuracy: 0.8198\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.8242 - val_loss: 0.6582 - val_accuracy: 0.8216\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.8288 - val_loss: 0.6556 - val_accuracy: 0.8257\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.8277 - val_loss: 0.6232 - val_accuracy: 0.8287\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.8331 - val_loss: 0.6087 - val_accuracy: 0.8272\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.8354 - val_loss: 0.5944 - val_accuracy: 0.8373\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.8380 - val_loss: 0.5861 - val_accuracy: 0.8317\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.8386 - val_loss: 0.5732 - val_accuracy: 0.8336\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.8399 - val_loss: 0.5817 - val_accuracy: 0.8243\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.8411 - val_loss: 0.5767 - val_accuracy: 0.8284\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.8435 - val_loss: 0.5542 - val_accuracy: 0.8474\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.8417 - val_loss: 0.5617 - val_accuracy: 0.8306\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.8435 - val_loss: 0.5513 - val_accuracy: 0.8463\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.8433 - val_loss: 0.5457 - val_accuracy: 0.8287\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.8470 - val_loss: 0.5479 - val_accuracy: 0.8478\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8464 - val_loss: 0.5484 - val_accuracy: 0.8455\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8462 - val_loss: 0.5665 - val_accuracy: 0.8328\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8480 - val_loss: 0.5337 - val_accuracy: 0.8310\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8472 - val_loss: 0.5502 - val_accuracy: 0.8381\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8494 - val_loss: 0.5386 - val_accuracy: 0.8328\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8478 - val_loss: 0.5320 - val_accuracy: 0.8384\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8493 - val_loss: 0.5381 - val_accuracy: 0.8388\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.8484 - val_loss: 0.5296 - val_accuracy: 0.8425\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.8484 - val_loss: 0.5235 - val_accuracy: 0.8392\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8500 - val_loss: 0.5264 - val_accuracy: 0.8377\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8494 - val_loss: 0.5211 - val_accuracy: 0.8358\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8477 - val_loss: 0.5344 - val_accuracy: 0.8425\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8495 - val_loss: 0.5264 - val_accuracy: 0.8407\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8489 - val_loss: 0.5394 - val_accuracy: 0.8440\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8498 - val_loss: 0.5150 - val_accuracy: 0.8455\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8501 - val_loss: 0.5165 - val_accuracy: 0.8459\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8513 - val_loss: 0.5140 - val_accuracy: 0.8437\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8507 - val_loss: 0.5165 - val_accuracy: 0.8284\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8507 - val_loss: 0.5346 - val_accuracy: 0.8496\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8514 - val_loss: 0.5158 - val_accuracy: 0.8414\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8492 - val_loss: 0.5117 - val_accuracy: 0.8463\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8501 - val_loss: 0.5137 - val_accuracy: 0.8474\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8521 - val_loss: 0.5137 - val_accuracy: 0.8396\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8535 - val_loss: 0.5152 - val_accuracy: 0.8485\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8524 - val_loss: 0.5093 - val_accuracy: 0.8481\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8509 - val_loss: 0.5082 - val_accuracy: 0.8418\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8511 - val_loss: 0.5081 - val_accuracy: 0.8325\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8521 - val_loss: 0.5088 - val_accuracy: 0.8325\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8514 - val_loss: 0.5056 - val_accuracy: 0.8425\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8529 - val_loss: 0.5042 - val_accuracy: 0.8403\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8527 - val_loss: 0.5077 - val_accuracy: 0.8403\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8535 - val_loss: 0.5040 - val_accuracy: 0.8455\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8523 - val_loss: 0.5088 - val_accuracy: 0.8474\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8538 - val_loss: 0.5048 - val_accuracy: 0.8328\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8530 - val_loss: 0.5014 - val_accuracy: 0.8448\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8516 - val_loss: 0.5089 - val_accuracy: 0.8489\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8540 - val_loss: 0.4999 - val_accuracy: 0.8388\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8513 - val_loss: 0.4992 - val_accuracy: 0.8399\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8529 - val_loss: 0.4983 - val_accuracy: 0.8369\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8531 - val_loss: 0.5077 - val_accuracy: 0.8466\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8533 - val_loss: 0.4980 - val_accuracy: 0.8429\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8527 - val_loss: 0.5020 - val_accuracy: 0.8451\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8539 - val_loss: 0.5085 - val_accuracy: 0.8496\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8515 - val_loss: 0.5038 - val_accuracy: 0.8422\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8509 - val_loss: 0.5002 - val_accuracy: 0.8429\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8535 - val_loss: 0.5042 - val_accuracy: 0.8485\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8520 - val_loss: 0.5033 - val_accuracy: 0.8500\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8536 - val_loss: 0.4989 - val_accuracy: 0.8463\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8516 - val_loss: 0.5049 - val_accuracy: 0.8496\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8534 - val_loss: 0.4940 - val_accuracy: 0.8422\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8532 - val_loss: 0.5065 - val_accuracy: 0.8459\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8530 - val_loss: 0.4979 - val_accuracy: 0.8418\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8512 - val_loss: 0.5104 - val_accuracy: 0.8504\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8539 - val_loss: 0.4951 - val_accuracy: 0.8474\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8528 - val_loss: 0.5024 - val_accuracy: 0.8425\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8525 - val_loss: 0.5060 - val_accuracy: 0.8451\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8531 - val_loss: 0.4961 - val_accuracy: 0.8496\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8517 - val_loss: 0.4991 - val_accuracy: 0.8481\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8547 - val_loss: 0.4937 - val_accuracy: 0.8358\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8522 - val_loss: 0.4971 - val_accuracy: 0.8437\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8530 - val_loss: 0.4964 - val_accuracy: 0.8429\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8519 - val_loss: 0.5022 - val_accuracy: 0.8489\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8521 - val_loss: 0.5068 - val_accuracy: 0.8373\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8513 - val_loss: 0.4983 - val_accuracy: 0.8500\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8532 - val_loss: 0.5000 - val_accuracy: 0.8519\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8527 - val_loss: 0.5187 - val_accuracy: 0.8455\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8544 - val_loss: 0.4923 - val_accuracy: 0.8388\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8541 - val_loss: 0.5030 - val_accuracy: 0.8500\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8528 - val_loss: 0.4943 - val_accuracy: 0.8396\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8533 - val_loss: 0.4935 - val_accuracy: 0.8455\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8528 - val_loss: 0.4931 - val_accuracy: 0.8396\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8539 - val_loss: 0.4976 - val_accuracy: 0.8500\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8535 - val_loss: 0.5021 - val_accuracy: 0.8489\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8530 - val_loss: 0.4943 - val_accuracy: 0.8481\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8540 - val_loss: 0.4913 - val_accuracy: 0.8444\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8526 - val_loss: 0.4929 - val_accuracy: 0.8455\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8538 - val_loss: 0.4905 - val_accuracy: 0.8440\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8544 - val_loss: 0.5080 - val_accuracy: 0.8451\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8536 - val_loss: 0.4935 - val_accuracy: 0.8396\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8528 - val_loss: 0.4938 - val_accuracy: 0.8496\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8551 - val_loss: 0.4915 - val_accuracy: 0.8489\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8548 - val_loss: 0.4933 - val_accuracy: 0.8429\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8540 - val_loss: 0.4900 - val_accuracy: 0.8418\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8536 - val_loss: 0.4939 - val_accuracy: 0.8493\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8533 - val_loss: 0.4986 - val_accuracy: 0.8496\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8540 - val_loss: 0.4952 - val_accuracy: 0.8347\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8535 - val_loss: 0.4907 - val_accuracy: 0.8425\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8534 - val_loss: 0.4908 - val_accuracy: 0.8478\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8535 - val_loss: 0.4912 - val_accuracy: 0.8403\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8527 - val_loss: 0.4903 - val_accuracy: 0.8511\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8550 - val_loss: 0.4995 - val_accuracy: 0.8485\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8542 - val_loss: 0.4917 - val_accuracy: 0.8493\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8543 - val_loss: 0.5047 - val_accuracy: 0.8455\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8523 - val_loss: 0.4946 - val_accuracy: 0.8470\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8546 - val_loss: 0.4898 - val_accuracy: 0.8403\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8547 - val_loss: 0.4908 - val_accuracy: 0.8489\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8536 - val_loss: 0.4899 - val_accuracy: 0.8463\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8538 - val_loss: 0.4950 - val_accuracy: 0.8504\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8552 - val_loss: 0.4941 - val_accuracy: 0.8496\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8534 - val_loss: 0.4986 - val_accuracy: 0.8507\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8531 - val_loss: 0.5010 - val_accuracy: 0.8366\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8550 - val_loss: 0.4922 - val_accuracy: 0.8459\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8522 - val_loss: 0.4959 - val_accuracy: 0.8466\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8531 - val_loss: 0.5019 - val_accuracy: 0.8478\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8542 - val_loss: 0.4945 - val_accuracy: 0.8425\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8549 - val_loss: 0.5030 - val_accuracy: 0.8433\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8547 - val_loss: 0.4942 - val_accuracy: 0.8463\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8545 - val_loss: 0.4906 - val_accuracy: 0.8500\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8544 - val_loss: 0.4897 - val_accuracy: 0.8433\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8530 - val_loss: 0.5052 - val_accuracy: 0.8489\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8523 - val_loss: 0.4921 - val_accuracy: 0.8474\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8545 - val_loss: 0.4900 - val_accuracy: 0.8485\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8528 - val_loss: 0.4988 - val_accuracy: 0.8478\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8560 - val_loss: 0.4926 - val_accuracy: 0.8507\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8535 - val_loss: 0.4921 - val_accuracy: 0.8481\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8539 - val_loss: 0.4960 - val_accuracy: 0.8474\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8538 - val_loss: 0.5004 - val_accuracy: 0.8429\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8521 - val_loss: 0.4936 - val_accuracy: 0.8511\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8558 - val_loss: 0.5014 - val_accuracy: 0.8481\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8543 - val_loss: 0.4965 - val_accuracy: 0.8474\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8537 - val_loss: 0.4959 - val_accuracy: 0.8369\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.4587 - accuracy: 0.8516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▌                                                           | 3/10 [05:12<12:08, 104.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4586627781391144, 0.8515796661376953]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1249/40000 [00:00<00:03, 12478.20it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2497/40000 [00:00<00:03, 12399.06it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3738/40000 [00:00<00:02, 12400.21it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4979/40000 [00:00<00:02, 12401.58it/s]\u001b[A\n",
      " 16%|███████████▉                                                                 | 6220/40000 [00:00<00:02, 12401.69it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7461/40000 [00:00<00:02, 12396.93it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8701/40000 [00:00<00:02, 12392.28it/s]\u001b[A\n",
      " 25%|███████████████████▏                                                         | 9941/40000 [00:00<00:02, 12392.43it/s]\u001b[A\n",
      " 28%|█████████████████████▎                                                      | 11185/40000 [00:00<00:02, 12406.86it/s]\u001b[A\n",
      " 31%|███████████████████████▌                                                    | 12428/40000 [00:01<00:02, 12412.57it/s]\u001b[A\n",
      " 34%|█████████████████████████▉                                                  | 13670/40000 [00:01<00:02, 12411.24it/s]\u001b[A\n",
      " 37%|████████████████████████████▎                                               | 14915/40000 [00:01<00:02, 12422.82it/s]\u001b[A\n",
      " 40%|██████████████████████████████▋                                             | 16158/40000 [00:01<00:01, 12418.88it/s]\u001b[A\n",
      " 44%|█████████████████████████████████                                           | 17400/40000 [00:01<00:01, 12412.68it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▍                                        | 18647/40000 [00:01<00:01, 12428.20it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▊                                      | 19890/40000 [00:01<00:01, 12425.28it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▏                                   | 21133/40000 [00:01<00:01, 12417.34it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▌                                 | 22375/40000 [00:01<00:01, 12408.36it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▊                               | 23616/40000 [00:01<00:01, 12250.41it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▏                            | 24854/40000 [00:02<00:01, 12286.82it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▌                          | 26094/40000 [00:02<00:01, 12317.77it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▉                        | 27331/40000 [00:02<00:01, 12333.24it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████▎                     | 28568/40000 [00:02<00:00, 12341.57it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████▋                   | 29803/40000 [00:02<00:00, 12341.98it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████▉                 | 31041/40000 [00:02<00:00, 12351.92it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▎              | 32281/40000 [00:02<00:00, 12364.00it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▋            | 33518/40000 [00:02<00:00, 12363.88it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████          | 34757/40000 [00:02<00:00, 12369.01it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▍       | 35995/40000 [00:02<00:00, 12369.72it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▋     | 37233/40000 [00:03<00:00, 12371.26it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████   | 38471/40000 [00:03<00:00, 12372.18it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12375.33it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 10.9979 - accuracy: 0.2717 - val_loss: 6.0413 - val_accuracy: 0.2925\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 5.1858 - accuracy: 0.3069 - val_loss: 3.9809 - val_accuracy: 0.3481\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.4566 - accuracy: 0.4201 - val_loss: 2.7588 - val_accuracy: 0.4873\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.5100 - accuracy: 0.5300 - val_loss: 2.0868 - val_accuracy: 0.5694\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.9394 - accuracy: 0.5977 - val_loss: 1.6721 - val_accuracy: 0.6254\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.5554 - accuracy: 0.6396 - val_loss: 1.3711 - val_accuracy: 0.6582\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.2801 - accuracy: 0.6705 - val_loss: 1.1303 - val_accuracy: 0.6817\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.0823 - accuracy: 0.6931 - val_loss: 0.9695 - val_accuracy: 0.7049\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9508 - accuracy: 0.7127 - val_loss: 0.8690 - val_accuracy: 0.7168\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8621 - accuracy: 0.7325 - val_loss: 0.7951 - val_accuracy: 0.7526\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8006 - accuracy: 0.7463 - val_loss: 0.7570 - val_accuracy: 0.7463\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7505 - accuracy: 0.7645 - val_loss: 0.7082 - val_accuracy: 0.7910\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.7782 - val_loss: 0.6874 - val_accuracy: 0.7795\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.7875 - val_loss: 0.6525 - val_accuracy: 0.8015\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.8011 - val_loss: 0.6359 - val_accuracy: 0.8198\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.8084 - val_loss: 0.6196 - val_accuracy: 0.8354\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.8154 - val_loss: 0.6081 - val_accuracy: 0.8179\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.8224 - val_loss: 0.5957 - val_accuracy: 0.8239\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.8274 - val_loss: 0.5839 - val_accuracy: 0.8381\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.8321 - val_loss: 0.5748 - val_accuracy: 0.8515\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.8365 - val_loss: 0.5695 - val_accuracy: 0.8381\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.8396 - val_loss: 0.5615 - val_accuracy: 0.8444\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.8439 - val_loss: 0.5507 - val_accuracy: 0.8504\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.8487 - val_loss: 0.5468 - val_accuracy: 0.8448\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.8488 - val_loss: 0.5373 - val_accuracy: 0.8534\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.8516 - val_loss: 0.5288 - val_accuracy: 0.8537\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.8513 - val_loss: 0.5229 - val_accuracy: 0.8552\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.8536 - val_loss: 0.5192 - val_accuracy: 0.8638\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8567 - val_loss: 0.5227 - val_accuracy: 0.8493\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.8572 - val_loss: 0.5072 - val_accuracy: 0.8646\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.8604 - val_loss: 0.5095 - val_accuracy: 0.8631\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8598 - val_loss: 0.5005 - val_accuracy: 0.8675\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.8606 - val_loss: 0.4921 - val_accuracy: 0.8541\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8606 - val_loss: 0.4929 - val_accuracy: 0.8698\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8619 - val_loss: 0.4954 - val_accuracy: 0.8619\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8625 - val_loss: 0.4819 - val_accuracy: 0.8552\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8632 - val_loss: 0.4749 - val_accuracy: 0.8549\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8641 - val_loss: 0.4681 - val_accuracy: 0.8705\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8648 - val_loss: 0.4656 - val_accuracy: 0.8769\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8679 - val_loss: 0.4609 - val_accuracy: 0.8653\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8661 - val_loss: 0.4587 - val_accuracy: 0.8769\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8696 - val_loss: 0.4547 - val_accuracy: 0.8619\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8680 - val_loss: 0.4516 - val_accuracy: 0.8716\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8696 - val_loss: 0.4587 - val_accuracy: 0.8698\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8672 - val_loss: 0.4501 - val_accuracy: 0.8769\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8691 - val_loss: 0.4531 - val_accuracy: 0.8757\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8691 - val_loss: 0.4399 - val_accuracy: 0.8802\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8686 - val_loss: 0.4454 - val_accuracy: 0.8586\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8689 - val_loss: 0.4348 - val_accuracy: 0.8821\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8699 - val_loss: 0.4310 - val_accuracy: 0.8705\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8694 - val_loss: 0.4315 - val_accuracy: 0.8795\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8712 - val_loss: 0.4260 - val_accuracy: 0.8795\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8700 - val_loss: 0.4267 - val_accuracy: 0.8840\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8707 - val_loss: 0.4229 - val_accuracy: 0.8821\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8739 - val_loss: 0.4348 - val_accuracy: 0.8765\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8700 - val_loss: 0.4180 - val_accuracy: 0.8657\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8717 - val_loss: 0.4206 - val_accuracy: 0.8817\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8730 - val_loss: 0.4137 - val_accuracy: 0.8743\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8733 - val_loss: 0.4139 - val_accuracy: 0.8776\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8727 - val_loss: 0.4111 - val_accuracy: 0.8769\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8725 - val_loss: 0.4137 - val_accuracy: 0.8799\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8736 - val_loss: 0.4159 - val_accuracy: 0.8817\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8736 - val_loss: 0.4089 - val_accuracy: 0.8828\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8738 - val_loss: 0.4064 - val_accuracy: 0.8728\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8730 - val_loss: 0.4058 - val_accuracy: 0.8675\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8729 - val_loss: 0.4027 - val_accuracy: 0.8780\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8742 - val_loss: 0.4020 - val_accuracy: 0.8806\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8735 - val_loss: 0.3989 - val_accuracy: 0.8720\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8747 - val_loss: 0.4052 - val_accuracy: 0.8795\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8736 - val_loss: 0.4008 - val_accuracy: 0.8795\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8737 - val_loss: 0.3989 - val_accuracy: 0.8776\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8737 - val_loss: 0.3993 - val_accuracy: 0.8825\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8759 - val_loss: 0.3974 - val_accuracy: 0.8854\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8748 - val_loss: 0.3930 - val_accuracy: 0.8810\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8749 - val_loss: 0.3934 - val_accuracy: 0.8813\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8752 - val_loss: 0.3910 - val_accuracy: 0.8705\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8737 - val_loss: 0.3960 - val_accuracy: 0.8892\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8748 - val_loss: 0.3899 - val_accuracy: 0.8784\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8735 - val_loss: 0.3883 - val_accuracy: 0.8698\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8754 - val_loss: 0.3998 - val_accuracy: 0.8806\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8738 - val_loss: 0.3889 - val_accuracy: 0.8795\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8752 - val_loss: 0.3991 - val_accuracy: 0.8858\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8759 - val_loss: 0.3855 - val_accuracy: 0.8810\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8752 - val_loss: 0.3882 - val_accuracy: 0.8683\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8746 - val_loss: 0.3914 - val_accuracy: 0.8761\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8762 - val_loss: 0.3966 - val_accuracy: 0.8817\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8749 - val_loss: 0.3853 - val_accuracy: 0.8631\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8748 - val_loss: 0.3857 - val_accuracy: 0.8601\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8755 - val_loss: 0.3819 - val_accuracy: 0.8832\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8756 - val_loss: 0.3812 - val_accuracy: 0.8731\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8749 - val_loss: 0.3799 - val_accuracy: 0.8802\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8756 - val_loss: 0.3809 - val_accuracy: 0.8694\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8746 - val_loss: 0.3790 - val_accuracy: 0.8795\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8761 - val_loss: 0.3842 - val_accuracy: 0.8772\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8756 - val_loss: 0.3824 - val_accuracy: 0.8802\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8758 - val_loss: 0.3790 - val_accuracy: 0.8840\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8765 - val_loss: 0.3774 - val_accuracy: 0.8840\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8749 - val_loss: 0.3805 - val_accuracy: 0.8765\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8747 - val_loss: 0.3774 - val_accuracy: 0.8694\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8768 - val_loss: 0.3782 - val_accuracy: 0.8746\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8734 - val_loss: 0.3827 - val_accuracy: 0.8627\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8736 - val_loss: 0.3802 - val_accuracy: 0.8821\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8761 - val_loss: 0.3793 - val_accuracy: 0.8888\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8752 - val_loss: 0.3816 - val_accuracy: 0.8862\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8765 - val_loss: 0.3814 - val_accuracy: 0.8821\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8759 - val_loss: 0.3777 - val_accuracy: 0.8657\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8731 - val_loss: 0.3754 - val_accuracy: 0.8832\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8747 - val_loss: 0.3781 - val_accuracy: 0.8877\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8765 - val_loss: 0.3786 - val_accuracy: 0.8757\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8756 - val_loss: 0.3715 - val_accuracy: 0.8776\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8762 - val_loss: 0.3741 - val_accuracy: 0.8799\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8768 - val_loss: 0.3728 - val_accuracy: 0.8843\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8757 - val_loss: 0.3713 - val_accuracy: 0.8765\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8762 - val_loss: 0.3755 - val_accuracy: 0.8877\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8769 - val_loss: 0.3725 - val_accuracy: 0.8731\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8754 - val_loss: 0.3786 - val_accuracy: 0.8873\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8761 - val_loss: 0.3720 - val_accuracy: 0.8828\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8762 - val_loss: 0.3720 - val_accuracy: 0.8720\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8750 - val_loss: 0.3813 - val_accuracy: 0.8896\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8789 - val_loss: 0.3712 - val_accuracy: 0.8851\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8750 - val_loss: 0.3699 - val_accuracy: 0.8746\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8777 - val_loss: 0.3742 - val_accuracy: 0.8638\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8754 - val_loss: 0.3750 - val_accuracy: 0.8847\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8779 - val_loss: 0.3720 - val_accuracy: 0.8802\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8749 - val_loss: 0.3825 - val_accuracy: 0.8791\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8776 - val_loss: 0.3769 - val_accuracy: 0.8806\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8750 - val_loss: 0.3702 - val_accuracy: 0.8869\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8752 - val_loss: 0.3724 - val_accuracy: 0.8862\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8774 - val_loss: 0.3703 - val_accuracy: 0.8862\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8747 - val_loss: 0.3714 - val_accuracy: 0.8836\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8755 - val_loss: 0.3688 - val_accuracy: 0.8821\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8752 - val_loss: 0.3797 - val_accuracy: 0.8795\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8770 - val_loss: 0.3707 - val_accuracy: 0.8795\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8765 - val_loss: 0.3677 - val_accuracy: 0.8847\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8747 - val_loss: 0.3674 - val_accuracy: 0.8761\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8757 - val_loss: 0.3669 - val_accuracy: 0.8802\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8773 - val_loss: 0.3754 - val_accuracy: 0.8780\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8752 - val_loss: 0.3809 - val_accuracy: 0.8877\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8766 - val_loss: 0.3807 - val_accuracy: 0.8847\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8773 - val_loss: 0.3742 - val_accuracy: 0.8575\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8759 - val_loss: 0.3697 - val_accuracy: 0.8757\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8766 - val_loss: 0.3770 - val_accuracy: 0.8843\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8773 - val_loss: 0.3770 - val_accuracy: 0.8769\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8769 - val_loss: 0.3712 - val_accuracy: 0.8642\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8759 - val_loss: 0.3695 - val_accuracy: 0.8862\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8745 - val_loss: 0.3723 - val_accuracy: 0.8840\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8765 - val_loss: 0.3677 - val_accuracy: 0.8660\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8753 - val_loss: 0.3712 - val_accuracy: 0.8862\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8758 - val_loss: 0.3675 - val_accuracy: 0.8862\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8777 - val_loss: 0.3665 - val_accuracy: 0.8877\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.3617 - accuracy: 0.8868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████                                                   | 4/10 [06:53<10:16, 102.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36172422766685486, 0.8868095874786377]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1253/40000 [00:00<00:03, 12524.76it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2506/40000 [00:00<00:03, 12425.61it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3749/40000 [00:00<00:02, 12378.58it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4987/40000 [00:00<00:02, 12338.81it/s]\u001b[A\n",
      " 16%|███████████▉                                                                 | 6221/40000 [00:00<00:02, 12320.38it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7454/40000 [00:00<00:02, 12311.20it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8686/40000 [00:00<00:02, 12310.24it/s]\u001b[A\n",
      " 25%|███████████████████                                                          | 9918/40000 [00:00<00:02, 12303.58it/s]\u001b[A\n",
      " 28%|█████████████████████▏                                                      | 11152/40000 [00:00<00:02, 12313.82it/s]\u001b[A\n",
      " 31%|███████████████████████▌                                                    | 12391/40000 [00:01<00:02, 12334.98it/s]\u001b[A\n",
      " 34%|█████████████████████████▉                                                  | 13631/40000 [00:01<00:02, 12352.60it/s]\u001b[A\n",
      " 37%|████████████████████████████▎                                               | 14874/40000 [00:01<00:02, 12374.87it/s]\u001b[A\n",
      " 40%|██████████████████████████████▌                                             | 16112/40000 [00:01<00:01, 12372.63it/s]\u001b[A\n",
      " 43%|████████████████████████████████▉                                           | 17350/40000 [00:01<00:01, 12370.95it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▎                                        | 18588/40000 [00:01<00:01, 12356.27it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▋                                      | 19824/40000 [00:01<00:01, 12355.73it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████                                    | 21060/40000 [00:01<00:01, 12342.96it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▎                                 | 22295/40000 [00:01<00:01, 12343.12it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▋                               | 23530/40000 [00:01<00:01, 12335.83it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████                             | 24764/40000 [00:02<00:01, 12331.10it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▍                          | 25998/40000 [00:02<00:01, 12325.10it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▋                        | 27231/40000 [00:02<00:01, 12311.58it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████                      | 28463/40000 [00:02<00:00, 12309.36it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▍                   | 29694/40000 [00:02<00:00, 12014.16it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▊                 | 30922/40000 [00:02<00:00, 12091.42it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████               | 32154/40000 [00:02<00:00, 12157.18it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▍            | 33386/40000 [00:02<00:00, 12202.62it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▊          | 34616/40000 [00:02<00:00, 12229.20it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████        | 35847/40000 [00:02<00:00, 12250.47it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▍     | 37078/40000 [00:03<00:00, 12268.04it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▊   | 38307/40000 [00:03<00:00, 12273.43it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12289.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 12.9313 - accuracy: 0.2493 - val_loss: 7.8389 - val_accuracy: 0.2701\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 6.6706 - accuracy: 0.3267 - val_loss: 5.5043 - val_accuracy: 0.3772\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.6468 - accuracy: 0.4309 - val_loss: 3.9485 - val_accuracy: 0.4608\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.2866 - accuracy: 0.5082 - val_loss: 2.8343 - val_accuracy: 0.5392\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.3657 - accuracy: 0.5672 - val_loss: 2.0956 - val_accuracy: 0.5776\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.7344 - accuracy: 0.6095 - val_loss: 1.5448 - val_accuracy: 0.6276\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.3154 - accuracy: 0.6442 - val_loss: 1.1904 - val_accuracy: 0.6429\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.0286 - accuracy: 0.6670 - val_loss: 0.9367 - val_accuracy: 0.6780\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8408 - accuracy: 0.6853 - val_loss: 0.7720 - val_accuracy: 0.7041\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7218 - accuracy: 0.7046 - val_loss: 0.6759 - val_accuracy: 0.7134\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.7161 - val_loss: 0.6250 - val_accuracy: 0.7347\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.7221 - val_loss: 0.5970 - val_accuracy: 0.7198\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.7319 - val_loss: 0.5777 - val_accuracy: 0.7138\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7353 - val_loss: 0.5497 - val_accuracy: 0.7522\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7381 - val_loss: 0.5433 - val_accuracy: 0.7235\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7353 - val_loss: 0.5230 - val_accuracy: 0.7511\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7412 - val_loss: 0.5154 - val_accuracy: 0.7362\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7465 - val_loss: 0.5106 - val_accuracy: 0.7478\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7521 - val_loss: 0.5057 - val_accuracy: 0.7556\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7476 - val_loss: 0.5003 - val_accuracy: 0.7560\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7539 - val_loss: 0.4969 - val_accuracy: 0.7466\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7523 - val_loss: 0.4901 - val_accuracy: 0.7713\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7562 - val_loss: 0.4893 - val_accuracy: 0.7593\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7540 - val_loss: 0.4972 - val_accuracy: 0.7239\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7549 - val_loss: 0.4840 - val_accuracy: 0.7690\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7631 - val_loss: 0.4832 - val_accuracy: 0.7776\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7605 - val_loss: 0.4905 - val_accuracy: 0.7410\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7618 - val_loss: 0.4798 - val_accuracy: 0.7713\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7623 - val_loss: 0.4805 - val_accuracy: 0.7754\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7592 - val_loss: 0.4719 - val_accuracy: 0.7828\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7683 - val_loss: 0.4814 - val_accuracy: 0.7429\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7649 - val_loss: 0.4697 - val_accuracy: 0.7858\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7610 - val_loss: 0.4666 - val_accuracy: 0.7888\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7672 - val_loss: 0.4667 - val_accuracy: 0.7881\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7678 - val_loss: 0.4658 - val_accuracy: 0.7668\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7675 - val_loss: 0.5044 - val_accuracy: 0.7052\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7685 - val_loss: 0.4657 - val_accuracy: 0.7687\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7718 - val_loss: 0.4620 - val_accuracy: 0.7690\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7707 - val_loss: 0.4569 - val_accuracy: 0.7873\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7719 - val_loss: 0.4572 - val_accuracy: 0.7731\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7730 - val_loss: 0.4543 - val_accuracy: 0.7802\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7771 - val_loss: 0.4653 - val_accuracy: 0.7403\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7792 - val_loss: 0.4549 - val_accuracy: 0.7847\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7761 - val_loss: 0.4528 - val_accuracy: 0.7892\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7771 - val_loss: 0.4554 - val_accuracy: 0.7604\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7740 - val_loss: 0.4487 - val_accuracy: 0.7910\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7738 - val_loss: 0.4570 - val_accuracy: 0.7466\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7724 - val_loss: 0.4494 - val_accuracy: 0.7985\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7746 - val_loss: 0.4466 - val_accuracy: 0.7642\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7770 - val_loss: 0.4437 - val_accuracy: 0.7903\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7719 - val_loss: 0.4450 - val_accuracy: 0.7989\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7762 - val_loss: 0.4464 - val_accuracy: 0.7937\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7746 - val_loss: 0.4470 - val_accuracy: 0.7948\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7772 - val_loss: 0.4389 - val_accuracy: 0.7981\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7752 - val_loss: 0.4472 - val_accuracy: 0.7522\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7765 - val_loss: 0.4414 - val_accuracy: 0.7813\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7763 - val_loss: 0.4383 - val_accuracy: 0.7649\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7763 - val_loss: 0.4396 - val_accuracy: 0.7963\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7766 - val_loss: 0.4358 - val_accuracy: 0.7679\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7766 - val_loss: 0.4396 - val_accuracy: 0.7545\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7798 - val_loss: 0.4366 - val_accuracy: 0.7974\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7776 - val_loss: 0.4327 - val_accuracy: 0.7884\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7790 - val_loss: 0.4318 - val_accuracy: 0.7840\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7790 - val_loss: 0.4351 - val_accuracy: 0.7627\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7829 - val_loss: 0.4308 - val_accuracy: 0.7948\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7781 - val_loss: 0.4363 - val_accuracy: 0.7664\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7823 - val_loss: 0.4295 - val_accuracy: 0.8011\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7816 - val_loss: 0.4288 - val_accuracy: 0.7910\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7802 - val_loss: 0.4405 - val_accuracy: 0.7455\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7855 - val_loss: 0.4250 - val_accuracy: 0.7959\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7801 - val_loss: 0.4390 - val_accuracy: 0.7496\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7816 - val_loss: 0.4271 - val_accuracy: 0.7996\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7783 - val_loss: 0.4250 - val_accuracy: 0.7735\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7807 - val_loss: 0.4233 - val_accuracy: 0.7840\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7819 - val_loss: 0.4231 - val_accuracy: 0.7989\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7829 - val_loss: 0.4341 - val_accuracy: 0.7493\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7850 - val_loss: 0.4208 - val_accuracy: 0.7817\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7835 - val_loss: 0.4208 - val_accuracy: 0.7851\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7843 - val_loss: 0.4281 - val_accuracy: 0.7560\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7830 - val_loss: 0.4388 - val_accuracy: 0.7892\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7843 - val_loss: 0.4211 - val_accuracy: 0.7832\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7830 - val_loss: 0.4215 - val_accuracy: 0.7743\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7814 - val_loss: 0.4197 - val_accuracy: 0.8063\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7826 - val_loss: 0.4236 - val_accuracy: 0.7586\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7841 - val_loss: 0.4181 - val_accuracy: 0.7974\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7836 - val_loss: 0.4168 - val_accuracy: 0.7832\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7816 - val_loss: 0.4196 - val_accuracy: 0.7687\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7853 - val_loss: 0.4168 - val_accuracy: 0.7765\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7837 - val_loss: 0.4184 - val_accuracy: 0.7675\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7802 - val_loss: 0.4142 - val_accuracy: 0.7940\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7839 - val_loss: 0.4208 - val_accuracy: 0.7653\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7856 - val_loss: 0.4203 - val_accuracy: 0.7556\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7862 - val_loss: 0.4241 - val_accuracy: 0.7556\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7882 - val_loss: 0.4224 - val_accuracy: 0.8101\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7850 - val_loss: 0.4144 - val_accuracy: 0.7724\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7838 - val_loss: 0.4220 - val_accuracy: 0.8026\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7857 - val_loss: 0.4168 - val_accuracy: 0.7567\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7844 - val_loss: 0.4116 - val_accuracy: 0.8022\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7877 - val_loss: 0.4203 - val_accuracy: 0.7560\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7846 - val_loss: 0.4115 - val_accuracy: 0.7854\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7870 - val_loss: 0.4136 - val_accuracy: 0.7675\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.4124 - val_accuracy: 0.7746\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7855 - val_loss: 0.4090 - val_accuracy: 0.7907\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7858 - val_loss: 0.4130 - val_accuracy: 0.8071\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7876 - val_loss: 0.4069 - val_accuracy: 0.7993\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7841 - val_loss: 0.4315 - val_accuracy: 0.7463\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7870 - val_loss: 0.4067 - val_accuracy: 0.7925\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7863 - val_loss: 0.4058 - val_accuracy: 0.8011\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7860 - val_loss: 0.4123 - val_accuracy: 0.8075\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7843 - val_loss: 0.4108 - val_accuracy: 0.7660\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7869 - val_loss: 0.4077 - val_accuracy: 0.7840\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7889 - val_loss: 0.4051 - val_accuracy: 0.7944\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.7866 - val_loss: 0.4048 - val_accuracy: 0.7836\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7867 - val_loss: 0.4268 - val_accuracy: 0.7451\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.7882 - val_loss: 0.4057 - val_accuracy: 0.7974\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.7855 - val_loss: 0.4186 - val_accuracy: 0.7511\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.7898 - val_loss: 0.4056 - val_accuracy: 0.8108\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.7852 - val_loss: 0.4038 - val_accuracy: 0.7955\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.7886 - val_loss: 0.4046 - val_accuracy: 0.7974\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.7868 - val_loss: 0.4069 - val_accuracy: 0.7993\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.7857 - val_loss: 0.4036 - val_accuracy: 0.8015\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.7914 - val_loss: 0.4033 - val_accuracy: 0.7914\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.7872 - val_loss: 0.4172 - val_accuracy: 0.7541\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.7894 - val_loss: 0.4016 - val_accuracy: 0.7996\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.7882 - val_loss: 0.4017 - val_accuracy: 0.7914\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.7889 - val_loss: 0.4018 - val_accuracy: 0.7903\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7892 - val_loss: 0.4024 - val_accuracy: 0.7799\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.7880 - val_loss: 0.4009 - val_accuracy: 0.7951\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.7883 - val_loss: 0.4045 - val_accuracy: 0.8045\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.7880 - val_loss: 0.4105 - val_accuracy: 0.7608\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.7897 - val_loss: 0.4005 - val_accuracy: 0.7955\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.7886 - val_loss: 0.4004 - val_accuracy: 0.7780\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.7855 - val_loss: 0.4293 - val_accuracy: 0.7433\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7892 - val_loss: 0.4102 - val_accuracy: 0.8119\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.7868 - val_loss: 0.4032 - val_accuracy: 0.7668\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.7869 - val_loss: 0.4000 - val_accuracy: 0.7757\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.7873 - val_loss: 0.4029 - val_accuracy: 0.7634\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.7890 - val_loss: 0.3988 - val_accuracy: 0.7940\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.7898 - val_loss: 0.4087 - val_accuracy: 0.7653\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.7857 - val_loss: 0.3967 - val_accuracy: 0.8116\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.7911 - val_loss: 0.4123 - val_accuracy: 0.7549\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.7884 - val_loss: 0.4000 - val_accuracy: 0.7713\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.7889 - val_loss: 0.4043 - val_accuracy: 0.7623\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.7887 - val_loss: 0.3968 - val_accuracy: 0.7989\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.7921 - val_loss: 0.3961 - val_accuracy: 0.7843\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.7919 - val_loss: 0.4008 - val_accuracy: 0.7780\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.7882 - val_loss: 0.3946 - val_accuracy: 0.8022\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.7905 - val_loss: 0.4064 - val_accuracy: 0.7627\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.7889 - val_loss: 0.3975 - val_accuracy: 0.7739\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.7892 - val_loss: 0.3990 - val_accuracy: 0.8090\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.3979 - accuracy: 0.8089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████▌                                          | 5/10 [08:33<08:29, 101.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3978671431541443, 0.8089249134063721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1189/40000 [00:00<00:03, 11888.37it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2415/40000 [00:00<00:03, 12103.66it/s]\u001b[A\n",
      "  9%|███████                                                                      | 3647/40000 [00:00<00:02, 12199.23it/s]\u001b[A\n",
      " 12%|█████████▍                                                                   | 4885/40000 [00:00<00:02, 12267.34it/s]\u001b[A\n",
      " 15%|███████████▊                                                                 | 6121/40000 [00:00<00:02, 12297.11it/s]\u001b[A\n",
      " 18%|██████████████▏                                                              | 7358/40000 [00:00<00:02, 12320.80it/s]\u001b[A\n",
      " 21%|████████████████▌                                                            | 8591/40000 [00:00<00:02, 12313.04it/s]\u001b[A\n",
      " 25%|██████████████████▉                                                          | 9829/40000 [00:00<00:02, 12334.04it/s]\u001b[A\n",
      " 28%|█████████████████████                                                       | 11063/40000 [00:00<00:02, 12317.25it/s]\u001b[A\n",
      " 31%|███████████████████████▎                                                    | 12297/40000 [00:01<00:02, 12321.37it/s]\u001b[A\n",
      " 34%|█████████████████████████▋                                                  | 13540/40000 [00:01<00:02, 12352.58it/s]\u001b[A\n",
      " 37%|████████████████████████████                                                | 14777/40000 [00:01<00:02, 12356.05it/s]\u001b[A\n",
      " 40%|██████████████████████████████▍                                             | 16020/40000 [00:01<00:01, 12376.40it/s]\u001b[A\n",
      " 43%|████████████████████████████████▊                                           | 17262/40000 [00:01<00:01, 12387.99it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▏                                        | 18502/40000 [00:01<00:01, 12389.85it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▌                                      | 19741/40000 [00:01<00:01, 12380.41it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▊                                    | 20984/40000 [00:01<00:01, 12394.06it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▏                                 | 22224/40000 [00:01<00:01, 12378.88it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▌                               | 23465/40000 [00:01<00:01, 12385.43it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▉                             | 24707/40000 [00:02<00:01, 12393.30it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▎                          | 25947/40000 [00:02<00:01, 12389.12it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▋                        | 27189/40000 [00:02<00:01, 12395.47it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████                      | 28429/40000 [00:02<00:00, 12390.11it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▎                   | 29670/40000 [00:02<00:00, 12394.83it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▋                 | 30910/40000 [00:02<00:00, 12084.03it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████               | 32121/40000 [00:02<00:00, 12044.98it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▍            | 33365/40000 [00:02<00:00, 12158.80it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▊          | 34606/40000 [00:02<00:00, 12232.82it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████        | 35850/40000 [00:02<00:00, 12294.03it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▍     | 37093/40000 [00:03<00:00, 12331.71it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▊   | 38338/40000 [00:03<00:00, 12364.29it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12318.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 20.2215 - accuracy: 0.2767 - val_loss: 11.6622 - val_accuracy: 0.2664\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 9.6932 - accuracy: 0.3023 - val_loss: 8.7744 - val_accuracy: 0.3138\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 7.1572 - accuracy: 0.3626 - val_loss: 6.4869 - val_accuracy: 0.3761\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 5.3652 - accuracy: 0.4377 - val_loss: 4.9537 - val_accuracy: 0.4392\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.1173 - accuracy: 0.4906 - val_loss: 3.7953 - val_accuracy: 0.4996\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.1855 - accuracy: 0.5313 - val_loss: 2.9384 - val_accuracy: 0.5336\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.4840 - accuracy: 0.5647 - val_loss: 2.2998 - val_accuracy: 0.5720\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.9785 - accuracy: 0.5895 - val_loss: 1.8567 - val_accuracy: 0.5888\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.6242 - accuracy: 0.6084 - val_loss: 1.5236 - val_accuracy: 0.6041\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.3684 - accuracy: 0.6237 - val_loss: 1.2831 - val_accuracy: 0.6224\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.1819 - accuracy: 0.6434 - val_loss: 1.1280 - val_accuracy: 0.6362\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.0484 - accuracy: 0.6628 - val_loss: 1.0092 - val_accuracy: 0.6545\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9466 - accuracy: 0.6817 - val_loss: 0.9176 - val_accuracy: 0.7019\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8711 - accuracy: 0.7015 - val_loss: 0.8530 - val_accuracy: 0.7101\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8148 - accuracy: 0.7203 - val_loss: 0.8082 - val_accuracy: 0.7157\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7716 - accuracy: 0.7365 - val_loss: 0.7660 - val_accuracy: 0.7440\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7407 - accuracy: 0.7502 - val_loss: 0.7364 - val_accuracy: 0.7638\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7163 - accuracy: 0.7616 - val_loss: 0.7217 - val_accuracy: 0.7646\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.7698 - val_loss: 0.7058 - val_accuracy: 0.7347\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.7715 - val_loss: 0.6874 - val_accuracy: 0.7780\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.7821 - val_loss: 0.6851 - val_accuracy: 0.7720\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.7848 - val_loss: 0.6612 - val_accuracy: 0.7907\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.7853 - val_loss: 0.6550 - val_accuracy: 0.7843\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7894 - val_loss: 0.6479 - val_accuracy: 0.7892\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.7930 - val_loss: 0.6398 - val_accuracy: 0.7948\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.7910 - val_loss: 0.6452 - val_accuracy: 0.7713\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.7946 - val_loss: 0.6370 - val_accuracy: 0.7866\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.7955 - val_loss: 0.6315 - val_accuracy: 0.7866\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.7929 - val_loss: 0.6199 - val_accuracy: 0.7948\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.7951 - val_loss: 0.6201 - val_accuracy: 0.7933\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7989 - val_loss: 0.6170 - val_accuracy: 0.7970\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.7967 - val_loss: 0.6132 - val_accuracy: 0.8037\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.7959 - val_loss: 0.6099 - val_accuracy: 0.7970\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.7938 - val_loss: 0.6111 - val_accuracy: 0.7978\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.7972 - val_loss: 0.6222 - val_accuracy: 0.7866\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.7927 - val_loss: 0.6078 - val_accuracy: 0.7974\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.7943 - val_loss: 0.6021 - val_accuracy: 0.7996\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.7972 - val_loss: 0.6073 - val_accuracy: 0.7873\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7924 - val_loss: 0.6199 - val_accuracy: 0.7728\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7961 - val_loss: 0.6085 - val_accuracy: 0.8007\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.7956 - val_loss: 0.6007 - val_accuracy: 0.7933\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.7948 - val_loss: 0.5972 - val_accuracy: 0.7989\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.7979 - val_loss: 0.5983 - val_accuracy: 0.7944\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.7928 - val_loss: 0.5979 - val_accuracy: 0.7955\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.7912 - val_loss: 0.5973 - val_accuracy: 0.7929\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7950 - val_loss: 0.5923 - val_accuracy: 0.7996\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7954 - val_loss: 0.6165 - val_accuracy: 0.7929\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7937 - val_loss: 0.5964 - val_accuracy: 0.7940\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.7961 - val_loss: 0.6086 - val_accuracy: 0.7754\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7933 - val_loss: 0.5918 - val_accuracy: 0.7970\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.7957 - val_loss: 0.5990 - val_accuracy: 0.7918\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7937 - val_loss: 0.6043 - val_accuracy: 0.7993\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.7944 - val_loss: 0.5885 - val_accuracy: 0.8015\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7948 - val_loss: 0.5896 - val_accuracy: 0.7862\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.7954 - val_loss: 0.5912 - val_accuracy: 0.7959\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7945 - val_loss: 0.5861 - val_accuracy: 0.7940\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7932 - val_loss: 0.5838 - val_accuracy: 0.7970\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7933 - val_loss: 0.5886 - val_accuracy: 0.7981\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7938 - val_loss: 0.5882 - val_accuracy: 0.7963\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7928 - val_loss: 0.5836 - val_accuracy: 0.7989\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7957 - val_loss: 0.5897 - val_accuracy: 0.7843\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7940 - val_loss: 0.5941 - val_accuracy: 0.8052\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7953 - val_loss: 0.5792 - val_accuracy: 0.7951\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7935 - val_loss: 0.5976 - val_accuracy: 0.7780\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7955 - val_loss: 0.5777 - val_accuracy: 0.8015\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7945 - val_loss: 0.5793 - val_accuracy: 0.7966\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7923 - val_loss: 0.5801 - val_accuracy: 0.7959\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7944 - val_loss: 0.5803 - val_accuracy: 0.7899\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7931 - val_loss: 0.5817 - val_accuracy: 0.7933\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7941 - val_loss: 0.5788 - val_accuracy: 0.7899\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7949 - val_loss: 0.5758 - val_accuracy: 0.7918\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7931 - val_loss: 0.5777 - val_accuracy: 0.7996\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7922 - val_loss: 0.5762 - val_accuracy: 0.7944\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7932 - val_loss: 0.5877 - val_accuracy: 0.7806\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7921 - val_loss: 0.5859 - val_accuracy: 0.7966\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7940 - val_loss: 0.5758 - val_accuracy: 0.7944\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7942 - val_loss: 0.5769 - val_accuracy: 0.7914\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7929 - val_loss: 0.5763 - val_accuracy: 0.7914\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7931 - val_loss: 0.5741 - val_accuracy: 0.7974\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7946 - val_loss: 0.5748 - val_accuracy: 0.7929\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7923 - val_loss: 0.5713 - val_accuracy: 0.7970\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7928 - val_loss: 0.5734 - val_accuracy: 0.7978\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7940 - val_loss: 0.5747 - val_accuracy: 0.7944\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7937 - val_loss: 0.5717 - val_accuracy: 0.7970\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7931 - val_loss: 0.5757 - val_accuracy: 0.7922\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7923 - val_loss: 0.5828 - val_accuracy: 0.7832\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7914 - val_loss: 0.5756 - val_accuracy: 0.7929\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7935 - val_loss: 0.5755 - val_accuracy: 0.7944\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.7929 - val_loss: 0.5714 - val_accuracy: 0.7981\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7914 - val_loss: 0.5814 - val_accuracy: 0.7866\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7902 - val_loss: 0.5690 - val_accuracy: 0.8000\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7929 - val_loss: 0.5689 - val_accuracy: 0.7985\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7918 - val_loss: 0.5705 - val_accuracy: 0.8007\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7922 - val_loss: 0.5732 - val_accuracy: 0.7937\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7894 - val_loss: 0.5765 - val_accuracy: 0.7925\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7887 - val_loss: 0.5697 - val_accuracy: 0.8000\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7922 - val_loss: 0.5774 - val_accuracy: 0.7896\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7916 - val_loss: 0.5732 - val_accuracy: 0.8075\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7907 - val_loss: 0.5765 - val_accuracy: 0.7989\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7930 - val_loss: 0.5779 - val_accuracy: 0.8019\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7921 - val_loss: 0.5711 - val_accuracy: 0.7978\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7912 - val_loss: 0.5775 - val_accuracy: 0.7993\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7924 - val_loss: 0.5711 - val_accuracy: 0.7896\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7904 - val_loss: 0.5737 - val_accuracy: 0.8011\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7914 - val_loss: 0.5690 - val_accuracy: 0.7985\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7922 - val_loss: 0.5754 - val_accuracy: 0.7981\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7894 - val_loss: 0.5792 - val_accuracy: 0.7817\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7894 - val_loss: 0.5736 - val_accuracy: 0.7933\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7931 - val_loss: 0.5693 - val_accuracy: 0.7888\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7909 - val_loss: 0.5728 - val_accuracy: 0.7843\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7907 - val_loss: 0.5911 - val_accuracy: 0.7869\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7918 - val_loss: 0.5716 - val_accuracy: 0.7948\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7911 - val_loss: 0.5820 - val_accuracy: 0.7869\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7908 - val_loss: 0.5801 - val_accuracy: 0.7873\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7938 - val_loss: 0.5721 - val_accuracy: 0.7896\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7891 - val_loss: 0.5804 - val_accuracy: 0.7799\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7911 - val_loss: 0.5682 - val_accuracy: 0.7989\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7905 - val_loss: 0.5753 - val_accuracy: 0.7974\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7915 - val_loss: 0.5715 - val_accuracy: 0.8045\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7905 - val_loss: 0.5650 - val_accuracy: 0.7948\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7902 - val_loss: 0.5717 - val_accuracy: 0.7836\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7903 - val_loss: 0.5642 - val_accuracy: 0.8004\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7913 - val_loss: 0.5698 - val_accuracy: 0.7963\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7905 - val_loss: 0.5756 - val_accuracy: 0.8015\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7911 - val_loss: 0.5675 - val_accuracy: 0.7966\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7906 - val_loss: 0.5716 - val_accuracy: 0.7981\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7925 - val_loss: 0.5659 - val_accuracy: 0.8004\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7896 - val_loss: 0.5766 - val_accuracy: 0.7769\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7921 - val_loss: 0.5692 - val_accuracy: 0.7918\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7906 - val_loss: 0.5930 - val_accuracy: 0.7720\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7901 - val_loss: 0.5721 - val_accuracy: 0.7918\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7897 - val_loss: 0.5650 - val_accuracy: 0.7974\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7926 - val_loss: 0.5722 - val_accuracy: 0.7940\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7906 - val_loss: 0.5660 - val_accuracy: 0.7981\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7904 - val_loss: 0.5730 - val_accuracy: 0.7832\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7891 - val_loss: 0.5680 - val_accuracy: 0.7922\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7909 - val_loss: 0.5705 - val_accuracy: 0.7888\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7890 - val_loss: 0.5719 - val_accuracy: 0.7918\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7903 - val_loss: 0.5683 - val_accuracy: 0.7877\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7896 - val_loss: 0.5694 - val_accuracy: 0.7974\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7921 - val_loss: 0.5689 - val_accuracy: 0.7918\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7891 - val_loss: 0.5712 - val_accuracy: 0.7896\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7883 - val_loss: 0.5702 - val_accuracy: 0.7914\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7904 - val_loss: 0.5769 - val_accuracy: 0.7892\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7900 - val_loss: 0.5669 - val_accuracy: 0.7989\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7871 - val_loss: 0.5737 - val_accuracy: 0.8019\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7897 - val_loss: 0.5651 - val_accuracy: 0.7959\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7906 - val_loss: 0.5693 - val_accuracy: 0.7836\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7894 - val_loss: 0.5682 - val_accuracy: 0.7836\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7907 - val_loss: 0.5750 - val_accuracy: 0.7937\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.5710 - accuracy: 0.7873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████                                  | 6/10 [10:15<06:47, 101.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5710064172744751, 0.7873323559761047]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1251/40000 [00:00<00:03, 12501.58it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2502/40000 [00:00<00:03, 12390.59it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3743/40000 [00:00<00:02, 12395.60it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4983/40000 [00:00<00:02, 12365.30it/s]\u001b[A\n",
      " 16%|███████████▉                                                                 | 6224/40000 [00:00<00:02, 12379.35it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7462/40000 [00:00<00:02, 12364.01it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8699/40000 [00:00<00:02, 12342.42it/s]\u001b[A\n",
      " 25%|███████████████████▏                                                         | 9939/40000 [00:00<00:02, 12360.26it/s]\u001b[A\n",
      " 28%|█████████████████████▏                                                      | 11176/40000 [00:00<00:02, 12332.77it/s]\u001b[A\n",
      " 31%|███████████████████████▌                                                    | 12411/40000 [00:01<00:02, 12335.83it/s]\u001b[A\n",
      " 34%|█████████████████████████▉                                                  | 13645/40000 [00:01<00:02, 12300.10it/s]\u001b[A\n",
      " 37%|████████████████████████████▎                                               | 14876/40000 [00:01<00:02, 12198.89it/s]\u001b[A\n",
      " 40%|██████████████████████████████▌                                             | 16117/40000 [00:01<00:01, 12261.86it/s]\u001b[A\n",
      " 43%|████████████████████████████████▉                                           | 17349/40000 [00:01<00:01, 12276.81it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▎                                        | 18589/40000 [00:01<00:01, 12311.18it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▋                                      | 19821/40000 [00:01<00:01, 12309.72it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████                                    | 21066/40000 [00:01<00:01, 12349.55it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▍                                 | 22310/40000 [00:01<00:01, 12376.33it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▋                               | 23548/40000 [00:01<00:01, 12365.61it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████                             | 24790/40000 [00:02<00:01, 12380.11it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▍                          | 26029/40000 [00:02<00:01, 12367.04it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▊                        | 27271/40000 [00:02<00:01, 12380.77it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████▏                     | 28511/40000 [00:02<00:00, 12384.11it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▌                   | 29750/40000 [00:02<00:00, 12373.62it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▉                 | 30993/40000 [00:02<00:00, 12389.80it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▏              | 32232/40000 [00:02<00:00, 12227.81it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▌            | 33473/40000 [00:02<00:00, 12280.32it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▉          | 34705/40000 [00:02<00:00, 12291.13it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▎       | 35944/40000 [00:02<00:00, 12318.12it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▋     | 37177/40000 [00:03<00:00, 12302.31it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▉   | 38415/40000 [00:03<00:00, 12323.79it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12328.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 13.1813 - accuracy: 0.2963 - val_loss: 6.8488 - val_accuracy: 0.3231\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 5.8169 - accuracy: 0.3731 - val_loss: 4.4779 - val_accuracy: 0.4310\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.7902 - accuracy: 0.4712 - val_loss: 2.8829 - val_accuracy: 0.5317\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.5049 - accuracy: 0.5622 - val_loss: 1.9688 - val_accuracy: 0.6153\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.7462 - accuracy: 0.6286 - val_loss: 1.4101 - val_accuracy: 0.6575\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.2605 - accuracy: 0.6570 - val_loss: 1.0272 - val_accuracy: 0.6660\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9347 - accuracy: 0.6738 - val_loss: 0.8005 - val_accuracy: 0.6847\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7583 - accuracy: 0.6947 - val_loss: 0.6913 - val_accuracy: 0.7142\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.7121 - val_loss: 0.6503 - val_accuracy: 0.7082\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.7226 - val_loss: 0.6226 - val_accuracy: 0.7366\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.7309 - val_loss: 0.6084 - val_accuracy: 0.7515\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.7323 - val_loss: 0.5970 - val_accuracy: 0.7455\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.7336 - val_loss: 0.5957 - val_accuracy: 0.7463\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7314 - val_loss: 0.5850 - val_accuracy: 0.7466\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7385 - val_loss: 0.5859 - val_accuracy: 0.7466\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7379 - val_loss: 0.5762 - val_accuracy: 0.7496\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7381 - val_loss: 0.5741 - val_accuracy: 0.7519\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7398 - val_loss: 0.5740 - val_accuracy: 0.7146\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7417 - val_loss: 0.5674 - val_accuracy: 0.7496\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7416 - val_loss: 0.5774 - val_accuracy: 0.7500\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7436 - val_loss: 0.5647 - val_accuracy: 0.7541\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7438 - val_loss: 0.5645 - val_accuracy: 0.7646\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7473 - val_loss: 0.5691 - val_accuracy: 0.7187\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7462 - val_loss: 0.5671 - val_accuracy: 0.7590\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7449 - val_loss: 0.5585 - val_accuracy: 0.7541\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7439 - val_loss: 0.5596 - val_accuracy: 0.7511\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7501 - val_loss: 0.5556 - val_accuracy: 0.7567\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7443 - val_loss: 0.5523 - val_accuracy: 0.7444\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7425 - val_loss: 0.5529 - val_accuracy: 0.7340\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7421 - val_loss: 0.5571 - val_accuracy: 0.7701\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7428 - val_loss: 0.5574 - val_accuracy: 0.7757\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7469 - val_loss: 0.5504 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7475 - val_loss: 0.5551 - val_accuracy: 0.7701\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7450 - val_loss: 0.5567 - val_accuracy: 0.7209\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7453 - val_loss: 0.5486 - val_accuracy: 0.7631\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7501 - val_loss: 0.5462 - val_accuracy: 0.7280\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7448 - val_loss: 0.5464 - val_accuracy: 0.7392\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7454 - val_loss: 0.5503 - val_accuracy: 0.7254\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7473 - val_loss: 0.5495 - val_accuracy: 0.7201\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7501 - val_loss: 0.5468 - val_accuracy: 0.7216\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7449 - val_loss: 0.5537 - val_accuracy: 0.7735\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7472 - val_loss: 0.5562 - val_accuracy: 0.7552\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7441 - val_loss: 0.5414 - val_accuracy: 0.7466\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7480 - val_loss: 0.5420 - val_accuracy: 0.7474\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7468 - val_loss: 0.5684 - val_accuracy: 0.7586\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7445 - val_loss: 0.5415 - val_accuracy: 0.7478\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7477 - val_loss: 0.5393 - val_accuracy: 0.7414\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7478 - val_loss: 0.5415 - val_accuracy: 0.7437\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7454 - val_loss: 0.5458 - val_accuracy: 0.7679\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7467 - val_loss: 0.5392 - val_accuracy: 0.7295\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7454 - val_loss: 0.5401 - val_accuracy: 0.7519\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7471 - val_loss: 0.5401 - val_accuracy: 0.7519\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7459 - val_loss: 0.5384 - val_accuracy: 0.7384\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7503 - val_loss: 0.5389 - val_accuracy: 0.7276\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7487 - val_loss: 0.5371 - val_accuracy: 0.7280\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7485 - val_loss: 0.5385 - val_accuracy: 0.7522\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7476 - val_loss: 0.5369 - val_accuracy: 0.7332\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7502 - val_loss: 0.5375 - val_accuracy: 0.7504\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7479 - val_loss: 0.5359 - val_accuracy: 0.7437\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7480 - val_loss: 0.5428 - val_accuracy: 0.7668\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7482 - val_loss: 0.5392 - val_accuracy: 0.7321\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7474 - val_loss: 0.5358 - val_accuracy: 0.7522\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7441 - val_loss: 0.5344 - val_accuracy: 0.7313\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7484 - val_loss: 0.5398 - val_accuracy: 0.7493\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7448 - val_loss: 0.5602 - val_accuracy: 0.7638\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7479 - val_loss: 0.5386 - val_accuracy: 0.7616\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7483 - val_loss: 0.5362 - val_accuracy: 0.7422\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7476 - val_loss: 0.5409 - val_accuracy: 0.7657\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7434 - val_loss: 0.5427 - val_accuracy: 0.7198\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7476 - val_loss: 0.5594 - val_accuracy: 0.7627\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7463 - val_loss: 0.5398 - val_accuracy: 0.7235\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7483 - val_loss: 0.5341 - val_accuracy: 0.7552\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7481 - val_loss: 0.5463 - val_accuracy: 0.7496\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7475 - val_loss: 0.5379 - val_accuracy: 0.7653\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7474 - val_loss: 0.5413 - val_accuracy: 0.7698\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7492 - val_loss: 0.5389 - val_accuracy: 0.7243\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7476 - val_loss: 0.5488 - val_accuracy: 0.7687\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7494 - val_loss: 0.5329 - val_accuracy: 0.7399\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7487 - val_loss: 0.5329 - val_accuracy: 0.7541\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7464 - val_loss: 0.5445 - val_accuracy: 0.7466\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7448 - val_loss: 0.5369 - val_accuracy: 0.7530\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7493 - val_loss: 0.5320 - val_accuracy: 0.7485\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7484 - val_loss: 0.5315 - val_accuracy: 0.7366\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7478 - val_loss: 0.5302 - val_accuracy: 0.7425\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7464 - val_loss: 0.5345 - val_accuracy: 0.7545\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7479 - val_loss: 0.5359 - val_accuracy: 0.7631\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7479 - val_loss: 0.5373 - val_accuracy: 0.7604\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7480 - val_loss: 0.5359 - val_accuracy: 0.7549\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7457 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7476 - val_loss: 0.5314 - val_accuracy: 0.7347\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7478 - val_loss: 0.5434 - val_accuracy: 0.7675\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7489 - val_loss: 0.5423 - val_accuracy: 0.7224\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7474 - val_loss: 0.5297 - val_accuracy: 0.7410\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7501 - val_loss: 0.5332 - val_accuracy: 0.7299\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7467 - val_loss: 0.5337 - val_accuracy: 0.7433\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7505 - val_loss: 0.5313 - val_accuracy: 0.7272\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7448 - val_loss: 0.5324 - val_accuracy: 0.7541\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7467 - val_loss: 0.5411 - val_accuracy: 0.7653\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7482 - val_loss: 0.5291 - val_accuracy: 0.7511\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7463 - val_loss: 0.5292 - val_accuracy: 0.7287\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7476 - val_loss: 0.5309 - val_accuracy: 0.7325\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7464 - val_loss: 0.5302 - val_accuracy: 0.7291\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7512 - val_loss: 0.5299 - val_accuracy: 0.7534\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7484 - val_loss: 0.5318 - val_accuracy: 0.7526\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7472 - val_loss: 0.5386 - val_accuracy: 0.7220\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7467 - val_loss: 0.5314 - val_accuracy: 0.7575\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7490 - val_loss: 0.5365 - val_accuracy: 0.7463\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7487 - val_loss: 0.5285 - val_accuracy: 0.7328\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7457 - val_loss: 0.5313 - val_accuracy: 0.7560\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7494 - val_loss: 0.5353 - val_accuracy: 0.7623\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7483 - val_loss: 0.5306 - val_accuracy: 0.7504\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7482 - val_loss: 0.5312 - val_accuracy: 0.7519\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7439 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7474 - val_loss: 0.5401 - val_accuracy: 0.7690\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7486 - val_loss: 0.5282 - val_accuracy: 0.7362\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7503 - val_loss: 0.5297 - val_accuracy: 0.7358\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7459 - val_loss: 0.5334 - val_accuracy: 0.7642\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7496 - val_loss: 0.5556 - val_accuracy: 0.7619\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7479 - val_loss: 0.5301 - val_accuracy: 0.7407\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7492 - val_loss: 0.5350 - val_accuracy: 0.7631\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7497 - val_loss: 0.5279 - val_accuracy: 0.7291\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7444 - val_loss: 0.5306 - val_accuracy: 0.7563\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7490 - val_loss: 0.5264 - val_accuracy: 0.7422\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7483 - val_loss: 0.5335 - val_accuracy: 0.7440\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7473 - val_loss: 0.5347 - val_accuracy: 0.7642\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7478 - val_loss: 0.5386 - val_accuracy: 0.7291\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7452 - val_loss: 0.5320 - val_accuracy: 0.7522\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7477 - val_loss: 0.5351 - val_accuracy: 0.7265\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7501 - val_loss: 0.5284 - val_accuracy: 0.7299\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7456 - val_loss: 0.5282 - val_accuracy: 0.7519\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7481 - val_loss: 0.5282 - val_accuracy: 0.7507\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7462 - val_loss: 0.5336 - val_accuracy: 0.7608\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7487 - val_loss: 0.5303 - val_accuracy: 0.7582\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7486 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7507 - val_loss: 0.5347 - val_accuracy: 0.7246\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7495 - val_loss: 0.5518 - val_accuracy: 0.7612\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7494 - val_loss: 0.5252 - val_accuracy: 0.7410\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7480 - val_loss: 0.5307 - val_accuracy: 0.7549\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7481 - val_loss: 0.5248 - val_accuracy: 0.7366\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7487 - val_loss: 0.5264 - val_accuracy: 0.7437\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7494 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7483 - val_loss: 0.5272 - val_accuracy: 0.7422\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7501 - val_loss: 0.5260 - val_accuracy: 0.7384\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7467 - val_loss: 0.5300 - val_accuracy: 0.7511\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7481 - val_loss: 0.5353 - val_accuracy: 0.7243\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7467 - val_loss: 0.5300 - val_accuracy: 0.7444\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7480 - val_loss: 0.5326 - val_accuracy: 0.7534\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7499 - val_loss: 0.5303 - val_accuracy: 0.7563\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7493 - val_loss: 0.5444 - val_accuracy: 0.7172\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7487 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.5114 - accuracy: 0.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████▍                         | 7/10 [11:55<05:03, 101.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5114464163780212, 0.7428593039512634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1203/40000 [00:00<00:03, 12021.50it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2406/40000 [00:00<00:03, 11760.89it/s]\u001b[A\n",
      "  9%|██████▉                                                                      | 3630/40000 [00:00<00:03, 11974.83it/s]\u001b[A\n",
      " 12%|█████████▎                                                                   | 4858/40000 [00:00<00:02, 12092.20it/s]\u001b[A\n",
      " 15%|███████████▋                                                                 | 6081/40000 [00:00<00:02, 12138.20it/s]\u001b[A\n",
      " 18%|██████████████                                                               | 7306/40000 [00:00<00:02, 12173.54it/s]\u001b[A\n",
      " 21%|████████████████▍                                                            | 8529/40000 [00:00<00:02, 12191.61it/s]\u001b[A\n",
      " 24%|██████████████████▊                                                          | 9754/40000 [00:00<00:02, 12208.20it/s]\u001b[A\n",
      " 27%|████████████████████▊                                                       | 10975/40000 [00:00<00:02, 12197.00it/s]\u001b[A\n",
      " 30%|███████████████████████▏                                                    | 12196/40000 [00:01<00:02, 12199.38it/s]\u001b[A\n",
      " 34%|█████████████████████████▌                                                  | 13425/40000 [00:01<00:02, 12224.80it/s]\u001b[A\n",
      " 37%|███████████████████████████▊                                                | 14648/40000 [00:01<00:02, 12214.44it/s]\u001b[A\n",
      " 40%|██████████████████████████████▏                                             | 15871/40000 [00:01<00:01, 12217.09it/s]\u001b[A\n",
      " 43%|████████████████████████████████▍                                           | 17098/40000 [00:01<00:01, 12231.23it/s]\u001b[A\n",
      " 46%|██████████████████████████████████▊                                         | 18322/40000 [00:01<00:01, 12218.85it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▏                                      | 19546/40000 [00:01<00:01, 12222.99it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▍                                    | 20772/40000 [00:01<00:01, 12232.01it/s]\u001b[A\n",
      " 55%|█████████████████████████████████████████▊                                  | 22001/40000 [00:01<00:01, 12247.80it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████▏                               | 23230/40000 [00:01<00:01, 12259.09it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████▍                             | 24458/40000 [00:02<00:01, 12262.22it/s]\u001b[A\n",
      " 64%|████████████████████████████████████████████████▊                           | 25686/40000 [00:02<00:01, 12264.87it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████▏                        | 26913/40000 [00:02<00:01, 12262.87it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████▍                      | 28142/40000 [00:02<00:00, 12269.94it/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████▊                    | 29370/40000 [00:02<00:00, 12271.06it/s]\u001b[A\n",
      " 76%|██████████████████████████████████████████████████████████▏                 | 30598/40000 [00:02<00:00, 12265.74it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▍               | 31827/40000 [00:02<00:00, 12272.50it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████▊             | 33055/40000 [00:02<00:00, 12257.72it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████▏          | 34282/40000 [00:02<00:00, 12260.55it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████▍        | 35509/40000 [00:02<00:00, 12256.63it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████▊      | 36738/40000 [00:03<00:00, 12263.51it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████▏   | 37965/40000 [00:03<00:00, 12113.97it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12197.50it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 14.5858 - accuracy: 0.5218 - val_loss: 5.1907 - val_accuracy: 0.5052\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.3749 - accuracy: 0.5331 - val_loss: 3.4060 - val_accuracy: 0.5899\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.9734 - accuracy: 0.6100 - val_loss: 2.3493 - val_accuracy: 0.6646\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.0260 - accuracy: 0.6599 - val_loss: 1.5537 - val_accuracy: 0.6985\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.3099 - accuracy: 0.6943 - val_loss: 0.9776 - val_accuracy: 0.7287\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8700 - accuracy: 0.7302 - val_loss: 0.7033 - val_accuracy: 0.7575\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.7545 - val_loss: 0.5895 - val_accuracy: 0.7619\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7646 - val_loss: 0.5010 - val_accuracy: 0.7761\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7770 - val_loss: 0.4525 - val_accuracy: 0.8019\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7895 - val_loss: 0.4313 - val_accuracy: 0.7996\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.4211 - val_accuracy: 0.7993\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8064 - val_loss: 0.4020 - val_accuracy: 0.8328\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8165 - val_loss: 0.3940 - val_accuracy: 0.7940\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8096 - val_loss: 0.3841 - val_accuracy: 0.8470\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8275 - val_loss: 0.3752 - val_accuracy: 0.8519\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8264 - val_loss: 0.3708 - val_accuracy: 0.8440\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8386 - val_loss: 0.3735 - val_accuracy: 0.8097\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8319 - val_loss: 0.3599 - val_accuracy: 0.8571\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8434 - val_loss: 0.3538 - val_accuracy: 0.8642\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8460 - val_loss: 0.3531 - val_accuracy: 0.8541\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8478 - val_loss: 0.3515 - val_accuracy: 0.8590\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8457 - val_loss: 0.3468 - val_accuracy: 0.8545\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8422 - val_loss: 0.3405 - val_accuracy: 0.8608\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8504 - val_loss: 0.3367 - val_accuracy: 0.8675\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8458 - val_loss: 0.3335 - val_accuracy: 0.8638\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8421 - val_loss: 0.3313 - val_accuracy: 0.8668\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8506 - val_loss: 0.3290 - val_accuracy: 0.8619\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8494 - val_loss: 0.3340 - val_accuracy: 0.8388\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8519 - val_loss: 0.3245 - val_accuracy: 0.8612\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8476 - val_loss: 0.3228 - val_accuracy: 0.8634\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8506 - val_loss: 0.3219 - val_accuracy: 0.8616\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8499 - val_loss: 0.3261 - val_accuracy: 0.8522\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8555 - val_loss: 0.3237 - val_accuracy: 0.8590\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8506 - val_loss: 0.3211 - val_accuracy: 0.8571\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8500 - val_loss: 0.3208 - val_accuracy: 0.8455\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8562 - val_loss: 0.3160 - val_accuracy: 0.8563\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8529 - val_loss: 0.3214 - val_accuracy: 0.8429\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8528 - val_loss: 0.3148 - val_accuracy: 0.8534\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8526 - val_loss: 0.3135 - val_accuracy: 0.8634\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8501 - val_loss: 0.3120 - val_accuracy: 0.8586\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8541 - val_loss: 0.3081 - val_accuracy: 0.8683\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8551 - val_loss: 0.3107 - val_accuracy: 0.8642\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8511 - val_loss: 0.3054 - val_accuracy: 0.8687\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8560 - val_loss: 0.3179 - val_accuracy: 0.8336\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8557 - val_loss: 0.3055 - val_accuracy: 0.8657\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8530 - val_loss: 0.3055 - val_accuracy: 0.8597\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8566 - val_loss: 0.3060 - val_accuracy: 0.8601\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8555 - val_loss: 0.3090 - val_accuracy: 0.8649\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8554 - val_loss: 0.3030 - val_accuracy: 0.8649\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8549 - val_loss: 0.2998 - val_accuracy: 0.8687\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8591 - val_loss: 0.2985 - val_accuracy: 0.8698\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8548 - val_loss: 0.3009 - val_accuracy: 0.8675\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8573 - val_loss: 0.2978 - val_accuracy: 0.8694\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8528 - val_loss: 0.2995 - val_accuracy: 0.8683\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8562 - val_loss: 0.2984 - val_accuracy: 0.8664\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8585 - val_loss: 0.3016 - val_accuracy: 0.8541\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8555 - val_loss: 0.2970 - val_accuracy: 0.8683\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8549 - val_loss: 0.3040 - val_accuracy: 0.8519\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8545 - val_loss: 0.2951 - val_accuracy: 0.8664\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8598 - val_loss: 0.2941 - val_accuracy: 0.8687\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8576 - val_loss: 0.2998 - val_accuracy: 0.8616\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8553 - val_loss: 0.2936 - val_accuracy: 0.8660\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8542 - val_loss: 0.2929 - val_accuracy: 0.8649\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8539 - val_loss: 0.2942 - val_accuracy: 0.8634\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8567 - val_loss: 0.2981 - val_accuracy: 0.8563\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8560 - val_loss: 0.2927 - val_accuracy: 0.8657\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8568 - val_loss: 0.2910 - val_accuracy: 0.8664\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8577 - val_loss: 0.2898 - val_accuracy: 0.8687\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8577 - val_loss: 0.2902 - val_accuracy: 0.8679\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8559 - val_loss: 0.2902 - val_accuracy: 0.8672\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8569 - val_loss: 0.2888 - val_accuracy: 0.8701\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8550 - val_loss: 0.2888 - val_accuracy: 0.8701\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8588 - val_loss: 0.2946 - val_accuracy: 0.8593\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8566 - val_loss: 0.2892 - val_accuracy: 0.8657\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8563 - val_loss: 0.2905 - val_accuracy: 0.8664\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8589 - val_loss: 0.2875 - val_accuracy: 0.8698\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8585 - val_loss: 0.2907 - val_accuracy: 0.8687\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8569 - val_loss: 0.2960 - val_accuracy: 0.8612\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.8566 - val_loss: 0.2868 - val_accuracy: 0.8679\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.8571 - val_loss: 0.2893 - val_accuracy: 0.8649\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8577 - val_loss: 0.2855 - val_accuracy: 0.8705\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.8588 - val_loss: 0.2873 - val_accuracy: 0.8679\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.8589 - val_loss: 0.2885 - val_accuracy: 0.8642\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8586 - val_loss: 0.2986 - val_accuracy: 0.8623\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8574 - val_loss: 0.2849 - val_accuracy: 0.8668\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.8586 - val_loss: 0.2894 - val_accuracy: 0.8653\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8577 - val_loss: 0.2846 - val_accuracy: 0.8672\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.8576 - val_loss: 0.2890 - val_accuracy: 0.8623\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8579 - val_loss: 0.2849 - val_accuracy: 0.8653\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8566 - val_loss: 0.2870 - val_accuracy: 0.8657\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8595 - val_loss: 0.2857 - val_accuracy: 0.8668\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.8546 - val_loss: 0.2864 - val_accuracy: 0.8634\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8575 - val_loss: 0.2847 - val_accuracy: 0.8668\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8579 - val_loss: 0.2825 - val_accuracy: 0.8735\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8589 - val_loss: 0.2880 - val_accuracy: 0.8638\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.8603 - val_loss: 0.2881 - val_accuracy: 0.8653\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8592 - val_loss: 0.2842 - val_accuracy: 0.8675\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8551 - val_loss: 0.2870 - val_accuracy: 0.8653\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8594 - val_loss: 0.2872 - val_accuracy: 0.8619\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8580 - val_loss: 0.2870 - val_accuracy: 0.8660\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8560 - val_loss: 0.2847 - val_accuracy: 0.8675\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8577 - val_loss: 0.2854 - val_accuracy: 0.8675\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2919 - accuracy: 0.8574 - val_loss: 0.2899 - val_accuracy: 0.8623\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8588 - val_loss: 0.2823 - val_accuracy: 0.8660\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.8592 - val_loss: 0.2831 - val_accuracy: 0.8687\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.8571 - val_loss: 0.2819 - val_accuracy: 0.8649\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8568 - val_loss: 0.2804 - val_accuracy: 0.8694\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8590 - val_loss: 0.2818 - val_accuracy: 0.8720\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8585 - val_loss: 0.2886 - val_accuracy: 0.8604\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8586 - val_loss: 0.2837 - val_accuracy: 0.8646\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8589 - val_loss: 0.2816 - val_accuracy: 0.8713\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8598 - val_loss: 0.2818 - val_accuracy: 0.8675\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8587 - val_loss: 0.2833 - val_accuracy: 0.8672\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8591 - val_loss: 0.2809 - val_accuracy: 0.8668\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8570 - val_loss: 0.2800 - val_accuracy: 0.8668\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.8576 - val_loss: 0.2789 - val_accuracy: 0.8720\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8581 - val_loss: 0.2806 - val_accuracy: 0.8690\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8602 - val_loss: 0.2793 - val_accuracy: 0.8679\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8594 - val_loss: 0.2797 - val_accuracy: 0.8690\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.8601 - val_loss: 0.2851 - val_accuracy: 0.8660\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8569 - val_loss: 0.2789 - val_accuracy: 0.8679\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.8598 - val_loss: 0.2838 - val_accuracy: 0.8631\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.8595 - val_loss: 0.2779 - val_accuracy: 0.8728\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8602 - val_loss: 0.2777 - val_accuracy: 0.8724\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.8591 - val_loss: 0.2797 - val_accuracy: 0.8683\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8577 - val_loss: 0.2778 - val_accuracy: 0.8709\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8587 - val_loss: 0.2781 - val_accuracy: 0.8701\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8568 - val_loss: 0.2801 - val_accuracy: 0.8690\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8609 - val_loss: 0.2772 - val_accuracy: 0.8705\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.8585 - val_loss: 0.2777 - val_accuracy: 0.8705\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.8586 - val_loss: 0.2782 - val_accuracy: 0.8709\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.8587 - val_loss: 0.2786 - val_accuracy: 0.8701\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.8571 - val_loss: 0.2886 - val_accuracy: 0.8631\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.8593 - val_loss: 0.2771 - val_accuracy: 0.8731\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.8603 - val_loss: 0.2914 - val_accuracy: 0.8534\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8603 - val_loss: 0.2768 - val_accuracy: 0.8701\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8594 - val_loss: 0.2756 - val_accuracy: 0.8724\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8601 - val_loss: 0.2852 - val_accuracy: 0.8601\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.8581 - val_loss: 0.2764 - val_accuracy: 0.8754\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8594 - val_loss: 0.2793 - val_accuracy: 0.8683\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8584 - val_loss: 0.2758 - val_accuracy: 0.8701\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8604 - val_loss: 0.2775 - val_accuracy: 0.8694\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8598 - val_loss: 0.2828 - val_accuracy: 0.8634\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.8603 - val_loss: 0.2775 - val_accuracy: 0.8675\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8580 - val_loss: 0.2766 - val_accuracy: 0.8709\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.8592 - val_loss: 0.2766 - val_accuracy: 0.8720\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8593 - val_loss: 0.2755 - val_accuracy: 0.8701\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.8605 - val_loss: 0.2765 - val_accuracy: 0.8694\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.8600 - val_loss: 0.2806 - val_accuracy: 0.8679\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.8600 - val_loss: 0.2946 - val_accuracy: 0.8455\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.2986 - accuracy: 0.8429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████                 | 8/10 [13:36<03:22, 101.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.298590749502182, 0.8428668975830078]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1242/40000 [00:00<00:03, 12413.26it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2484/40000 [00:00<00:03, 12366.84it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3721/40000 [00:00<00:02, 12355.74it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4957/40000 [00:00<00:02, 12347.34it/s]\u001b[A\n",
      " 15%|███████████▉                                                                 | 6194/40000 [00:00<00:02, 12352.44it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7430/40000 [00:00<00:02, 12353.58it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8666/40000 [00:00<00:02, 12350.16it/s]\u001b[A\n",
      " 25%|███████████████████                                                          | 9902/40000 [00:00<00:02, 12346.88it/s]\u001b[A\n",
      " 28%|█████████████████████▏                                                      | 11139/40000 [00:00<00:02, 12352.91it/s]\u001b[A\n",
      " 31%|███████████████████████▌                                                    | 12375/40000 [00:01<00:02, 12351.10it/s]\u001b[A\n",
      " 34%|█████████████████████████▊                                                  | 13611/40000 [00:01<00:02, 12352.03it/s]\u001b[A\n",
      " 37%|████████████████████████████▏                                               | 14848/40000 [00:01<00:02, 12356.62it/s]\u001b[A\n",
      " 40%|██████████████████████████████▌                                             | 16090/40000 [00:01<00:01, 12374.03it/s]\u001b[A\n",
      " 43%|████████████████████████████████▉                                           | 17329/40000 [00:01<00:01, 12377.29it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▎                                        | 18567/40000 [00:01<00:01, 12372.00it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▋                                      | 19805/40000 [00:01<00:01, 12365.55it/s]\u001b[A\n",
      " 53%|███████████████████████████████████████▉                                    | 21042/40000 [00:01<00:01, 12360.11it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▎                                 | 22279/40000 [00:01<00:01, 12354.67it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▋                               | 23515/40000 [00:01<00:01, 12350.04it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████                             | 24751/40000 [00:02<00:01, 12351.38it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▍                          | 25987/40000 [00:02<00:01, 12351.42it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▋                        | 27224/40000 [00:02<00:01, 12355.00it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████                      | 28461/40000 [00:02<00:00, 12358.41it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▍                   | 29697/40000 [00:02<00:00, 12225.56it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▊                 | 30930/40000 [00:02<00:00, 12253.88it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████               | 32164/40000 [00:02<00:00, 12279.27it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▍            | 33398/40000 [00:02<00:00, 12295.96it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▊          | 34633/40000 [00:02<00:00, 12311.47it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▏       | 35867/40000 [00:02<00:00, 12318.26it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▍     | 37104/40000 [00:03<00:00, 12332.04it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▊   | 38340/40000 [00:03<00:00, 12339.44it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12337.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 26.4849 - accuracy: 0.4785 - val_loss: 13.2389 - val_accuracy: 0.5284\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 7.4161 - accuracy: 0.5062 - val_loss: 6.0005 - val_accuracy: 0.4854\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 5.4079 - accuracy: 0.5290 - val_loss: 4.8835 - val_accuracy: 0.5384\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.4380 - accuracy: 0.5773 - val_loss: 3.9768 - val_accuracy: 0.5843\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.6170 - accuracy: 0.6078 - val_loss: 3.2022 - val_accuracy: 0.6164\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.8972 - accuracy: 0.6323 - val_loss: 2.5272 - val_accuracy: 0.6384\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.2339 - accuracy: 0.6480 - val_loss: 1.9184 - val_accuracy: 0.6455\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.6615 - accuracy: 0.6585 - val_loss: 1.4227 - val_accuracy: 0.6679\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.2159 - accuracy: 0.6719 - val_loss: 1.0480 - val_accuracy: 0.6847\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9090 - accuracy: 0.6910 - val_loss: 0.8129 - val_accuracy: 0.6951\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.7086 - val_loss: 0.6795 - val_accuracy: 0.7104\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.7242 - val_loss: 0.6188 - val_accuracy: 0.7246\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7349 - val_loss: 0.5850 - val_accuracy: 0.7410\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7410 - val_loss: 0.5736 - val_accuracy: 0.7276\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7493 - val_loss: 0.5547 - val_accuracy: 0.7489\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7563 - val_loss: 0.5507 - val_accuracy: 0.7328\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7542 - val_loss: 0.5332 - val_accuracy: 0.7739\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7597 - val_loss: 0.5342 - val_accuracy: 0.7321\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7653 - val_loss: 0.5282 - val_accuracy: 0.7384\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7635 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7736 - val_loss: 0.5144 - val_accuracy: 0.7713\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7746 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7775 - val_loss: 0.5030 - val_accuracy: 0.7504\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7806 - val_loss: 0.4982 - val_accuracy: 0.7563\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7795 - val_loss: 0.4873 - val_accuracy: 0.7836\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7824 - val_loss: 0.4875 - val_accuracy: 0.7862\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7832 - val_loss: 0.4867 - val_accuracy: 0.7474\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7781 - val_loss: 0.4857 - val_accuracy: 0.7470\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7888 - val_loss: 0.4841 - val_accuracy: 0.7459\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7895 - val_loss: 0.4710 - val_accuracy: 0.7907\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7875 - val_loss: 0.4648 - val_accuracy: 0.8093\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7834 - val_loss: 0.4660 - val_accuracy: 0.7813\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7887 - val_loss: 0.4599 - val_accuracy: 0.8007\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7933 - val_loss: 0.4572 - val_accuracy: 0.7854\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7932 - val_loss: 0.4552 - val_accuracy: 0.8078\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7975 - val_loss: 0.4780 - val_accuracy: 0.7228\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7859 - val_loss: 0.4501 - val_accuracy: 0.7993\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8026 - val_loss: 0.4505 - val_accuracy: 0.8063\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7931 - val_loss: 0.4447 - val_accuracy: 0.8123\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7965 - val_loss: 0.4502 - val_accuracy: 0.7709\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7991 - val_loss: 0.4461 - val_accuracy: 0.7705\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7991 - val_loss: 0.4389 - val_accuracy: 0.8093\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8001 - val_loss: 0.4443 - val_accuracy: 0.7728\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7949 - val_loss: 0.4390 - val_accuracy: 0.7858\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7990 - val_loss: 0.4362 - val_accuracy: 0.8097\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7991 - val_loss: 0.4334 - val_accuracy: 0.8131\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7989 - val_loss: 0.4342 - val_accuracy: 0.8108\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7984 - val_loss: 0.4309 - val_accuracy: 0.8078\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8033 - val_loss: 0.4306 - val_accuracy: 0.8086\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8000 - val_loss: 0.4270 - val_accuracy: 0.8022\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7985 - val_loss: 0.4309 - val_accuracy: 0.7817\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8009 - val_loss: 0.4286 - val_accuracy: 0.7817\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8001 - val_loss: 0.4262 - val_accuracy: 0.7993\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8004 - val_loss: 0.4338 - val_accuracy: 0.7526\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.4212 - val_accuracy: 0.8090\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8022 - val_loss: 0.4598 - val_accuracy: 0.7280\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7977 - val_loss: 0.4291 - val_accuracy: 0.7560\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8040 - val_loss: 0.4201 - val_accuracy: 0.8034\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8035 - val_loss: 0.4150 - val_accuracy: 0.8116\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8039 - val_loss: 0.4225 - val_accuracy: 0.7705\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7982 - val_loss: 0.4280 - val_accuracy: 0.7507\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8024 - val_loss: 0.4143 - val_accuracy: 0.7970\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8035 - val_loss: 0.4150 - val_accuracy: 0.7828\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8029 - val_loss: 0.4162 - val_accuracy: 0.7828\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8015 - val_loss: 0.4171 - val_accuracy: 0.7791\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8053 - val_loss: 0.4451 - val_accuracy: 0.7332\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8039 - val_loss: 0.4129 - val_accuracy: 0.7791\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8066 - val_loss: 0.4124 - val_accuracy: 0.8175\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8045 - val_loss: 0.4235 - val_accuracy: 0.8101\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8040 - val_loss: 0.4181 - val_accuracy: 0.7549\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8034 - val_loss: 0.4092 - val_accuracy: 0.7948\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8030 - val_loss: 0.4094 - val_accuracy: 0.7903\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8079 - val_loss: 0.4092 - val_accuracy: 0.7772\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8011 - val_loss: 0.4074 - val_accuracy: 0.8116\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8052 - val_loss: 0.4102 - val_accuracy: 0.7776\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8028 - val_loss: 0.4062 - val_accuracy: 0.7847\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8050 - val_loss: 0.4058 - val_accuracy: 0.8097\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8052 - val_loss: 0.4128 - val_accuracy: 0.8138\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8028 - val_loss: 0.4195 - val_accuracy: 0.8108\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8045 - val_loss: 0.4043 - val_accuracy: 0.8060\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8027 - val_loss: 0.4038 - val_accuracy: 0.8056\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8060 - val_loss: 0.4032 - val_accuracy: 0.8157\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8042 - val_loss: 0.4066 - val_accuracy: 0.8175\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8035 - val_loss: 0.4062 - val_accuracy: 0.7985\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8008 - val_loss: 0.3996 - val_accuracy: 0.8097\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8031 - val_loss: 0.4004 - val_accuracy: 0.8097\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8037 - val_loss: 0.4026 - val_accuracy: 0.8187\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8040 - val_loss: 0.4127 - val_accuracy: 0.7642\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8062 - val_loss: 0.4141 - val_accuracy: 0.7534\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8057 - val_loss: 0.3998 - val_accuracy: 0.7858\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8068 - val_loss: 0.4010 - val_accuracy: 0.7881\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8039 - val_loss: 0.4064 - val_accuracy: 0.8168\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8042 - val_loss: 0.4021 - val_accuracy: 0.7810\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8051 - val_loss: 0.3990 - val_accuracy: 0.8131\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8054 - val_loss: 0.3981 - val_accuracy: 0.7903\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8057 - val_loss: 0.3974 - val_accuracy: 0.7996\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8035 - val_loss: 0.4000 - val_accuracy: 0.8160\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8043 - val_loss: 0.3965 - val_accuracy: 0.8093\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8064 - val_loss: 0.4008 - val_accuracy: 0.7810\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8056 - val_loss: 0.3957 - val_accuracy: 0.8127\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8049 - val_loss: 0.4034 - val_accuracy: 0.7683\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8067 - val_loss: 0.4008 - val_accuracy: 0.7791\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8048 - val_loss: 0.3954 - val_accuracy: 0.8026\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8033 - val_loss: 0.3986 - val_accuracy: 0.7769\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8021 - val_loss: 0.3954 - val_accuracy: 0.7951\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8055 - val_loss: 0.4031 - val_accuracy: 0.7675\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8072 - val_loss: 0.3980 - val_accuracy: 0.7799\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8040 - val_loss: 0.3952 - val_accuracy: 0.8157\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8081 - val_loss: 0.3933 - val_accuracy: 0.8104\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8038 - val_loss: 0.3995 - val_accuracy: 0.8175\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8055 - val_loss: 0.3960 - val_accuracy: 0.7836\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8056 - val_loss: 0.4028 - val_accuracy: 0.7627\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8063 - val_loss: 0.4024 - val_accuracy: 0.7631\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8050 - val_loss: 0.3938 - val_accuracy: 0.8201\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8053 - val_loss: 0.3928 - val_accuracy: 0.8090\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8059 - val_loss: 0.3937 - val_accuracy: 0.7940\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8033 - val_loss: 0.4123 - val_accuracy: 0.7496\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8061 - val_loss: 0.3928 - val_accuracy: 0.8045\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8056 - val_loss: 0.3915 - val_accuracy: 0.8052\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8047 - val_loss: 0.3917 - val_accuracy: 0.7978\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8066 - val_loss: 0.3977 - val_accuracy: 0.8153\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8072 - val_loss: 0.3916 - val_accuracy: 0.7896\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8042 - val_loss: 0.3933 - val_accuracy: 0.7810\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8030 - val_loss: 0.4018 - val_accuracy: 0.7597\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8047 - val_loss: 0.3955 - val_accuracy: 0.7739\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8034 - val_loss: 0.3904 - val_accuracy: 0.7959\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8055 - val_loss: 0.3926 - val_accuracy: 0.8183\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8067 - val_loss: 0.3915 - val_accuracy: 0.8190\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8063 - val_loss: 0.3946 - val_accuracy: 0.7795\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8037 - val_loss: 0.3949 - val_accuracy: 0.7739\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8066 - val_loss: 0.3901 - val_accuracy: 0.7858\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8042 - val_loss: 0.3915 - val_accuracy: 0.7888\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8047 - val_loss: 0.3934 - val_accuracy: 0.7810\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8047 - val_loss: 0.3996 - val_accuracy: 0.7668\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8047 - val_loss: 0.3936 - val_accuracy: 0.7832\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8077 - val_loss: 0.3893 - val_accuracy: 0.8056\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8075 - val_loss: 0.3905 - val_accuracy: 0.8104\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8074 - val_loss: 0.3932 - val_accuracy: 0.7854\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8056 - val_loss: 0.3908 - val_accuracy: 0.7940\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8068 - val_loss: 0.3930 - val_accuracy: 0.7765\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8071 - val_loss: 0.3954 - val_accuracy: 0.8153\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8037 - val_loss: 0.3946 - val_accuracy: 0.8172\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8059 - val_loss: 0.3986 - val_accuracy: 0.7664\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8050 - val_loss: 0.3953 - val_accuracy: 0.8153\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8025 - val_loss: 0.3900 - val_accuracy: 0.8138\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8038 - val_loss: 0.3894 - val_accuracy: 0.8034\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8062 - val_loss: 0.3886 - val_accuracy: 0.8097\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8056 - val_loss: 0.3887 - val_accuracy: 0.7937\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8044 - val_loss: 0.4011 - val_accuracy: 0.7638\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8063 - val_loss: 0.3900 - val_accuracy: 0.7832\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.3808 - accuracy: 0.7997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████▌        | 9/10 [15:19<01:41, 101.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3808378577232361, 0.7996817827224731]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1242/40000 [00:00<00:03, 12412.67it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2484/40000 [00:00<00:03, 12368.29it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3721/40000 [00:00<00:02, 12312.16it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4956/40000 [00:00<00:02, 12324.56it/s]\u001b[A\n",
      " 15%|███████████▉                                                                 | 6189/40000 [00:00<00:02, 12292.19it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7419/40000 [00:00<00:02, 12277.34it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8652/40000 [00:00<00:02, 12291.35it/s]\u001b[A\n",
      " 25%|███████████████████                                                          | 9882/40000 [00:00<00:02, 12278.93it/s]\u001b[A\n",
      " 28%|█████████████████████                                                       | 11111/40000 [00:00<00:02, 12281.30it/s]\u001b[A\n",
      " 31%|███████████████████████▍                                                    | 12340/40000 [00:01<00:02, 12260.76it/s]\u001b[A\n",
      " 34%|█████████████████████████▊                                                  | 13567/40000 [00:01<00:02, 12261.49it/s]\u001b[A\n",
      " 37%|████████████████████████████                                                | 14796/40000 [00:01<00:02, 12269.38it/s]\u001b[A\n",
      " 40%|██████████████████████████████▍                                             | 16023/40000 [00:01<00:01, 12045.93it/s]\u001b[A\n",
      " 43%|████████████████████████████████▊                                           | 17253/40000 [00:01<00:01, 12120.27it/s]\u001b[A\n",
      " 46%|███████████████████████████████████                                         | 18473/40000 [00:01<00:01, 12141.63it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▍                                      | 19706/40000 [00:01<00:01, 12195.44it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▊                                    | 20933/40000 [00:01<00:01, 12214.74it/s]\u001b[A\n",
      " 55%|██████████████████████████████████████████                                  | 22163/40000 [00:01<00:01, 12239.67it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▍                               | 23401/40000 [00:01<00:01, 12279.61it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▊                             | 24631/40000 [00:02<00:01, 12284.41it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▏                          | 25867/40000 [00:02<00:01, 12306.03it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▍                        | 27098/40000 [00:02<00:01, 12065.20it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▊                      | 28306/40000 [00:02<00:00, 11975.33it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████                    | 29530/40000 [00:02<00:00, 12052.18it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▍                 | 30745/40000 [00:02<00:00, 12079.37it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▋               | 31971/40000 [00:02<00:00, 12132.63it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████             | 33193/40000 [00:02<00:00, 12157.97it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████▍          | 34419/40000 [00:02<00:00, 12187.67it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████▋        | 35643/40000 [00:02<00:00, 12203.19it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████      | 36864/40000 [00:03<00:00, 12192.16it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████▍   | 38093/40000 [00:03<00:00, 12221.09it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12203.75it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 48.1208 - accuracy: 0.2860 - val_loss: 24.2608 - val_accuracy: 0.2698\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 16.8071 - accuracy: 0.2717 - val_loss: 8.5606 - val_accuracy: 0.2627\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 8.0190 - accuracy: 0.2628 - val_loss: 6.7657 - val_accuracy: 0.3000\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 6.3424 - accuracy: 0.3139 - val_loss: 5.2883 - val_accuracy: 0.3530\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.9375 - accuracy: 0.3710 - val_loss: 4.0850 - val_accuracy: 0.4142\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.8110 - accuracy: 0.4306 - val_loss: 3.1409 - val_accuracy: 0.4802\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.9608 - accuracy: 0.4880 - val_loss: 2.4779 - val_accuracy: 0.5187\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 2.3560 - accuracy: 0.5378 - val_loss: 2.0019 - val_accuracy: 0.5713\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.9099 - accuracy: 0.5744 - val_loss: 1.6389 - val_accuracy: 0.6090\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.5693 - accuracy: 0.6063 - val_loss: 1.3771 - val_accuracy: 0.6306\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.3333 - accuracy: 0.6286 - val_loss: 1.1947 - val_accuracy: 0.6384\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.1716 - accuracy: 0.6437 - val_loss: 1.0741 - val_accuracy: 0.6343\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.0537 - accuracy: 0.6544 - val_loss: 0.9702 - val_accuracy: 0.6560\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9610 - accuracy: 0.6666 - val_loss: 0.8938 - val_accuracy: 0.6851\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8865 - accuracy: 0.6787 - val_loss: 0.8365 - val_accuracy: 0.6858\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8310 - accuracy: 0.6949 - val_loss: 0.7924 - val_accuracy: 0.7019\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7909 - accuracy: 0.7115 - val_loss: 0.7736 - val_accuracy: 0.7209\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7630 - accuracy: 0.7276 - val_loss: 0.7424 - val_accuracy: 0.7384\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7468 - accuracy: 0.7406 - val_loss: 0.7311 - val_accuracy: 0.7485\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7348 - accuracy: 0.7508 - val_loss: 0.7247 - val_accuracy: 0.7526\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7255 - accuracy: 0.7544 - val_loss: 0.7154 - val_accuracy: 0.7567\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.7583 - val_loss: 0.7095 - val_accuracy: 0.7634\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7120 - accuracy: 0.7610 - val_loss: 0.7004 - val_accuracy: 0.7687\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.7684 - val_loss: 0.6934 - val_accuracy: 0.7679\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.7690 - val_loss: 0.7213 - val_accuracy: 0.7567\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.7702 - val_loss: 0.6853 - val_accuracy: 0.7780\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.7727 - val_loss: 0.6814 - val_accuracy: 0.7716\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.7775 - val_loss: 0.6779 - val_accuracy: 0.7877\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.7758 - val_loss: 0.6696 - val_accuracy: 0.7761\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.7806 - val_loss: 0.6652 - val_accuracy: 0.7754\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.7810 - val_loss: 0.6640 - val_accuracy: 0.7832\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.7838 - val_loss: 0.6595 - val_accuracy: 0.7776\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.7831 - val_loss: 0.6651 - val_accuracy: 0.7743\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.7865 - val_loss: 0.6451 - val_accuracy: 0.7910\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.7877 - val_loss: 0.6491 - val_accuracy: 0.7810\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.7881 - val_loss: 0.6396 - val_accuracy: 0.7881\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.7891 - val_loss: 0.6294 - val_accuracy: 0.7966\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.7906 - val_loss: 0.6260 - val_accuracy: 0.7918\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.7891 - val_loss: 0.6225 - val_accuracy: 0.7899\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.7928 - val_loss: 0.6232 - val_accuracy: 0.7951\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.7937 - val_loss: 0.6159 - val_accuracy: 0.7993\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.7976 - val_loss: 0.6108 - val_accuracy: 0.7978\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.7975 - val_loss: 0.6087 - val_accuracy: 0.8015\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.7969 - val_loss: 0.6100 - val_accuracy: 0.8034\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.7976 - val_loss: 0.6081 - val_accuracy: 0.7888\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.7981 - val_loss: 0.6032 - val_accuracy: 0.8011\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.8001 - val_loss: 0.6075 - val_accuracy: 0.7918\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.8013 - val_loss: 0.5944 - val_accuracy: 0.8026\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.8016 - val_loss: 0.6001 - val_accuracy: 0.7933\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.8009 - val_loss: 0.5920 - val_accuracy: 0.7996\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.8050 - val_loss: 0.5869 - val_accuracy: 0.8067\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.8040 - val_loss: 0.5855 - val_accuracy: 0.8049\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.8049 - val_loss: 0.5818 - val_accuracy: 0.8063\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.8055 - val_loss: 0.5816 - val_accuracy: 0.8049\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.8061 - val_loss: 0.5834 - val_accuracy: 0.8078\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.8069 - val_loss: 0.5761 - val_accuracy: 0.8086\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.8059 - val_loss: 0.5739 - val_accuracy: 0.8011\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.8076 - val_loss: 0.5708 - val_accuracy: 0.8063\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.8069 - val_loss: 0.5729 - val_accuracy: 0.7985\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.8063 - val_loss: 0.5726 - val_accuracy: 0.8045\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.8090 - val_loss: 0.5697 - val_accuracy: 0.8090\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.8090 - val_loss: 0.5720 - val_accuracy: 0.8060\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.8093 - val_loss: 0.5656 - val_accuracy: 0.8034\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.8083 - val_loss: 0.5606 - val_accuracy: 0.8101\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.8103 - val_loss: 0.5599 - val_accuracy: 0.8127\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.8127 - val_loss: 0.5618 - val_accuracy: 0.8067\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.8125 - val_loss: 0.5604 - val_accuracy: 0.8101\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.8108 - val_loss: 0.5594 - val_accuracy: 0.8071\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.8121 - val_loss: 0.5633 - val_accuracy: 0.8030\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.8129 - val_loss: 0.5581 - val_accuracy: 0.8090\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.8126 - val_loss: 0.5539 - val_accuracy: 0.8131\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.8119 - val_loss: 0.5488 - val_accuracy: 0.8131\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.8125 - val_loss: 0.5474 - val_accuracy: 0.8108\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.8125 - val_loss: 0.5483 - val_accuracy: 0.8090\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.8113 - val_loss: 0.5492 - val_accuracy: 0.8101\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.8143 - val_loss: 0.5474 - val_accuracy: 0.8093\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.8126 - val_loss: 0.5422 - val_accuracy: 0.8116\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.8128 - val_loss: 0.5439 - val_accuracy: 0.8101\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.8144 - val_loss: 0.5389 - val_accuracy: 0.8116\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.8121 - val_loss: 0.5576 - val_accuracy: 0.8022\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.8126 - val_loss: 0.5380 - val_accuracy: 0.8116\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.8146 - val_loss: 0.5387 - val_accuracy: 0.8116\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.8145 - val_loss: 0.5380 - val_accuracy: 0.8127\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.8144 - val_loss: 0.5351 - val_accuracy: 0.8179\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.8149 - val_loss: 0.5366 - val_accuracy: 0.8119\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.8161 - val_loss: 0.5425 - val_accuracy: 0.8056\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.8138 - val_loss: 0.5352 - val_accuracy: 0.8127\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.8161 - val_loss: 0.5314 - val_accuracy: 0.8146\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.8135 - val_loss: 0.5322 - val_accuracy: 0.8112\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.8149 - val_loss: 0.5354 - val_accuracy: 0.8093\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.8130 - val_loss: 0.5318 - val_accuracy: 0.8172\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.8155 - val_loss: 0.5303 - val_accuracy: 0.8168\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.8165 - val_loss: 0.5308 - val_accuracy: 0.8157\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.8147 - val_loss: 0.5287 - val_accuracy: 0.8149\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.8149 - val_loss: 0.5282 - val_accuracy: 0.8142\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.8142 - val_loss: 0.5275 - val_accuracy: 0.8134\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.8169 - val_loss: 0.5285 - val_accuracy: 0.8142\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.8146\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.8167 - val_loss: 0.5224 - val_accuracy: 0.8172\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.8164 - val_loss: 0.5263 - val_accuracy: 0.8146\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.8176 - val_loss: 0.5266 - val_accuracy: 0.8183\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.8151 - val_loss: 0.5208 - val_accuracy: 0.8157\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.8154 - val_loss: 0.5213 - val_accuracy: 0.8142\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8161 - val_loss: 0.5239 - val_accuracy: 0.8172\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.8158 - val_loss: 0.5187 - val_accuracy: 0.8190\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.8165 - val_loss: 0.5204 - val_accuracy: 0.8146\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8164 - val_loss: 0.5196 - val_accuracy: 0.8134\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.8172 - val_loss: 0.5260 - val_accuracy: 0.8119\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.8164 - val_loss: 0.5211 - val_accuracy: 0.8146\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.8169 - val_loss: 0.5159 - val_accuracy: 0.8153\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.8167 - val_loss: 0.5190 - val_accuracy: 0.8172\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.8151 - val_loss: 0.5166 - val_accuracy: 0.8194\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.8149 - val_loss: 0.5191 - val_accuracy: 0.8164\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.8160 - val_loss: 0.5146 - val_accuracy: 0.8172\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.8156 - val_loss: 0.5160 - val_accuracy: 0.8183\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.8176 - val_loss: 0.5201 - val_accuracy: 0.8101\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.8169 - val_loss: 0.5126 - val_accuracy: 0.8149\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8179 - val_loss: 0.5202 - val_accuracy: 0.8142\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8160 - val_loss: 0.5102 - val_accuracy: 0.8179\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.8161 - val_loss: 0.5151 - val_accuracy: 0.8131\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.8161 - val_loss: 0.5172 - val_accuracy: 0.8119\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.8159 - val_loss: 0.5164 - val_accuracy: 0.8149\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.8152 - val_loss: 0.5107 - val_accuracy: 0.8160\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.8163 - val_loss: 0.5103 - val_accuracy: 0.8116\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.8173 - val_loss: 0.5145 - val_accuracy: 0.8086\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.8172 - val_loss: 0.5165 - val_accuracy: 0.8119\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.8169 - val_loss: 0.5114 - val_accuracy: 0.8190\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.8164 - val_loss: 0.5101 - val_accuracy: 0.8205\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8178 - val_loss: 0.5070 - val_accuracy: 0.8198\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.8191 - val_loss: 0.5116 - val_accuracy: 0.8134\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.8154 - val_loss: 0.5253 - val_accuracy: 0.8037\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.8163 - val_loss: 0.5181 - val_accuracy: 0.8112\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8181 - val_loss: 0.5049 - val_accuracy: 0.8179\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.8188 - val_loss: 0.5109 - val_accuracy: 0.8190\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8171 - val_loss: 0.5157 - val_accuracy: 0.8112\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.8161 - val_loss: 0.5086 - val_accuracy: 0.8153\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.8156 - val_loss: 0.5044 - val_accuracy: 0.8172\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8147 - val_loss: 0.5048 - val_accuracy: 0.8172\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8171 - val_loss: 0.5036 - val_accuracy: 0.8175\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8189 - val_loss: 0.5093 - val_accuracy: 0.8149\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8181 - val_loss: 0.5246 - val_accuracy: 0.8160\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8183 - val_loss: 0.5035 - val_accuracy: 0.8190\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8169 - val_loss: 0.5114 - val_accuracy: 0.8134\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8156 - val_loss: 0.5082 - val_accuracy: 0.8179\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8169 - val_loss: 0.5019 - val_accuracy: 0.8149\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8185 - val_loss: 0.5022 - val_accuracy: 0.8134\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8167 - val_loss: 0.5081 - val_accuracy: 0.8131\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8179 - val_loss: 0.5056 - val_accuracy: 0.8149\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8177 - val_loss: 0.5016 - val_accuracy: 0.8160\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.8154 - val_loss: 0.5094 - val_accuracy: 0.8146\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.4987 - accuracy: 0.8266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 10/10 [17:03<00:00, 102.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4987296462059021, 0.8265777826309204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "total_scores = []\n",
    "for i in tqdm(range(10)):\n",
    "    idealized_signals, labels = idealized(num = 10_000)\n",
    "    input_data = np.expand_dims(normalize_data(idealized_signals), axis = -1)\n",
    "    print(input_data[0,:,:].max(), input_data[0,:,:].min())\n",
    "    splits = input_data.shape[0]//1_000\n",
    "    X = []\n",
    "    print(input_data.shape)\n",
    "    for i in range(splits):\n",
    "        tensor = tf.convert_to_tensor(input_data[i*1_000:(i+1)*1_000, :,:,:], dtype=tf.float32)\n",
    "        X.append(autoencoder.encoder(tensor))\n",
    "    X = np.vstack(X)\n",
    "    print(X.shape)\n",
    "    X, labels = absolute_diff(X, labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "    linear = keras.Sequential(name=\"my_sequential\")\n",
    "    linear.add(layers.Dense(4, activation=\"sigmoid\", name=\"layer2\"))\n",
    "\n",
    "    linear.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    linear.fit(X_train, y_train, epochs=150, batch_size=128, validation_split = 0.1, shuffle=True)\n",
    "    results = linear.evaluate(X_test, y_test)\n",
    "    print(results)\n",
    "    total_scores.append(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6bd8485-e07e-4a7e-adaf-6709461d3e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8072278141975403\n",
      "0.04310384533411566\n",
      "tensorflow      WARNING  Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).cluster_loss_tracker.total\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).cluster_loss_tracker.count\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.89\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.90\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.91\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.92\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.93\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.94\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.95\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.96\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.97\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.98\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.99\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.100\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.101\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.102\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.103\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.104\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.105\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.106\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.107\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.108\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.109\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.110\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.111\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.112\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.113\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.114\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.115\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.116\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.117\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.118\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.119\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.120\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.121\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.122\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.123\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.124\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(total_scores))\n",
    "print(np.std(total_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
