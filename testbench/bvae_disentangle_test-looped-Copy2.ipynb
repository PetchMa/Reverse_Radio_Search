{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baed00ee-9461-4560-8813-31a571c86877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 11:33:45.422379: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import setigen as stg\n",
    "from blimpy import Waterfall\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from astropy import units as u\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import silhouette_score\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f020ec-5663-42ab-8527-2b5d37948ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e00c928-f039-4774-8477-10c9e940e2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def painting(data):\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    for c in range(num_classes):\n",
    "        drift = 2*random.random()*(-1)**random.randint(0,2)\n",
    "        snr = random.randint(100, 150)\n",
    "        width = random.randint(20, 50)\n",
    "        for s in range(num_samples_per_class):\n",
    "            index = random.randint(0, data.shape[0]-1)\n",
    "            window = data[index, :,:]\n",
    "            \n",
    "            start = random.randint(50, 180)\n",
    "            \n",
    "            frame = stg.Frame.from_data(df=2.7939677238464355*u.Hz,\n",
    "                                        dt=18.253611008*u.s,\n",
    "                                        fch1=1289*u.MHz,\n",
    "                                        ascending=True,\n",
    "                                        data=window)\n",
    "            frame.add_signal(stg.constant_path(\n",
    "                                        f_start=frame.get_frequency(index=start),\n",
    "                                       drift_rate=drift*u.Hz/u.s),\n",
    "                                      stg.constant_t_profile(level=frame.get_intensity(snr=snr)),\n",
    "                                      stg.gaussian_f_profile(width=width*u.Hz),\n",
    "                                      stg.constant_bp_profile(level=1))\n",
    "            all_data.append(frame.data)\n",
    "            labels.append(c)\n",
    "    all_data = np.array(all_data)\n",
    "    labels = np.vstack(labels)\n",
    "    return all_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e49e4f-15bd-4a32-a6d5-7a3274be3b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f54907-bc05-4c64-a362-5bcc5511de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = 8\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"kl_loss\"\n",
    "        )\n",
    "        self.kl_additional = tf.keras.losses.KLDivergence()\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "        ]\n",
    "    def gaussanity_loss(self, data, base):\n",
    "        return self.kl_additional(data, base)\n",
    "    \n",
    "    def train_step(self, data_in):\n",
    "        data = data_in\n",
    "        print(data.shape)\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            \n",
    "            \n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        \n",
    "        mse_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(mse_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "        }\n",
    "    def test_step(self, data_in):\n",
    "        data, _ = data_in\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss \n",
    "        \n",
    "        mse_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(mse_loss)\n",
    "        return {\n",
    "            \"test_loss\": self.total_loss_tracker.result(),\n",
    "            \"test_kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"test_reconstruction_loss\": self.reconstruction_loss_tracker.result()\n",
    "        }\n",
    "    def __call__ (self, inputs):\n",
    "        return self.decoder(self.encoder(inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4d21f4-47eb-4ec1-a211-13e63440ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531b40be-4015-40db-926c-0e681083194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 11:33:47.517192: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 11:33:47.879534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13888 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:a1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 16, 256, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 256, 32)  320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 16, 128, 32)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 16, 128, 32)  128        ['max_pooling2d[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 128, 64)  18496       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 64, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 64, 64)  256         ['max_pooling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 64, 64)   36928       ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 32, 64)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 32, 64)  256         ['max_pooling2d_2[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 32, 128)  73856       ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0          ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 16, 128)  512        ['max_pooling2d_3[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 16, 128)  147584      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 16, 8, 128)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 8, 128)  512         ['max_pooling2d_4[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 16384)        0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          4194560     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 256)         1024        ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           8224        ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32)          128         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           1056        ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 32)           1056        ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32)          128         ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 32)          128         ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 10)           330         ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 10)           330         ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 10)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,485,812\n",
      "Trainable params: 4,484,276\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "time_samples = 16\n",
    "freq_sample =  256\n",
    "encoder_inputs = keras.Input(shape=(time_samples, freq_sample, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=1, padding=\"same\")(encoder_inputs)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x_shape = x.shape\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(32, activation=\"relu\")(x)\n",
    "z_mean = layers.BatchNormalization()(z_mean)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(z_mean)\n",
    "\n",
    "z_log_var = layers.Dense(32, activation=\"relu\")(x)\n",
    "z_log_var = layers.BatchNormalization()(z_log_var)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(z_log_var)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7131cf6f-ba9a-43ea-8b45-d3f79bd5acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               2816      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16384)             4210688   \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 16384)            65536     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 8, 128)        0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 16, 128)      147584    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 128)      147584    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 16, 32, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 64, 64)       73792     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 16, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 16, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 32, 128, 64)      36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 128, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 16, 128, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 32, 256, 32)      18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 16, 256, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 16, 256, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 16, 256, 1)       289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,706,369\n",
      "Trainable params: 4,672,257\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(256, activation=\"relu\")(latent_inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(x_shape[1]* x_shape[2]* x_shape[3], activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Reshape((x_shape[1], x_shape[2], x_shape[3]))(x)\n",
    "x = layers.Conv2DTranspose(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"linear\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0074643-eba7-4961-aa51-3916eb75c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f4d2edc4f70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = VAE(encoder, decoder)\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3))\n",
    "# autoencoder.load_weights(\"../b-vae/models/full-weights-\"+'07-02-2023-15-19-23')\n",
    "autoencoder.load_weights(\"../b-vae/models/full-weights-\"+'08-23-2023-21-05-49')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df2f403c-1e31-45be-9f8b-44277bc1bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    epsilon = 1\n",
    "    min_val = data.min()\n",
    "    data = data - min_val + epsilon\n",
    "    new_data = np.log(data)\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    final_data = (data - min_val) / (max_val - min_val)\n",
    "    return final_data\n",
    "    \n",
    "def normalize_data(data):\n",
    "    for i in tqdm(range(data.shape[0])):\n",
    "        data[i,:,:] = normalize(data[i,:,:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd2791-b873-4546-a02d-634a8869a439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218b0964-8671-484c-b24f-e9081b651743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def idealized(num=10_000):\n",
    "    drift = drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "    snr = 50*random.random() +20\n",
    "    width = 50*random.random() +20\n",
    "    start = random.randint(50, 180)\n",
    "    data = []\n",
    "    labels = []\n",
    "    for tag in range(4):\n",
    "        label_vec = np.zeros(4)\n",
    "        label_vec[tag] = 1\n",
    "        for i in range(num):\n",
    "            if tag == 0:\n",
    "#             everything but drif\n",
    "                snr = 50*random.random() +20\n",
    "                width = 50*random.random() +20\n",
    "                start = random.randint(50, 180)\n",
    "            elif tag == 1:\n",
    "#             everything but snr\n",
    "                drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "                width = 50*random.random() +20\n",
    "                start = random.randint(50, 180)\n",
    "            elif tag == 2:\n",
    "#             everything but width\n",
    "                drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "                snr = 50*random.random() +20\n",
    "                start = random.randint(50, 180)\n",
    "            elif tag == 3:\n",
    "#             everything but start\n",
    "                drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "                snr = 50*random.random() +20\n",
    "                width = 50*random.random() +20\n",
    "\n",
    "            frame = stg.Frame(fchans=256*u.pixel,\n",
    "                              tchans=16*u.pixel,\n",
    "                              df=2.7939677238464355*u.Hz,\n",
    "                              dt=18.253611008*u.s,\n",
    "                              fch1=6095.214842353016*u.MHz)\n",
    "            noise = frame.add_noise(x_mean=1, noise_type='chi2')\n",
    "            frame.add_signal(stg.constant_path(\n",
    "                                        f_start=frame.get_frequency(index=start),\n",
    "                                       drift_rate=drift*u.Hz/u.s),\n",
    "                                      stg.constant_t_profile(level=frame.get_intensity(snr=snr)),\n",
    "                                      stg.gaussian_f_profile(width=width*u.Hz),\n",
    "                                      stg.constant_bp_profile(level=1))\n",
    "            data.append(frame.data)\n",
    "            labels.append(label_vec)\n",
    "    data = np.array(data)\n",
    "    labels = np.vstack(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bc1f444-120a-4e6c-a5a5-c09da959ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_diff(X, labels):\n",
    "    new_x = []\n",
    "    new_labels = []\n",
    "    one = np.arange(0,10000)\n",
    "    two = np.arange(10000,20000)\n",
    "    three = np.arange(20000,30000)\n",
    "    four = np.arange(30000,40000)\n",
    "    for i in range(X.shape[0] -1):\n",
    "        if np.argmax(labels[i,:]) == np.argmax(labels[i+1,:]): \n",
    "            index = np.argmax(labels[i,:])\n",
    "            if index == 0:\n",
    "                sample = np.random.choice(one, size = 1000)\n",
    "            elif index == 1:\n",
    "                sample = np.random.choice(two, size = 1000)\n",
    "            elif index == 2:\n",
    "                sample = np.random.choice(three, size = 1000)\n",
    "            elif index == 3:\n",
    "                sample = np.random.choice(four, size = 1000)\n",
    "            diff = abs(X[i,:] - X[sample,:])\n",
    "            diff = np.mean(diff, axis = 0)\n",
    "            new_x.append(diff)\n",
    "            new_labels.append(labels[i,:])\n",
    "            \n",
    "    return np.array(new_x), np.vstack(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9549969-98f3-4658-a0f7-ff09b604ff4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/10 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1251/40000 [00:00<00:03, 12502.62it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2502/40000 [00:00<00:03, 12463.05it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3749/40000 [00:00<00:02, 12452.51it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4995/40000 [00:00<00:02, 12445.67it/s]\u001b[A\n",
      " 16%|████████████                                                                 | 6240/40000 [00:00<00:02, 12437.77it/s]\u001b[A\n",
      " 19%|██████████████▍                                                              | 7485/40000 [00:00<00:02, 12441.01it/s]\u001b[A\n",
      " 22%|████████████████▊                                                            | 8730/40000 [00:00<00:02, 12440.08it/s]\u001b[A\n",
      " 25%|███████████████████▏                                                         | 9975/40000 [00:00<00:02, 12436.52it/s]\u001b[A\n",
      " 28%|█████████████████████▎                                                      | 11223/40000 [00:00<00:02, 12449.34it/s]\u001b[A\n",
      " 31%|███████████████████████▋                                                    | 12471/40000 [00:01<00:02, 12456.43it/s]\u001b[A\n",
      " 34%|██████████████████████████                                                  | 13717/40000 [00:01<00:02, 12455.65it/s]\u001b[A\n",
      " 37%|████████████████████████████▍                                               | 14963/40000 [00:01<00:02, 12432.79it/s]\u001b[A\n",
      " 41%|██████████████████████████████▊                                             | 16213/40000 [00:01<00:01, 12452.08it/s]\u001b[A\n",
      " 44%|█████████████████████████████████▏                                          | 17463/40000 [00:01<00:01, 12466.04it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▌                                        | 18712/40000 [00:01<00:01, 12470.43it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▉                                      | 19962/40000 [00:01<00:01, 12476.50it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▎                                   | 21210/40000 [00:01<00:01, 12470.39it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▋                                 | 22458/40000 [00:01<00:01, 12471.40it/s]\u001b[A\n",
      " 59%|█████████████████████████████████████████████                               | 23706/40000 [00:01<00:01, 12462.89it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▍                            | 24953/40000 [00:02<00:01, 12457.59it/s]\u001b[A\n",
      " 66%|█████████████████████████████████████████████████▊                          | 26202/40000 [00:02<00:01, 12466.09it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████▏                       | 27449/40000 [00:02<00:01, 12463.11it/s]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████████▌                     | 28696/40000 [00:02<00:00, 12454.91it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████▉                   | 29943/40000 [00:02<00:00, 12459.22it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████▎                | 31189/40000 [00:02<00:00, 12455.27it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▋              | 32435/40000 [00:02<00:00, 12452.14it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▉            | 33681/40000 [00:02<00:00, 12439.23it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████▎         | 34925/40000 [00:02<00:00, 12439.08it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▋       | 36171/40000 [00:02<00:00, 12443.23it/s]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████     | 37416/40000 [00:03<00:00, 12436.69it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████████████████████████████████████▍  | 38660/40000 [00:03<00:00, 12434.88it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12447.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 11:34:26.234065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2023-08-24 11:34:28.942422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 10)\n",
      "(40000, 4)\n",
      "(39996, 10) (39996, 4)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.2422 - accuracy: 0.4677 - val_loss: 1.0766 - val_accuracy: 0.7328\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9874 - accuracy: 0.7332 - val_loss: 0.9035 - val_accuracy: 0.7459\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8564 - accuracy: 0.7523 - val_loss: 0.8070 - val_accuracy: 0.7511\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7783 - accuracy: 0.7624 - val_loss: 0.7470 - val_accuracy: 0.7422\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7259 - accuracy: 0.7712 - val_loss: 0.7060 - val_accuracy: 0.7739\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.7789 - val_loss: 0.6736 - val_accuracy: 0.7590\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.7807 - val_loss: 0.6526 - val_accuracy: 0.7739\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.7857 - val_loss: 0.6325 - val_accuracy: 0.7780\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.7866 - val_loss: 0.6160 - val_accuracy: 0.7787\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7901 - val_loss: 0.6026 - val_accuracy: 0.7813\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.7908 - val_loss: 0.5919 - val_accuracy: 0.7810\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7923 - val_loss: 0.5843 - val_accuracy: 0.7836\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7936 - val_loss: 0.5750 - val_accuracy: 0.7847\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7967 - val_loss: 0.5678 - val_accuracy: 0.7840\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7986 - val_loss: 0.5618 - val_accuracy: 0.7862\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7984 - val_loss: 0.5557 - val_accuracy: 0.7802\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.8015 - val_loss: 0.5500 - val_accuracy: 0.7914\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.8024 - val_loss: 0.5453 - val_accuracy: 0.7851\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.8034 - val_loss: 0.5425 - val_accuracy: 0.7896\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.8033 - val_loss: 0.5378 - val_accuracy: 0.7903\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.8061 - val_loss: 0.5346 - val_accuracy: 0.7922\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.8071 - val_loss: 0.5312 - val_accuracy: 0.7914\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.8076 - val_loss: 0.5293 - val_accuracy: 0.7873\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8074 - val_loss: 0.5264 - val_accuracy: 0.7937\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.8096 - val_loss: 0.5243 - val_accuracy: 0.7944\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.8104 - val_loss: 0.5219 - val_accuracy: 0.7884\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8108 - val_loss: 0.5191 - val_accuracy: 0.7959\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8108 - val_loss: 0.5178 - val_accuracy: 0.7925\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8121 - val_loss: 0.5172 - val_accuracy: 0.7966\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8122 - val_loss: 0.5153 - val_accuracy: 0.7978\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8124 - val_loss: 0.5141 - val_accuracy: 0.7933\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.8140 - val_loss: 0.5107 - val_accuracy: 0.7970\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.8129 - val_loss: 0.5118 - val_accuracy: 0.7933\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.8135 - val_loss: 0.5098 - val_accuracy: 0.7888\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.8144 - val_loss: 0.5102 - val_accuracy: 0.7993\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8135 - val_loss: 0.5095 - val_accuracy: 0.7993\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8136 - val_loss: 0.5066 - val_accuracy: 0.8004\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.8142 - val_loss: 0.5039 - val_accuracy: 0.7985\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.8148 - val_loss: 0.5054 - val_accuracy: 0.7974\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8151 - val_loss: 0.5041 - val_accuracy: 0.7989\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8156 - val_loss: 0.5011 - val_accuracy: 0.7978\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8181 - val_loss: 0.5019 - val_accuracy: 0.7978\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8171 - val_loss: 0.4996 - val_accuracy: 0.7974\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8162 - val_loss: 0.4987 - val_accuracy: 0.7959\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8157 - val_loss: 0.4998 - val_accuracy: 0.7978\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8169 - val_loss: 0.4974 - val_accuracy: 0.7955\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.8164 - val_loss: 0.4975 - val_accuracy: 0.8000\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8180 - val_loss: 0.4965 - val_accuracy: 0.7955\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8186 - val_loss: 0.4969 - val_accuracy: 0.8007\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8172 - val_loss: 0.4945 - val_accuracy: 0.7985\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.8172 - val_loss: 0.4939 - val_accuracy: 0.8007\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8181 - val_loss: 0.4966 - val_accuracy: 0.8019\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.8196 - val_loss: 0.4928 - val_accuracy: 0.7985\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8199 - val_loss: 0.4923 - val_accuracy: 0.7993\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8181 - val_loss: 0.4948 - val_accuracy: 0.8019\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8186 - val_loss: 0.4915 - val_accuracy: 0.8015\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8191 - val_loss: 0.4906 - val_accuracy: 0.8004\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8183 - val_loss: 0.4901 - val_accuracy: 0.8004\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8194 - val_loss: 0.4932 - val_accuracy: 0.8022\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8198 - val_loss: 0.4911 - val_accuracy: 0.8015\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8200 - val_loss: 0.4895 - val_accuracy: 0.7993\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8204 - val_loss: 0.4895 - val_accuracy: 0.8052\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8203 - val_loss: 0.4880 - val_accuracy: 0.8011\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8206 - val_loss: 0.4877 - val_accuracy: 0.8041\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.8190 - val_loss: 0.4878 - val_accuracy: 0.8049\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8221 - val_loss: 0.4872 - val_accuracy: 0.8015\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8207 - val_loss: 0.4876 - val_accuracy: 0.8052\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8203 - val_loss: 0.4871 - val_accuracy: 0.7996\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8212 - val_loss: 0.4882 - val_accuracy: 0.8037\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.8222 - val_loss: 0.4850 - val_accuracy: 0.8049\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8216 - val_loss: 0.4868 - val_accuracy: 0.8037\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8222 - val_loss: 0.4859 - val_accuracy: 0.8026\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8222 - val_loss: 0.4854 - val_accuracy: 0.8000\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8231 - val_loss: 0.4861 - val_accuracy: 0.8000\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8233 - val_loss: 0.4838 - val_accuracy: 0.8041\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8233 - val_loss: 0.4828 - val_accuracy: 0.8041\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8243 - val_loss: 0.4841 - val_accuracy: 0.8030\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8227 - val_loss: 0.4827 - val_accuracy: 0.8060\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8228 - val_loss: 0.4819 - val_accuracy: 0.8090\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8245 - val_loss: 0.4861 - val_accuracy: 0.7974\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8229 - val_loss: 0.4826 - val_accuracy: 0.8045\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8237 - val_loss: 0.4822 - val_accuracy: 0.8034\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8226 - val_loss: 0.4804 - val_accuracy: 0.8067\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8246 - val_loss: 0.4802 - val_accuracy: 0.8056\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8236 - val_loss: 0.4799 - val_accuracy: 0.8067\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8237 - val_loss: 0.4797 - val_accuracy: 0.8071\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8246 - val_loss: 0.4794 - val_accuracy: 0.8071\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8246 - val_loss: 0.4789 - val_accuracy: 0.8082\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8247 - val_loss: 0.4789 - val_accuracy: 0.8075\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8241 - val_loss: 0.4810 - val_accuracy: 0.8060\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8242 - val_loss: 0.4794 - val_accuracy: 0.8082\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8250 - val_loss: 0.4779 - val_accuracy: 0.8101\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8240 - val_loss: 0.4789 - val_accuracy: 0.8078\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8260 - val_loss: 0.4782 - val_accuracy: 0.8045\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8251 - val_loss: 0.4792 - val_accuracy: 0.8045\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8264 - val_loss: 0.4779 - val_accuracy: 0.8090\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8257 - val_loss: 0.4767 - val_accuracy: 0.8097\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8260 - val_loss: 0.4770 - val_accuracy: 0.8067\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8267 - val_loss: 0.4756 - val_accuracy: 0.8090\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8265 - val_loss: 0.4767 - val_accuracy: 0.8108\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8261 - val_loss: 0.4774 - val_accuracy: 0.8090\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8270 - val_loss: 0.4754 - val_accuracy: 0.8116\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8261 - val_loss: 0.4747 - val_accuracy: 0.8097\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8271 - val_loss: 0.4747 - val_accuracy: 0.8112\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8271 - val_loss: 0.4743 - val_accuracy: 0.8116\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8255 - val_loss: 0.4740 - val_accuracy: 0.8101\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8268 - val_loss: 0.4737 - val_accuracy: 0.8104\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8262 - val_loss: 0.4736 - val_accuracy: 0.8090\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8266 - val_loss: 0.4771 - val_accuracy: 0.8041\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8278 - val_loss: 0.4743 - val_accuracy: 0.8082\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8264 - val_loss: 0.4736 - val_accuracy: 0.8078\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8283 - val_loss: 0.4737 - val_accuracy: 0.8082\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8272 - val_loss: 0.4729 - val_accuracy: 0.8131\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8273 - val_loss: 0.4720 - val_accuracy: 0.8112\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8282 - val_loss: 0.4716 - val_accuracy: 0.8101\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8279 - val_loss: 0.4726 - val_accuracy: 0.8138\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8289 - val_loss: 0.4714 - val_accuracy: 0.8134\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8293 - val_loss: 0.4723 - val_accuracy: 0.8112\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8273 - val_loss: 0.4709 - val_accuracy: 0.8116\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8300 - val_loss: 0.4744 - val_accuracy: 0.8101\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8274 - val_loss: 0.4703 - val_accuracy: 0.8104\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8297 - val_loss: 0.4696 - val_accuracy: 0.8101\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8282 - val_loss: 0.4697 - val_accuracy: 0.8104\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8286 - val_loss: 0.4697 - val_accuracy: 0.8134\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8289 - val_loss: 0.4694 - val_accuracy: 0.8116\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8290 - val_loss: 0.4688 - val_accuracy: 0.8123\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8298 - val_loss: 0.4689 - val_accuracy: 0.8097\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8288 - val_loss: 0.4705 - val_accuracy: 0.8108\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8298 - val_loss: 0.4682 - val_accuracy: 0.8153\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8297 - val_loss: 0.4684 - val_accuracy: 0.8149\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8299 - val_loss: 0.4686 - val_accuracy: 0.8119\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8302 - val_loss: 0.4691 - val_accuracy: 0.8142\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8292 - val_loss: 0.4680 - val_accuracy: 0.8142\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8297 - val_loss: 0.4673 - val_accuracy: 0.8112\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8304 - val_loss: 0.4673 - val_accuracy: 0.8138\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8307 - val_loss: 0.4675 - val_accuracy: 0.8175\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8308 - val_loss: 0.4674 - val_accuracy: 0.8157\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8311 - val_loss: 0.4670 - val_accuracy: 0.8146\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8313 - val_loss: 0.4658 - val_accuracy: 0.8164\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8312 - val_loss: 0.4659 - val_accuracy: 0.8146\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8324 - val_loss: 0.4672 - val_accuracy: 0.8134\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8320 - val_loss: 0.4698 - val_accuracy: 0.8146\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8310 - val_loss: 0.4714 - val_accuracy: 0.8138\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8317 - val_loss: 0.4652 - val_accuracy: 0.8157\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8317 - val_loss: 0.4665 - val_accuracy: 0.8168\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8328 - val_loss: 0.4641 - val_accuracy: 0.8127\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8341 - val_loss: 0.4640 - val_accuracy: 0.8149\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8318 - val_loss: 0.4637 - val_accuracy: 0.8190\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8329 - val_loss: 0.4642 - val_accuracy: 0.8157\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8317 - val_loss: 0.4638 - val_accuracy: 0.8164\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.4591 - accuracy: 0.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                             | 1/10 [01:39<14:59, 99.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45907196402549744, 0.829380989074707]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1187/40000 [00:00<00:03, 11859.69it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2420/40000 [00:00<00:03, 12134.26it/s]\u001b[A\n",
      "  9%|███████                                                                      | 3651/40000 [00:00<00:02, 12211.46it/s]\u001b[A\n",
      " 12%|█████████▍                                                                   | 4881/40000 [00:00<00:02, 12245.61it/s]\u001b[A\n",
      " 15%|███████████▊                                                                 | 6109/40000 [00:00<00:02, 12254.45it/s]\u001b[A\n",
      " 18%|██████████████▏                                                              | 7338/40000 [00:00<00:02, 12266.11it/s]\u001b[A\n",
      " 21%|████████████████▍                                                            | 8565/40000 [00:00<00:02, 12051.25it/s]\u001b[A\n",
      " 24%|██████████████████▊                                                          | 9792/40000 [00:00<00:02, 12118.55it/s]\u001b[A\n",
      " 28%|████████████████████▉                                                       | 11028/40000 [00:00<00:02, 12193.10it/s]\u001b[A\n",
      " 31%|███████████████████████▎                                                    | 12266/40000 [00:01<00:02, 12247.84it/s]\u001b[A\n",
      " 34%|█████████████████████████▋                                                  | 13502/40000 [00:01<00:02, 12281.11it/s]\u001b[A\n",
      " 37%|████████████████████████████                                                | 14738/40000 [00:01<00:02, 12303.91it/s]\u001b[A\n",
      " 40%|██████████████████████████████▎                                             | 15974/40000 [00:01<00:01, 12318.41it/s]\u001b[A\n",
      " 43%|████████████████████████████████▋                                           | 17208/40000 [00:01<00:01, 12323.68it/s]\u001b[A\n",
      " 46%|███████████████████████████████████                                         | 18441/40000 [00:01<00:01, 12304.59it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▍                                      | 19678/40000 [00:01<00:01, 12321.87it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▋                                    | 20911/40000 [00:01<00:01, 12322.57it/s]\u001b[A\n",
      " 55%|██████████████████████████████████████████                                  | 22144/40000 [00:01<00:01, 12314.66it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████▍                               | 23376/40000 [00:01<00:01, 12310.68it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▊                             | 24609/40000 [00:02<00:01, 12315.63it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████                           | 25841/40000 [00:02<00:01, 12312.17it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▍                        | 27075/40000 [00:02<00:01, 12319.66it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▊                      | 28307/40000 [00:02<00:00, 12319.32it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▏                   | 29543/40000 [00:02<00:00, 12330.67it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▍                 | 30777/40000 [00:02<00:00, 12325.29it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▊               | 32010/40000 [00:02<00:00, 12319.11it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▏            | 33242/40000 [00:02<00:00, 12311.34it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████▌          | 34474/40000 [00:02<00:00, 12302.43it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████▊        | 35705/40000 [00:02<00:00, 12294.96it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████▏     | 36939/40000 [00:03<00:00, 12306.45it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████▌   | 38172/40000 [00:03<00:00, 12310.76it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12277.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "(40000, 4)\n",
      "(39996, 10) (39996, 4)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.2341 - accuracy: 0.5260 - val_loss: 0.9973 - val_accuracy: 0.7896\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8667 - accuracy: 0.8188 - val_loss: 0.7609 - val_accuracy: 0.8541\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.8567 - val_loss: 0.6304 - val_accuracy: 0.8728\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.8737 - val_loss: 0.5471 - val_accuracy: 0.8933\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.8837 - val_loss: 0.4923 - val_accuracy: 0.9015\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8916 - val_loss: 0.4502 - val_accuracy: 0.9056\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8958 - val_loss: 0.4198 - val_accuracy: 0.9097\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.9007 - val_loss: 0.3951 - val_accuracy: 0.9112\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.9022 - val_loss: 0.3743 - val_accuracy: 0.9134\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.9058 - val_loss: 0.3576 - val_accuracy: 0.9164\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.9084 - val_loss: 0.3423 - val_accuracy: 0.9168\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.9096 - val_loss: 0.3313 - val_accuracy: 0.9209\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.9116 - val_loss: 0.3195 - val_accuracy: 0.9160\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.9135 - val_loss: 0.3105 - val_accuracy: 0.9201\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.9156 - val_loss: 0.3027 - val_accuracy: 0.9216\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.9171 - val_loss: 0.2951 - val_accuracy: 0.9235\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.9178 - val_loss: 0.2893 - val_accuracy: 0.9224\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.9181 - val_loss: 0.2840 - val_accuracy: 0.9276\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.9203 - val_loss: 0.2801 - val_accuracy: 0.9302\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.9211 - val_loss: 0.2728 - val_accuracy: 0.9284\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.9220 - val_loss: 0.2686 - val_accuracy: 0.9276\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.9232 - val_loss: 0.2657 - val_accuracy: 0.9313\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.9244 - val_loss: 0.2597 - val_accuracy: 0.9291\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9252 - val_loss: 0.2587 - val_accuracy: 0.9336\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.9254 - val_loss: 0.2571 - val_accuracy: 0.9340\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.9266 - val_loss: 0.2528 - val_accuracy: 0.9351\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.9273 - val_loss: 0.2499 - val_accuracy: 0.9340\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.9280 - val_loss: 0.2499 - val_accuracy: 0.9369\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9283 - val_loss: 0.2434 - val_accuracy: 0.9351\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.9298 - val_loss: 0.2408 - val_accuracy: 0.9332\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.9302 - val_loss: 0.2397 - val_accuracy: 0.9347\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9306 - val_loss: 0.2366 - val_accuracy: 0.9325\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.9308 - val_loss: 0.2371 - val_accuracy: 0.9369\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.9316 - val_loss: 0.2345 - val_accuracy: 0.9373\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.9315 - val_loss: 0.2331 - val_accuracy: 0.9373\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9318 - val_loss: 0.2337 - val_accuracy: 0.9388\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9325 - val_loss: 0.2287 - val_accuracy: 0.9336\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9334 - val_loss: 0.2285 - val_accuracy: 0.9377\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9329 - val_loss: 0.2272 - val_accuracy: 0.9366\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9342 - val_loss: 0.2258 - val_accuracy: 0.9347\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9332 - val_loss: 0.2251 - val_accuracy: 0.9377\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9340 - val_loss: 0.2236 - val_accuracy: 0.9362\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9329 - val_loss: 0.2234 - val_accuracy: 0.9369\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9346 - val_loss: 0.2222 - val_accuracy: 0.9362\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9348 - val_loss: 0.2204 - val_accuracy: 0.9332\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9344 - val_loss: 0.2204 - val_accuracy: 0.9358\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.9351 - val_loss: 0.2201 - val_accuracy: 0.9366\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9353 - val_loss: 0.2203 - val_accuracy: 0.9377\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2331 - accuracy: 0.9354 - val_loss: 0.2186 - val_accuracy: 0.9366\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9352 - val_loss: 0.2176 - val_accuracy: 0.9369\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9351 - val_loss: 0.2159 - val_accuracy: 0.9336\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.9350 - val_loss: 0.2163 - val_accuracy: 0.9358\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9363 - val_loss: 0.2165 - val_accuracy: 0.9369\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9351 - val_loss: 0.2158 - val_accuracy: 0.9377\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.9364 - val_loss: 0.2143 - val_accuracy: 0.9354\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.9359 - val_loss: 0.2166 - val_accuracy: 0.9392\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9367 - val_loss: 0.2138 - val_accuracy: 0.9343\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9364 - val_loss: 0.2134 - val_accuracy: 0.9358\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9361 - val_loss: 0.2128 - val_accuracy: 0.9362\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9368 - val_loss: 0.2123 - val_accuracy: 0.9354\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9367 - val_loss: 0.2112 - val_accuracy: 0.9347\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9363 - val_loss: 0.2108 - val_accuracy: 0.9332\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.9367 - val_loss: 0.2120 - val_accuracy: 0.9373\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9364 - val_loss: 0.2100 - val_accuracy: 0.9336\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9374 - val_loss: 0.2096 - val_accuracy: 0.9317\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9372 - val_loss: 0.2091 - val_accuracy: 0.9317\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9374 - val_loss: 0.2085 - val_accuracy: 0.9332\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9370 - val_loss: 0.2107 - val_accuracy: 0.9373\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9373 - val_loss: 0.2092 - val_accuracy: 0.9340\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9378 - val_loss: 0.2075 - val_accuracy: 0.9284\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9369 - val_loss: 0.2074 - val_accuracy: 0.9369\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9378 - val_loss: 0.2076 - val_accuracy: 0.9343\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9377 - val_loss: 0.2074 - val_accuracy: 0.9351\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9377 - val_loss: 0.2063 - val_accuracy: 0.9354\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9375 - val_loss: 0.2085 - val_accuracy: 0.9362\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9378 - val_loss: 0.2055 - val_accuracy: 0.9306\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9381 - val_loss: 0.2056 - val_accuracy: 0.9362\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9382 - val_loss: 0.2062 - val_accuracy: 0.9369\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9383 - val_loss: 0.2067 - val_accuracy: 0.9373\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9368 - val_loss: 0.2057 - val_accuracy: 0.9373\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9382 - val_loss: 0.2057 - val_accuracy: 0.9369\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9377 - val_loss: 0.2053 - val_accuracy: 0.9373\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9383 - val_loss: 0.2088 - val_accuracy: 0.9373\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9370 - val_loss: 0.2053 - val_accuracy: 0.9373\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9373 - val_loss: 0.2046 - val_accuracy: 0.9366\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9375 - val_loss: 0.2049 - val_accuracy: 0.9366\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9390 - val_loss: 0.2039 - val_accuracy: 0.9366\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9381 - val_loss: 0.2042 - val_accuracy: 0.9373\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9375 - val_loss: 0.2028 - val_accuracy: 0.9366\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9381 - val_loss: 0.2035 - val_accuracy: 0.9358\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.9382 - val_loss: 0.2027 - val_accuracy: 0.9366\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9385 - val_loss: 0.2033 - val_accuracy: 0.9388\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9383 - val_loss: 0.2031 - val_accuracy: 0.9369\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9381 - val_loss: 0.2023 - val_accuracy: 0.9328\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9379 - val_loss: 0.2020 - val_accuracy: 0.9343\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9379 - val_loss: 0.2022 - val_accuracy: 0.9377\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9381 - val_loss: 0.2027 - val_accuracy: 0.9384\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9381 - val_loss: 0.2032 - val_accuracy: 0.9384\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9384 - val_loss: 0.2020 - val_accuracy: 0.9369\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9383 - val_loss: 0.2018 - val_accuracy: 0.9377\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9393 - val_loss: 0.2011 - val_accuracy: 0.9373\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9388 - val_loss: 0.2017 - val_accuracy: 0.9373\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9378 - val_loss: 0.2022 - val_accuracy: 0.9377\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9385 - val_loss: 0.2007 - val_accuracy: 0.9325\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9382 - val_loss: 0.1998 - val_accuracy: 0.9328\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9382 - val_loss: 0.2004 - val_accuracy: 0.9366\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9384 - val_loss: 0.1997 - val_accuracy: 0.9358\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9381 - val_loss: 0.1997 - val_accuracy: 0.9377\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9386 - val_loss: 0.1997 - val_accuracy: 0.9362\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9387 - val_loss: 0.1996 - val_accuracy: 0.9351\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9387 - val_loss: 0.2007 - val_accuracy: 0.9377\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9385 - val_loss: 0.1996 - val_accuracy: 0.9343\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9381 - val_loss: 0.2017 - val_accuracy: 0.9381\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9379 - val_loss: 0.2010 - val_accuracy: 0.9388\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9390 - val_loss: 0.2009 - val_accuracy: 0.9392\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9392 - val_loss: 0.1991 - val_accuracy: 0.9369\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9380 - val_loss: 0.1986 - val_accuracy: 0.9373\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9389 - val_loss: 0.1989 - val_accuracy: 0.9384\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9393 - val_loss: 0.1983 - val_accuracy: 0.9373\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9382 - val_loss: 0.1994 - val_accuracy: 0.9377\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9386 - val_loss: 0.1995 - val_accuracy: 0.9392\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9395 - val_loss: 0.1981 - val_accuracy: 0.9369\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9391 - val_loss: 0.1989 - val_accuracy: 0.9358\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9384 - val_loss: 0.1996 - val_accuracy: 0.9384\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9388 - val_loss: 0.1983 - val_accuracy: 0.9377\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9389 - val_loss: 0.1987 - val_accuracy: 0.9354\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9389 - val_loss: 0.1977 - val_accuracy: 0.9373\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9391 - val_loss: 0.1992 - val_accuracy: 0.9388\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9394 - val_loss: 0.1988 - val_accuracy: 0.9384\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9389 - val_loss: 0.1990 - val_accuracy: 0.9381\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9387 - val_loss: 0.1982 - val_accuracy: 0.9381\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9385 - val_loss: 0.1975 - val_accuracy: 0.9351\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9387 - val_loss: 0.1965 - val_accuracy: 0.9366\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9383 - val_loss: 0.1968 - val_accuracy: 0.9369\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9393 - val_loss: 0.1981 - val_accuracy: 0.9381\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9391 - val_loss: 0.1994 - val_accuracy: 0.9388\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9395 - val_loss: 0.1977 - val_accuracy: 0.9381\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9393 - val_loss: 0.1976 - val_accuracy: 0.9392\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9390 - val_loss: 0.1967 - val_accuracy: 0.9381\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9392 - val_loss: 0.1968 - val_accuracy: 0.9388\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9390 - val_loss: 0.1968 - val_accuracy: 0.9384\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9393 - val_loss: 0.1991 - val_accuracy: 0.9392\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9389 - val_loss: 0.1967 - val_accuracy: 0.9388\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9388 - val_loss: 0.1978 - val_accuracy: 0.9388\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9394 - val_loss: 0.1969 - val_accuracy: 0.9384\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9393 - val_loss: 0.1957 - val_accuracy: 0.9369\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9391 - val_loss: 0.1985 - val_accuracy: 0.9403\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9391 - val_loss: 0.1952 - val_accuracy: 0.9343\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9390 - val_loss: 0.1958 - val_accuracy: 0.9384\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9390 - val_loss: 0.1979 - val_accuracy: 0.9392\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.2207 - accuracy: 0.9415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▏                                                                    | 2/10 [03:18<13:12, 99.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2207029014825821, 0.9415107369422913]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1249/40000 [00:00<00:03, 12482.33it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2498/40000 [00:00<00:03, 12383.50it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3737/40000 [00:00<00:02, 12335.23it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4971/40000 [00:00<00:02, 12308.86it/s]\u001b[A\n",
      " 16%|███████████▉                                                                 | 6209/40000 [00:00<00:02, 12332.82it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7443/40000 [00:00<00:02, 12313.25it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8675/40000 [00:00<00:02, 12301.72it/s]\u001b[A\n",
      " 25%|███████████████████                                                          | 9909/40000 [00:00<00:02, 12311.54it/s]\u001b[A\n",
      " 28%|█████████████████████▏                                                      | 11143/40000 [00:00<00:02, 12320.17it/s]\u001b[A\n",
      " 31%|███████████████████████▌                                                    | 12379/40000 [00:01<00:02, 12331.24it/s]\u001b[A\n",
      " 34%|█████████████████████████▊                                                  | 13616/40000 [00:01<00:02, 12341.70it/s]\u001b[A\n",
      " 37%|████████████████████████████▏                                               | 14860/40000 [00:01<00:02, 12370.72it/s]\u001b[A\n",
      " 40%|██████████████████████████████▌                                             | 16100/40000 [00:01<00:01, 12378.10it/s]\u001b[A\n",
      " 43%|████████████████████████████████▉                                           | 17339/40000 [00:01<00:01, 12381.45it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▎                                        | 18578/40000 [00:01<00:01, 12379.84it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▋                                      | 19817/40000 [00:01<00:01, 12381.57it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████                                    | 21056/40000 [00:01<00:01, 12371.99it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▎                                 | 22294/40000 [00:01<00:01, 12359.18it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▋                               | 23530/40000 [00:01<00:01, 12352.53it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████                             | 24766/40000 [00:02<00:01, 12345.33it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▍                          | 26001/40000 [00:02<00:01, 12337.03it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▋                        | 27235/40000 [00:02<00:01, 12326.19it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████                      | 28468/40000 [00:02<00:00, 12323.81it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▍                   | 29701/40000 [00:02<00:00, 12316.79it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▊                 | 30933/40000 [00:02<00:00, 12316.66it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████               | 32166/40000 [00:02<00:00, 12320.54it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▍            | 33399/40000 [00:02<00:00, 12322.08it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▊          | 34632/40000 [00:02<00:00, 12323.95it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▏       | 35866/40000 [00:02<00:00, 12327.35it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▍     | 37099/40000 [00:03<00:00, 12281.85it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▊   | 38331/40000 [00:03<00:00, 12292.48it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12328.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "(40000, 4)\n",
      "(39996, 10) (39996, 4)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.2134 - accuracy: 0.5334 - val_loss: 1.0410 - val_accuracy: 0.7239\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9423 - accuracy: 0.7629 - val_loss: 0.8570 - val_accuracy: 0.7951\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8050 - accuracy: 0.8072 - val_loss: 0.7537 - val_accuracy: 0.8149\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.8225 - val_loss: 0.6842 - val_accuracy: 0.8321\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.8299 - val_loss: 0.6361 - val_accuracy: 0.8321\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.8355 - val_loss: 0.5999 - val_accuracy: 0.8343\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.8387 - val_loss: 0.5685 - val_accuracy: 0.8455\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.8421 - val_loss: 0.5454 - val_accuracy: 0.8474\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.8433 - val_loss: 0.5260 - val_accuracy: 0.8507\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8460 - val_loss: 0.5117 - val_accuracy: 0.8433\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8461 - val_loss: 0.4962 - val_accuracy: 0.8526\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8486 - val_loss: 0.4850 - val_accuracy: 0.8489\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8479 - val_loss: 0.4746 - val_accuracy: 0.8500\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8494 - val_loss: 0.4695 - val_accuracy: 0.8448\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8509 - val_loss: 0.4582 - val_accuracy: 0.8526\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8513 - val_loss: 0.4521 - val_accuracy: 0.8507\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8514 - val_loss: 0.4464 - val_accuracy: 0.8470\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8517 - val_loss: 0.4399 - val_accuracy: 0.8563\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8526 - val_loss: 0.4379 - val_accuracy: 0.8478\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8530 - val_loss: 0.4303 - val_accuracy: 0.8507\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8546 - val_loss: 0.4261 - val_accuracy: 0.8549\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8546 - val_loss: 0.4220 - val_accuracy: 0.8563\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8557 - val_loss: 0.4196 - val_accuracy: 0.8534\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8555 - val_loss: 0.4163 - val_accuracy: 0.8590\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8570 - val_loss: 0.4130 - val_accuracy: 0.8567\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8574 - val_loss: 0.4103 - val_accuracy: 0.8537\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8573 - val_loss: 0.4079 - val_accuracy: 0.8556\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8573 - val_loss: 0.4065 - val_accuracy: 0.8515\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8587 - val_loss: 0.4083 - val_accuracy: 0.8511\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8574 - val_loss: 0.4015 - val_accuracy: 0.8537\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8578 - val_loss: 0.3996 - val_accuracy: 0.8552\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8580 - val_loss: 0.3983 - val_accuracy: 0.8537\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8589 - val_loss: 0.3967 - val_accuracy: 0.8552\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8584 - val_loss: 0.3946 - val_accuracy: 0.8582\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8595 - val_loss: 0.3942 - val_accuracy: 0.8563\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8596 - val_loss: 0.3937 - val_accuracy: 0.8619\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8608 - val_loss: 0.3915 - val_accuracy: 0.8575\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8598 - val_loss: 0.3895 - val_accuracy: 0.8578\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8611 - val_loss: 0.3905 - val_accuracy: 0.8563\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8612 - val_loss: 0.3885 - val_accuracy: 0.8586\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8616 - val_loss: 0.3869 - val_accuracy: 0.8608\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8611 - val_loss: 0.3861 - val_accuracy: 0.8601\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8612 - val_loss: 0.3856 - val_accuracy: 0.8593\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8614 - val_loss: 0.3838 - val_accuracy: 0.8601\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8612 - val_loss: 0.3834 - val_accuracy: 0.8586\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8617 - val_loss: 0.3827 - val_accuracy: 0.8608\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8617 - val_loss: 0.3839 - val_accuracy: 0.8649\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8618 - val_loss: 0.3867 - val_accuracy: 0.8549\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8619 - val_loss: 0.3817 - val_accuracy: 0.8623\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8613 - val_loss: 0.3809 - val_accuracy: 0.8616\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8622 - val_loss: 0.3803 - val_accuracy: 0.8638\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8619 - val_loss: 0.3850 - val_accuracy: 0.8556\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8612 - val_loss: 0.3789 - val_accuracy: 0.8604\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8631 - val_loss: 0.3824 - val_accuracy: 0.8571\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8623 - val_loss: 0.3773 - val_accuracy: 0.8631\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8628 - val_loss: 0.3774 - val_accuracy: 0.8623\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8625 - val_loss: 0.3766 - val_accuracy: 0.8623\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8628 - val_loss: 0.3759 - val_accuracy: 0.8623\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8625 - val_loss: 0.3769 - val_accuracy: 0.8604\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8624 - val_loss: 0.3756 - val_accuracy: 0.8668\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8619 - val_loss: 0.3743 - val_accuracy: 0.8619\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8619 - val_loss: 0.3753 - val_accuracy: 0.8623\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8620 - val_loss: 0.3739 - val_accuracy: 0.8642\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8637 - val_loss: 0.3739 - val_accuracy: 0.8653\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8635 - val_loss: 0.3745 - val_accuracy: 0.8597\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8621 - val_loss: 0.3750 - val_accuracy: 0.8627\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8623 - val_loss: 0.3728 - val_accuracy: 0.8664\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8637 - val_loss: 0.3727 - val_accuracy: 0.8668\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8637 - val_loss: 0.3719 - val_accuracy: 0.8672\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8633 - val_loss: 0.3722 - val_accuracy: 0.8672\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8633 - val_loss: 0.3723 - val_accuracy: 0.8634\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8636 - val_loss: 0.3723 - val_accuracy: 0.8687\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8637 - val_loss: 0.3724 - val_accuracy: 0.8646\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8638 - val_loss: 0.3714 - val_accuracy: 0.8672\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8640 - val_loss: 0.3720 - val_accuracy: 0.8634\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8640 - val_loss: 0.3714 - val_accuracy: 0.8634\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8644 - val_loss: 0.3703 - val_accuracy: 0.8642\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8636 - val_loss: 0.3694 - val_accuracy: 0.8657\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8628 - val_loss: 0.3707 - val_accuracy: 0.8653\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8641 - val_loss: 0.3708 - val_accuracy: 0.8664\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8626 - val_loss: 0.3691 - val_accuracy: 0.8634\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8641 - val_loss: 0.3700 - val_accuracy: 0.8646\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8628 - val_loss: 0.3683 - val_accuracy: 0.8672\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8630 - val_loss: 0.3698 - val_accuracy: 0.8642\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8628 - val_loss: 0.3692 - val_accuracy: 0.8634\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8633 - val_loss: 0.3685 - val_accuracy: 0.8657\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8648 - val_loss: 0.3704 - val_accuracy: 0.8616\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8645 - val_loss: 0.3684 - val_accuracy: 0.8660\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8629 - val_loss: 0.3686 - val_accuracy: 0.8664\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8642 - val_loss: 0.3671 - val_accuracy: 0.8675\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8640 - val_loss: 0.3671 - val_accuracy: 0.8660\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8643 - val_loss: 0.3672 - val_accuracy: 0.8664\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8637 - val_loss: 0.3674 - val_accuracy: 0.8672\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8651 - val_loss: 0.3670 - val_accuracy: 0.8672\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8646 - val_loss: 0.3665 - val_accuracy: 0.8675\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8646 - val_loss: 0.3667 - val_accuracy: 0.8664\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8642 - val_loss: 0.3677 - val_accuracy: 0.8642\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8644 - val_loss: 0.3672 - val_accuracy: 0.8646\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8642 - val_loss: 0.3685 - val_accuracy: 0.8627\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8637 - val_loss: 0.3672 - val_accuracy: 0.8657\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8643 - val_loss: 0.3669 - val_accuracy: 0.8646\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8650 - val_loss: 0.3651 - val_accuracy: 0.8690\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8650 - val_loss: 0.3676 - val_accuracy: 0.8638\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8638 - val_loss: 0.3653 - val_accuracy: 0.8668\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8650 - val_loss: 0.3657 - val_accuracy: 0.8653\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8642 - val_loss: 0.3648 - val_accuracy: 0.8701\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8648 - val_loss: 0.3646 - val_accuracy: 0.8687\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8650 - val_loss: 0.3650 - val_accuracy: 0.8664\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8653 - val_loss: 0.3686 - val_accuracy: 0.8601\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8655 - val_loss: 0.3644 - val_accuracy: 0.8679\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8652 - val_loss: 0.3653 - val_accuracy: 0.8675\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8650 - val_loss: 0.3667 - val_accuracy: 0.8664\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8642 - val_loss: 0.3652 - val_accuracy: 0.8657\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8643 - val_loss: 0.3663 - val_accuracy: 0.8660\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8650 - val_loss: 0.3636 - val_accuracy: 0.8683\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8650 - val_loss: 0.3639 - val_accuracy: 0.8709\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8652 - val_loss: 0.3640 - val_accuracy: 0.8672\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8645 - val_loss: 0.3636 - val_accuracy: 0.8694\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8657 - val_loss: 0.3632 - val_accuracy: 0.8690\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8645 - val_loss: 0.3638 - val_accuracy: 0.8668\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8646 - val_loss: 0.3634 - val_accuracy: 0.8705\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8648 - val_loss: 0.3634 - val_accuracy: 0.8675\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8643 - val_loss: 0.3635 - val_accuracy: 0.8716\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8657 - val_loss: 0.3637 - val_accuracy: 0.8668\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8650 - val_loss: 0.3635 - val_accuracy: 0.8672\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8659 - val_loss: 0.3634 - val_accuracy: 0.8672\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8654 - val_loss: 0.3637 - val_accuracy: 0.8664\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8651 - val_loss: 0.3640 - val_accuracy: 0.8668\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8648 - val_loss: 0.3633 - val_accuracy: 0.8668\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8652 - val_loss: 0.3644 - val_accuracy: 0.8653\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8643 - val_loss: 0.3629 - val_accuracy: 0.8664\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8637 - val_loss: 0.3627 - val_accuracy: 0.8672\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8654 - val_loss: 0.3622 - val_accuracy: 0.8657\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8645 - val_loss: 0.3621 - val_accuracy: 0.8668\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8651 - val_loss: 0.3633 - val_accuracy: 0.8664\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8651 - val_loss: 0.3624 - val_accuracy: 0.8672\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8648 - val_loss: 0.3616 - val_accuracy: 0.8709\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8643 - val_loss: 0.3630 - val_accuracy: 0.8668\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8656 - val_loss: 0.3632 - val_accuracy: 0.8664\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8659 - val_loss: 0.3640 - val_accuracy: 0.8713\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8655 - val_loss: 0.3622 - val_accuracy: 0.8687\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8659 - val_loss: 0.3620 - val_accuracy: 0.8657\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8649 - val_loss: 0.3645 - val_accuracy: 0.8638\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8653 - val_loss: 0.3623 - val_accuracy: 0.8660\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8654 - val_loss: 0.3619 - val_accuracy: 0.8668\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8656 - val_loss: 0.3614 - val_accuracy: 0.8687\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8658 - val_loss: 0.3610 - val_accuracy: 0.8701\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8655 - val_loss: 0.3620 - val_accuracy: 0.8653\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8654 - val_loss: 0.3626 - val_accuracy: 0.8716\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8653 - val_loss: 0.3609 - val_accuracy: 0.8687\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.3572 - accuracy: 0.8660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▊                                                            | 3/10 [04:55<11:25, 97.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35721465945243835, 0.8659747242927551]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▏                                                                          | 1164/40000 [00:00<00:03, 11630.72it/s]\u001b[A\n",
      "  6%|████▍                                                                        | 2328/40000 [00:00<00:03, 11590.47it/s]\u001b[A\n",
      "  9%|██████▋                                                                      | 3488/40000 [00:00<00:03, 11474.46it/s]\u001b[A\n",
      " 12%|█████████                                                                    | 4739/40000 [00:00<00:02, 11877.68it/s]\u001b[A\n",
      " 15%|███████████▌                                                                 | 5989/40000 [00:00<00:02, 12099.88it/s]\u001b[A\n",
      " 18%|█████████████▉                                                               | 7237/40000 [00:00<00:02, 12226.64it/s]\u001b[A\n",
      " 21%|████████████████▎                                                            | 8460/40000 [00:00<00:02, 12012.33it/s]\u001b[A\n",
      " 24%|██████████████████▌                                                          | 9663/40000 [00:00<00:02, 11991.59it/s]\u001b[A\n",
      " 27%|████████████████████▋                                                       | 10863/40000 [00:00<00:02, 11880.20it/s]\u001b[A\n",
      " 30%|██████████████████████▉                                                     | 12052/40000 [00:01<00:02, 11814.70it/s]\u001b[A\n",
      " 33%|█████████████████████████▏                                                  | 13234/40000 [00:01<00:02, 11758.55it/s]\u001b[A\n",
      " 36%|███████████████████████████▍                                                | 14411/40000 [00:01<00:02, 11734.88it/s]\u001b[A\n",
      " 39%|█████████████████████████████▋                                              | 15602/40000 [00:01<00:02, 11784.82it/s]\u001b[A\n",
      " 42%|███████████████████████████████▉                                            | 16800/40000 [00:01<00:01, 11841.02it/s]\u001b[A\n",
      " 45%|██████████████████████████████████▏                                         | 17985/40000 [00:01<00:01, 11765.61it/s]\u001b[A\n",
      " 48%|████████████████████████████████████▍                                       | 19178/40000 [00:01<00:01, 11812.50it/s]\u001b[A\n",
      " 51%|██████████████████████████████████████▋                                     | 20360/40000 [00:01<00:01, 11782.01it/s]\u001b[A\n",
      " 54%|████████████████████████████████████████▉                                   | 21539/40000 [00:01<00:01, 11732.42it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████▏                                | 22714/40000 [00:01<00:01, 11735.74it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████▍                              | 23888/40000 [00:02<00:01, 11734.07it/s]\u001b[A\n",
      " 63%|███████████████████████████████████████████████▌                            | 25062/40000 [00:02<00:01, 11681.86it/s]\u001b[A\n",
      " 66%|█████████████████████████████████████████████████▉                          | 26253/40000 [00:02<00:01, 11748.42it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████                        | 27432/40000 [00:02<00:01, 11758.57it/s]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████████▎                     | 28613/40000 [00:02<00:00, 11773.29it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████▋                   | 29807/40000 [00:02<00:00, 11822.88it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▉                 | 30990/40000 [00:02<00:00, 11822.24it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▎              | 32238/40000 [00:02<00:00, 12018.54it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▌            | 33469/40000 [00:02<00:00, 12103.27it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▉          | 34717/40000 [00:02<00:00, 12213.27it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▎       | 35964/40000 [00:03<00:00, 12289.02it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▋     | 37213/40000 [00:03<00:00, 12346.55it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████   | 38460/40000 [00:03<00:00, 12381.99it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 11946.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "(40000, 4)\n",
      "(39996, 10) (39996, 4)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.1538 - accuracy: 0.5576 - val_loss: 0.9857 - val_accuracy: 0.7108\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8816 - accuracy: 0.7692 - val_loss: 0.7930 - val_accuracy: 0.8183\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7375 - accuracy: 0.8242 - val_loss: 0.6812 - val_accuracy: 0.8396\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.8427 - val_loss: 0.6084 - val_accuracy: 0.8590\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.8550 - val_loss: 0.5628 - val_accuracy: 0.8455\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.8619 - val_loss: 0.5186 - val_accuracy: 0.8705\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8672 - val_loss: 0.4890 - val_accuracy: 0.8743\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8703 - val_loss: 0.4649 - val_accuracy: 0.8784\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8731 - val_loss: 0.4460 - val_accuracy: 0.8787\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8755 - val_loss: 0.4299 - val_accuracy: 0.8813\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8767 - val_loss: 0.4153 - val_accuracy: 0.8821\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8772 - val_loss: 0.4037 - val_accuracy: 0.8817\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8791 - val_loss: 0.3937 - val_accuracy: 0.8847\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8784 - val_loss: 0.3845 - val_accuracy: 0.8832\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8787 - val_loss: 0.3772 - val_accuracy: 0.8813\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8805 - val_loss: 0.3697 - val_accuracy: 0.8847\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8819 - val_loss: 0.3633 - val_accuracy: 0.8828\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8821 - val_loss: 0.3582 - val_accuracy: 0.8858\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8830 - val_loss: 0.3545 - val_accuracy: 0.8843\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8831 - val_loss: 0.3492 - val_accuracy: 0.8825\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8840 - val_loss: 0.3446 - val_accuracy: 0.8851\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8841 - val_loss: 0.3418 - val_accuracy: 0.8791\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8845 - val_loss: 0.3376 - val_accuracy: 0.8843\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8845 - val_loss: 0.3341 - val_accuracy: 0.8854\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8852 - val_loss: 0.3314 - val_accuracy: 0.8828\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8854 - val_loss: 0.3290 - val_accuracy: 0.8854\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8856 - val_loss: 0.3273 - val_accuracy: 0.8836\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8859 - val_loss: 0.3248 - val_accuracy: 0.8832\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8866 - val_loss: 0.3250 - val_accuracy: 0.8795\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8869 - val_loss: 0.3209 - val_accuracy: 0.8869\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8863 - val_loss: 0.3182 - val_accuracy: 0.8862\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8857 - val_loss: 0.3171 - val_accuracy: 0.8854\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8863 - val_loss: 0.3150 - val_accuracy: 0.8851\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8875 - val_loss: 0.3143 - val_accuracy: 0.8858\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8876 - val_loss: 0.3132 - val_accuracy: 0.8836\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8876 - val_loss: 0.3113 - val_accuracy: 0.8866\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8878 - val_loss: 0.3106 - val_accuracy: 0.8866\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8880 - val_loss: 0.3092 - val_accuracy: 0.8869\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8879 - val_loss: 0.3078 - val_accuracy: 0.8858\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8888 - val_loss: 0.3070 - val_accuracy: 0.8862\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8882 - val_loss: 0.3059 - val_accuracy: 0.8866\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8888 - val_loss: 0.3053 - val_accuracy: 0.8877\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8881 - val_loss: 0.3047 - val_accuracy: 0.8866\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8874 - val_loss: 0.3047 - val_accuracy: 0.8858\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8886 - val_loss: 0.3034 - val_accuracy: 0.8866\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8891 - val_loss: 0.3024 - val_accuracy: 0.8873\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8878 - val_loss: 0.3014 - val_accuracy: 0.8847\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8886 - val_loss: 0.3009 - val_accuracy: 0.8873\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8890 - val_loss: 0.3004 - val_accuracy: 0.8881\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8888 - val_loss: 0.3020 - val_accuracy: 0.8840\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8886 - val_loss: 0.2996 - val_accuracy: 0.8854\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8900 - val_loss: 0.2993 - val_accuracy: 0.8877\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8893 - val_loss: 0.3001 - val_accuracy: 0.8884\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8896 - val_loss: 0.2976 - val_accuracy: 0.8854\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8893 - val_loss: 0.2999 - val_accuracy: 0.8896\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8895 - val_loss: 0.2971 - val_accuracy: 0.8877\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8898 - val_loss: 0.2968 - val_accuracy: 0.8847\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8898 - val_loss: 0.2966 - val_accuracy: 0.8851\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8890 - val_loss: 0.2960 - val_accuracy: 0.8866\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8895 - val_loss: 0.2957 - val_accuracy: 0.8854\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8893 - val_loss: 0.2958 - val_accuracy: 0.8858\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8896 - val_loss: 0.2947 - val_accuracy: 0.8851\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8900 - val_loss: 0.2951 - val_accuracy: 0.8884\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8893 - val_loss: 0.2945 - val_accuracy: 0.8873\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8895 - val_loss: 0.2948 - val_accuracy: 0.8892\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8895 - val_loss: 0.2945 - val_accuracy: 0.8854\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8893 - val_loss: 0.2944 - val_accuracy: 0.8869\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8888 - val_loss: 0.2930 - val_accuracy: 0.8858\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8895 - val_loss: 0.2953 - val_accuracy: 0.8888\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8900 - val_loss: 0.2926 - val_accuracy: 0.8888\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8900 - val_loss: 0.2922 - val_accuracy: 0.8847\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8905 - val_loss: 0.2936 - val_accuracy: 0.8873\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8899 - val_loss: 0.2921 - val_accuracy: 0.8896\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8898 - val_loss: 0.2922 - val_accuracy: 0.8877\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8905 - val_loss: 0.2924 - val_accuracy: 0.8899\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8901 - val_loss: 0.2922 - val_accuracy: 0.8858\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8896 - val_loss: 0.2916 - val_accuracy: 0.8851\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8898 - val_loss: 0.2919 - val_accuracy: 0.8862\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8898 - val_loss: 0.2907 - val_accuracy: 0.8873\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8904 - val_loss: 0.2917 - val_accuracy: 0.8869\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8898 - val_loss: 0.2913 - val_accuracy: 0.8881\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8897 - val_loss: 0.2901 - val_accuracy: 0.8888\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8902 - val_loss: 0.2901 - val_accuracy: 0.8862\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8895 - val_loss: 0.2899 - val_accuracy: 0.8877\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8899 - val_loss: 0.2893 - val_accuracy: 0.8854\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8905 - val_loss: 0.2913 - val_accuracy: 0.8881\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8896 - val_loss: 0.2911 - val_accuracy: 0.8873\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8904 - val_loss: 0.2894 - val_accuracy: 0.8881\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8911 - val_loss: 0.2897 - val_accuracy: 0.8862\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8895 - val_loss: 0.2893 - val_accuracy: 0.8888\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8906 - val_loss: 0.2897 - val_accuracy: 0.8903\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8900 - val_loss: 0.2891 - val_accuracy: 0.8881\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8900 - val_loss: 0.2883 - val_accuracy: 0.8866\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8903 - val_loss: 0.2892 - val_accuracy: 0.8858\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8902 - val_loss: 0.2885 - val_accuracy: 0.8892\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8909 - val_loss: 0.2899 - val_accuracy: 0.8862\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8907 - val_loss: 0.2886 - val_accuracy: 0.8869\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8911 - val_loss: 0.2882 - val_accuracy: 0.8866\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8902 - val_loss: 0.2891 - val_accuracy: 0.8884\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8907 - val_loss: 0.2886 - val_accuracy: 0.8892\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8904 - val_loss: 0.2879 - val_accuracy: 0.8881\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8906 - val_loss: 0.2873 - val_accuracy: 0.8862\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8912 - val_loss: 0.2876 - val_accuracy: 0.8862\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8907 - val_loss: 0.2900 - val_accuracy: 0.8892\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8902 - val_loss: 0.2881 - val_accuracy: 0.8907\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8907 - val_loss: 0.2874 - val_accuracy: 0.8873\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.8904 - val_loss: 0.2872 - val_accuracy: 0.8881\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8903 - val_loss: 0.2873 - val_accuracy: 0.8877\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8901 - val_loss: 0.2874 - val_accuracy: 0.8881\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.8907 - val_loss: 0.2867 - val_accuracy: 0.8862\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8907 - val_loss: 0.2869 - val_accuracy: 0.8888\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8902 - val_loss: 0.2869 - val_accuracy: 0.8892\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8903 - val_loss: 0.2864 - val_accuracy: 0.8877\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8909 - val_loss: 0.2875 - val_accuracy: 0.8896\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8902 - val_loss: 0.2869 - val_accuracy: 0.8884\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8905 - val_loss: 0.2859 - val_accuracy: 0.8873\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8904 - val_loss: 0.2864 - val_accuracy: 0.8862\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8902 - val_loss: 0.2860 - val_accuracy: 0.8866\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8909 - val_loss: 0.2857 - val_accuracy: 0.8881\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8905 - val_loss: 0.2858 - val_accuracy: 0.8877\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8906 - val_loss: 0.2871 - val_accuracy: 0.8899\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8903 - val_loss: 0.2872 - val_accuracy: 0.8888\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8907 - val_loss: 0.2860 - val_accuracy: 0.8862\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8906 - val_loss: 0.2860 - val_accuracy: 0.8888\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8909 - val_loss: 0.2854 - val_accuracy: 0.8854\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8912 - val_loss: 0.2862 - val_accuracy: 0.8899\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8912 - val_loss: 0.2856 - val_accuracy: 0.8892\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8903 - val_loss: 0.2861 - val_accuracy: 0.8896\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8912 - val_loss: 0.2856 - val_accuracy: 0.8899\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.8898 - val_loss: 0.2873 - val_accuracy: 0.8862\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8901 - val_loss: 0.2861 - val_accuracy: 0.8892\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8902 - val_loss: 0.2860 - val_accuracy: 0.8888\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8902 - val_loss: 0.2853 - val_accuracy: 0.8869\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8907 - val_loss: 0.2852 - val_accuracy: 0.8888\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8906 - val_loss: 0.2853 - val_accuracy: 0.8877\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8905 - val_loss: 0.2849 - val_accuracy: 0.8877\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8912 - val_loss: 0.2845 - val_accuracy: 0.8888\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8905 - val_loss: 0.2850 - val_accuracy: 0.8873\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8906 - val_loss: 0.2856 - val_accuracy: 0.8884\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8910 - val_loss: 0.2853 - val_accuracy: 0.8888\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8905 - val_loss: 0.2880 - val_accuracy: 0.8892\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8917 - val_loss: 0.2854 - val_accuracy: 0.8858\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8909 - val_loss: 0.2850 - val_accuracy: 0.8869\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8911 - val_loss: 0.2843 - val_accuracy: 0.8888\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8915 - val_loss: 0.2850 - val_accuracy: 0.8892\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8900 - val_loss: 0.2853 - val_accuracy: 0.8881\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8909 - val_loss: 0.2839 - val_accuracy: 0.8884\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8909 - val_loss: 0.2845 - val_accuracy: 0.8877\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8903 - val_loss: 0.2847 - val_accuracy: 0.8873\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8907 - val_loss: 0.2842 - val_accuracy: 0.8877\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.3094 - accuracy: 0.8848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▍                                                   | 4/10 [06:31<09:45, 97.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3093660771846771, 0.8847640156745911]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1214/40000 [00:00<00:03, 12136.71it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2428/40000 [00:00<00:03, 12062.16it/s]\u001b[A\n",
      "  9%|██████▉                                                                      | 3635/40000 [00:00<00:03, 11981.35it/s]\u001b[A\n",
      " 12%|█████████▍                                                                   | 4888/40000 [00:00<00:02, 12194.69it/s]\u001b[A\n",
      " 15%|███████████▊                                                                 | 6141/40000 [00:00<00:02, 12313.07it/s]\u001b[A\n",
      " 18%|██████████████▏                                                              | 7396/40000 [00:00<00:02, 12391.14it/s]\u001b[A\n",
      " 22%|████████████████▌                                                            | 8636/40000 [00:00<00:02, 12222.05it/s]\u001b[A\n",
      " 25%|██████████████████▉                                                          | 9859/40000 [00:00<00:02, 12031.64it/s]\u001b[A\n",
      " 28%|█████████████████████                                                       | 11110/40000 [00:00<00:02, 12175.90it/s]\u001b[A\n",
      " 31%|███████████████████████▍                                                    | 12361/40000 [00:01<00:02, 12275.64it/s]\u001b[A\n",
      " 34%|█████████████████████████▊                                                  | 13610/40000 [00:01<00:02, 12338.77it/s]\u001b[A\n",
      " 37%|████████████████████████████▏                                               | 14862/40000 [00:01<00:02, 12393.04it/s]\u001b[A\n",
      " 40%|██████████████████████████████▌                                             | 16110/40000 [00:01<00:01, 12418.64it/s]\u001b[A\n",
      " 43%|████████████████████████████████▉                                           | 17361/40000 [00:01<00:01, 12443.52it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▎                                        | 18613/40000 [00:01<00:01, 12465.14it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▋                                      | 19865/40000 [00:01<00:01, 12479.11it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████                                    | 21118/40000 [00:01<00:01, 12492.99it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▍                                 | 22368/40000 [00:01<00:01, 12493.05it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▊                               | 23618/40000 [00:01<00:01, 12480.08it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▏                            | 24867/40000 [00:02<00:01, 12446.65it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▌                          | 26117/40000 [00:02<00:01, 12459.72it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▉                        | 27365/40000 [00:02<00:01, 12465.38it/s]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████████▎                     | 28615/40000 [00:02<00:00, 12475.65it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████▋                   | 29865/40000 [00:02<00:00, 12481.57it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████                 | 31114/40000 [00:02<00:00, 12483.75it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▍              | 32363/40000 [00:02<00:00, 12483.75it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▊            | 33614/40000 [00:02<00:00, 12489.57it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████▏         | 34863/40000 [00:02<00:00, 12488.89it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▌       | 36115/40000 [00:02<00:00, 12496.75it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▉     | 37365/40000 [00:03<00:00, 12497.62it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████████████████████████████████████▎  | 38616/40000 [00:03<00:00, 12498.86it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12398.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "(40000, 4)\n",
      "(39996, 10) (39996, 4)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.0762 - accuracy: 0.5475 - val_loss: 0.8661 - val_accuracy: 0.7668\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7753 - accuracy: 0.7900 - val_loss: 0.6834 - val_accuracy: 0.8384\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.8341 - val_loss: 0.5924 - val_accuracy: 0.8519\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.8486 - val_loss: 0.5329 - val_accuracy: 0.8638\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.8594 - val_loss: 0.4918 - val_accuracy: 0.8746\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8647 - val_loss: 0.4618 - val_accuracy: 0.8772\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8686 - val_loss: 0.4367 - val_accuracy: 0.8802\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8731 - val_loss: 0.4157 - val_accuracy: 0.8877\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8752 - val_loss: 0.3989 - val_accuracy: 0.8896\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8780 - val_loss: 0.3837 - val_accuracy: 0.8884\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8794 - val_loss: 0.3722 - val_accuracy: 0.8869\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8806 - val_loss: 0.3596 - val_accuracy: 0.8966\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8813 - val_loss: 0.3518 - val_accuracy: 0.8869\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8835 - val_loss: 0.3412 - val_accuracy: 0.8951\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8838 - val_loss: 0.3355 - val_accuracy: 0.8910\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8850 - val_loss: 0.3282 - val_accuracy: 0.8907\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8860 - val_loss: 0.3214 - val_accuracy: 0.8959\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8875 - val_loss: 0.3153 - val_accuracy: 0.8974\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8885 - val_loss: 0.3110 - val_accuracy: 0.8966\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8886 - val_loss: 0.3057 - val_accuracy: 0.9011\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8899 - val_loss: 0.3034 - val_accuracy: 0.8974\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8902 - val_loss: 0.2982 - val_accuracy: 0.9007\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8908 - val_loss: 0.2939 - val_accuracy: 0.9030\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8924 - val_loss: 0.2913 - val_accuracy: 0.9026\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8933 - val_loss: 0.2891 - val_accuracy: 0.9004\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.8939 - val_loss: 0.2870 - val_accuracy: 0.9026\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8935 - val_loss: 0.2853 - val_accuracy: 0.8981\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8938 - val_loss: 0.2812 - val_accuracy: 0.9041\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8961 - val_loss: 0.2800 - val_accuracy: 0.9030\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8945 - val_loss: 0.2782 - val_accuracy: 0.9004\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.8956 - val_loss: 0.2764 - val_accuracy: 0.9049\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8965 - val_loss: 0.2746 - val_accuracy: 0.9034\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8948 - val_loss: 0.2721 - val_accuracy: 0.9045\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.8963 - val_loss: 0.2731 - val_accuracy: 0.9007\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.8973 - val_loss: 0.2703 - val_accuracy: 0.9026\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8977 - val_loss: 0.2696 - val_accuracy: 0.9045\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8968 - val_loss: 0.2684 - val_accuracy: 0.9034\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.8976 - val_loss: 0.2683 - val_accuracy: 0.9015\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8977 - val_loss: 0.2653 - val_accuracy: 0.9045\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.8980 - val_loss: 0.2651 - val_accuracy: 0.9030\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.8988 - val_loss: 0.2634 - val_accuracy: 0.9034\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8989 - val_loss: 0.2644 - val_accuracy: 0.9022\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.8980 - val_loss: 0.2618 - val_accuracy: 0.9022\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8989 - val_loss: 0.2653 - val_accuracy: 0.9004\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8987 - val_loss: 0.2603 - val_accuracy: 0.9026\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.8994 - val_loss: 0.2600 - val_accuracy: 0.9045\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8992 - val_loss: 0.2599 - val_accuracy: 0.9022\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8988 - val_loss: 0.2602 - val_accuracy: 0.9030\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.8995 - val_loss: 0.2611 - val_accuracy: 0.9026\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8998 - val_loss: 0.2606 - val_accuracy: 0.9026\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8992 - val_loss: 0.2594 - val_accuracy: 0.9030\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.8996 - val_loss: 0.2615 - val_accuracy: 0.9022\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8997 - val_loss: 0.2611 - val_accuracy: 0.8996\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8997 - val_loss: 0.2579 - val_accuracy: 0.9030\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.9003 - val_loss: 0.2565 - val_accuracy: 0.9026\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8998 - val_loss: 0.2552 - val_accuracy: 0.9045\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8999 - val_loss: 0.2553 - val_accuracy: 0.9030\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.9000 - val_loss: 0.2541 - val_accuracy: 0.9034\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.9005 - val_loss: 0.2559 - val_accuracy: 0.9026\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.9001 - val_loss: 0.2570 - val_accuracy: 0.9004\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.9001 - val_loss: 0.2534 - val_accuracy: 0.9026\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.9010 - val_loss: 0.2538 - val_accuracy: 0.9015\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9001 - val_loss: 0.2564 - val_accuracy: 0.9011\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9004 - val_loss: 0.2525 - val_accuracy: 0.9030\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.9014 - val_loss: 0.2522 - val_accuracy: 0.9019\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.9006 - val_loss: 0.2535 - val_accuracy: 0.9026\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.9006 - val_loss: 0.2527 - val_accuracy: 0.9022\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.9007 - val_loss: 0.2517 - val_accuracy: 0.9011\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9007 - val_loss: 0.2524 - val_accuracy: 0.9026\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.9006 - val_loss: 0.2522 - val_accuracy: 0.9045\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9003 - val_loss: 0.2530 - val_accuracy: 0.9026\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9011 - val_loss: 0.2517 - val_accuracy: 0.9022\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.9005 - val_loss: 0.2524 - val_accuracy: 0.9011\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.9013 - val_loss: 0.2511 - val_accuracy: 0.9034\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.9013 - val_loss: 0.2509 - val_accuracy: 0.9037\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9010 - val_loss: 0.2511 - val_accuracy: 0.9019\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9016 - val_loss: 0.2504 - val_accuracy: 0.9026\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.9021 - val_loss: 0.2512 - val_accuracy: 0.9022\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.9015 - val_loss: 0.2529 - val_accuracy: 0.9030\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.9016 - val_loss: 0.2530 - val_accuracy: 0.9026\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.9014 - val_loss: 0.2491 - val_accuracy: 0.9026\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9008 - val_loss: 0.2495 - val_accuracy: 0.9030\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.9016 - val_loss: 0.2519 - val_accuracy: 0.9030\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.9014 - val_loss: 0.2499 - val_accuracy: 0.9030\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.9017 - val_loss: 0.2495 - val_accuracy: 0.9015\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9017 - val_loss: 0.2492 - val_accuracy: 0.9037\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.9020 - val_loss: 0.2496 - val_accuracy: 0.9026\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9023 - val_loss: 0.2492 - val_accuracy: 0.9041\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.9020 - val_loss: 0.2485 - val_accuracy: 0.9026\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.9015 - val_loss: 0.2479 - val_accuracy: 0.9011\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.9024 - val_loss: 0.2482 - val_accuracy: 0.9026\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.9019 - val_loss: 0.2493 - val_accuracy: 0.9030\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.9014 - val_loss: 0.2482 - val_accuracy: 0.9030\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.9022 - val_loss: 0.2497 - val_accuracy: 0.9019\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.9021 - val_loss: 0.2484 - val_accuracy: 0.9026\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9022 - val_loss: 0.2477 - val_accuracy: 0.9034\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.9024 - val_loss: 0.2506 - val_accuracy: 0.9041\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9025 - val_loss: 0.2493 - val_accuracy: 0.9041\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.9014 - val_loss: 0.2488 - val_accuracy: 0.9015\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9026 - val_loss: 0.2478 - val_accuracy: 0.9045\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9020 - val_loss: 0.2480 - val_accuracy: 0.9037\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.9022 - val_loss: 0.2478 - val_accuracy: 0.9030\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9015 - val_loss: 0.2471 - val_accuracy: 0.9026\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9026 - val_loss: 0.2475 - val_accuracy: 0.9041\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9027 - val_loss: 0.2476 - val_accuracy: 0.9026\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.9025 - val_loss: 0.2497 - val_accuracy: 0.9037\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.9029 - val_loss: 0.2479 - val_accuracy: 0.9034\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.9025 - val_loss: 0.2471 - val_accuracy: 0.9030\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.9021 - val_loss: 0.2473 - val_accuracy: 0.9034\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.9026 - val_loss: 0.2492 - val_accuracy: 0.9037\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.9029 - val_loss: 0.2469 - val_accuracy: 0.9037\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.9024 - val_loss: 0.2467 - val_accuracy: 0.9034\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.9028 - val_loss: 0.2463 - val_accuracy: 0.9045\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.9022 - val_loss: 0.2483 - val_accuracy: 0.9034\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.9026 - val_loss: 0.2468 - val_accuracy: 0.9034\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.9028 - val_loss: 0.2483 - val_accuracy: 0.9041\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.9024 - val_loss: 0.2471 - val_accuracy: 0.9037\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.9021 - val_loss: 0.2469 - val_accuracy: 0.9034\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9028 - val_loss: 0.2480 - val_accuracy: 0.9034\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9028 - val_loss: 0.2469 - val_accuracy: 0.9022\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.9032 - val_loss: 0.2458 - val_accuracy: 0.9026\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.9026 - val_loss: 0.2459 - val_accuracy: 0.9037\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.9034 - val_loss: 0.2455 - val_accuracy: 0.9030\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.9029 - val_loss: 0.2486 - val_accuracy: 0.9022\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.9027 - val_loss: 0.2458 - val_accuracy: 0.9034\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9021 - val_loss: 0.2491 - val_accuracy: 0.9026\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.9028 - val_loss: 0.2465 - val_accuracy: 0.9045\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.9031 - val_loss: 0.2459 - val_accuracy: 0.9037\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9033 - val_loss: 0.2454 - val_accuracy: 0.9041\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.9028 - val_loss: 0.2451 - val_accuracy: 0.9037\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9025 - val_loss: 0.2457 - val_accuracy: 0.9034\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.9026 - val_loss: 0.2451 - val_accuracy: 0.9034\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.9024 - val_loss: 0.2450 - val_accuracy: 0.9030\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.9024 - val_loss: 0.2449 - val_accuracy: 0.9041\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.9026 - val_loss: 0.2485 - val_accuracy: 0.9037\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9031 - val_loss: 0.2460 - val_accuracy: 0.9037\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.9031 - val_loss: 0.2452 - val_accuracy: 0.9045\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.9030 - val_loss: 0.2466 - val_accuracy: 0.9045\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.9031 - val_loss: 0.2469 - val_accuracy: 0.9041\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.9027 - val_loss: 0.2472 - val_accuracy: 0.9045\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.9029 - val_loss: 0.2456 - val_accuracy: 0.9037\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9031 - val_loss: 0.2495 - val_accuracy: 0.9045\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.9035 - val_loss: 0.2448 - val_accuracy: 0.9045\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9034 - val_loss: 0.2450 - val_accuracy: 0.9041\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.9036 - val_loss: 0.2448 - val_accuracy: 0.9060\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.9034 - val_loss: 0.2452 - val_accuracy: 0.9041\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9030 - val_loss: 0.2459 - val_accuracy: 0.9034\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9042 - val_loss: 0.2455 - val_accuracy: 0.9045\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9033 - val_loss: 0.2457 - val_accuracy: 0.9049\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9030 - val_loss: 0.2459 - val_accuracy: 0.9041\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.2468 - accuracy: 0.9042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████                                           | 5/10 [08:09<08:08, 97.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24680854380130768, 0.9042351841926575]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1252/40000 [00:00<00:03, 12509.63it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2503/40000 [00:00<00:03, 12450.89it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3749/40000 [00:00<00:02, 12431.29it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4994/40000 [00:00<00:02, 12435.05it/s]\u001b[A\n",
      " 16%|████████████                                                                 | 6238/40000 [00:00<00:02, 12433.24it/s]\u001b[A\n",
      " 19%|██████████████▍                                                              | 7484/40000 [00:00<00:02, 12439.01it/s]\u001b[A\n",
      " 22%|████████████████▊                                                            | 8730/40000 [00:00<00:02, 12443.08it/s]\u001b[A\n",
      " 25%|███████████████████▏                                                         | 9975/40000 [00:00<00:02, 12441.58it/s]\u001b[A\n",
      " 28%|█████████████████████▎                                                      | 11220/40000 [00:00<00:02, 12437.60it/s]\u001b[A\n",
      " 31%|███████████████████████▋                                                    | 12464/40000 [00:01<00:02, 12434.95it/s]\u001b[A\n",
      " 34%|██████████████████████████                                                  | 13710/40000 [00:01<00:02, 12441.52it/s]\u001b[A\n",
      " 37%|████████████████████████████▍                                               | 14956/40000 [00:01<00:02, 12446.91it/s]\u001b[A\n",
      " 41%|██████████████████████████████▊                                             | 16201/40000 [00:01<00:01, 12446.95it/s]\u001b[A\n",
      " 44%|█████████████████████████████████▏                                          | 17448/40000 [00:01<00:01, 12452.47it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▌                                        | 18695/40000 [00:01<00:01, 12455.67it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▉                                      | 19941/40000 [00:01<00:01, 12447.39it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▎                                   | 21186/40000 [00:01<00:01, 12445.28it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▌                                 | 22431/40000 [00:01<00:01, 12441.25it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▉                               | 23676/40000 [00:01<00:01, 12443.70it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▎                            | 24921/40000 [00:02<00:01, 12441.62it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▋                          | 26166/40000 [00:02<00:01, 12441.65it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████                        | 27412/40000 [00:02<00:01, 12446.22it/s]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████████▍                     | 28658/40000 [00:02<00:00, 12447.46it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████▊                   | 29904/40000 [00:02<00:00, 12450.46it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████▏                | 31150/40000 [00:02<00:00, 12449.43it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▌              | 32395/40000 [00:02<00:00, 12448.82it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▉            | 33640/40000 [00:02<00:00, 12441.25it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████▎         | 34885/40000 [00:02<00:00, 12431.95it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▋       | 36130/40000 [00:02<00:00, 12435.19it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████████████████████████████████████     | 37375/40000 [00:03<00:00, 12439.50it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████████████████████████████████████▍  | 38619/40000 [00:03<00:00, 12426.20it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12433.51it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "(40000, 4)\n",
      "(39996, 10) (39996, 4)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.3210 - accuracy: 0.4614 - val_loss: 1.0192 - val_accuracy: 0.7347\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8911 - accuracy: 0.8298 - val_loss: 0.7850 - val_accuracy: 0.8713\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.8793 - val_loss: 0.6518 - val_accuracy: 0.9000\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.8938 - val_loss: 0.5669 - val_accuracy: 0.8978\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.9007 - val_loss: 0.5079 - val_accuracy: 0.9026\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.9043 - val_loss: 0.4644 - val_accuracy: 0.9075\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.9087 - val_loss: 0.4315 - val_accuracy: 0.9090\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.9101 - val_loss: 0.4087 - val_accuracy: 0.8996\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.9133 - val_loss: 0.3856 - val_accuracy: 0.9093\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.9142 - val_loss: 0.3676 - val_accuracy: 0.9131\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.9156 - val_loss: 0.3545 - val_accuracy: 0.9101\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.9165 - val_loss: 0.3414 - val_accuracy: 0.9149\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.9186 - val_loss: 0.3315 - val_accuracy: 0.9123\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.9182 - val_loss: 0.3217 - val_accuracy: 0.9168\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.9196 - val_loss: 0.3139 - val_accuracy: 0.9179\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.9192 - val_loss: 0.3072 - val_accuracy: 0.9179\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.9203 - val_loss: 0.3025 - val_accuracy: 0.9127\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.9209 - val_loss: 0.2958 - val_accuracy: 0.9157\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.9196 - val_loss: 0.2908 - val_accuracy: 0.9172\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.9197 - val_loss: 0.2866 - val_accuracy: 0.9213\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.9198 - val_loss: 0.2839 - val_accuracy: 0.9142\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.9213 - val_loss: 0.2798 - val_accuracy: 0.9157\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.9198 - val_loss: 0.2759 - val_accuracy: 0.9198\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.9206 - val_loss: 0.2733 - val_accuracy: 0.9175\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.9206 - val_loss: 0.2734 - val_accuracy: 0.9086\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.9198 - val_loss: 0.2687 - val_accuracy: 0.9146\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.9199 - val_loss: 0.2666 - val_accuracy: 0.9138\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9201 - val_loss: 0.2646 - val_accuracy: 0.9146\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.9195 - val_loss: 0.2623 - val_accuracy: 0.9205\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9198 - val_loss: 0.2608 - val_accuracy: 0.9157\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.9203 - val_loss: 0.2590 - val_accuracy: 0.9179\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.9200 - val_loss: 0.2581 - val_accuracy: 0.9153\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9205 - val_loss: 0.2576 - val_accuracy: 0.9116\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9204 - val_loss: 0.2550 - val_accuracy: 0.9168\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9201 - val_loss: 0.2567 - val_accuracy: 0.9090\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9198 - val_loss: 0.2531 - val_accuracy: 0.9164\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9195 - val_loss: 0.2523 - val_accuracy: 0.9198\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9196 - val_loss: 0.2513 - val_accuracy: 0.9168\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9204 - val_loss: 0.2520 - val_accuracy: 0.9104\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9200 - val_loss: 0.2498 - val_accuracy: 0.9142\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9194 - val_loss: 0.2496 - val_accuracy: 0.9127\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.9198 - val_loss: 0.2480 - val_accuracy: 0.9179\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9196 - val_loss: 0.2478 - val_accuracy: 0.9153\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.9197 - val_loss: 0.2475 - val_accuracy: 0.9138\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9194 - val_loss: 0.2465 - val_accuracy: 0.9160\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9195 - val_loss: 0.2464 - val_accuracy: 0.9131\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9199 - val_loss: 0.2469 - val_accuracy: 0.9104\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9189 - val_loss: 0.2469 - val_accuracy: 0.9097\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9199 - val_loss: 0.2475 - val_accuracy: 0.9078\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9201 - val_loss: 0.2461 - val_accuracy: 0.9101\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9196 - val_loss: 0.2438 - val_accuracy: 0.9168\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.9198 - val_loss: 0.2439 - val_accuracy: 0.9138\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9195 - val_loss: 0.2450 - val_accuracy: 0.9097\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9197 - val_loss: 0.2435 - val_accuracy: 0.9153\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9196 - val_loss: 0.2438 - val_accuracy: 0.9153\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9191 - val_loss: 0.2429 - val_accuracy: 0.9160\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9196 - val_loss: 0.2423 - val_accuracy: 0.9157\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9194 - val_loss: 0.2424 - val_accuracy: 0.9127\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9199 - val_loss: 0.2439 - val_accuracy: 0.9093\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9188 - val_loss: 0.2430 - val_accuracy: 0.9097\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9191 - val_loss: 0.2417 - val_accuracy: 0.9123\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9194 - val_loss: 0.2412 - val_accuracy: 0.9119\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9194 - val_loss: 0.2426 - val_accuracy: 0.9131\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9198 - val_loss: 0.2411 - val_accuracy: 0.9153\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9196 - val_loss: 0.2407 - val_accuracy: 0.9123\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9191 - val_loss: 0.2413 - val_accuracy: 0.9101\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9189 - val_loss: 0.2450 - val_accuracy: 0.9037\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9191 - val_loss: 0.2404 - val_accuracy: 0.9116\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9199 - val_loss: 0.2400 - val_accuracy: 0.9146\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9198 - val_loss: 0.2410 - val_accuracy: 0.9108\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9194 - val_loss: 0.2405 - val_accuracy: 0.9127\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9195 - val_loss: 0.2408 - val_accuracy: 0.9104\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9186 - val_loss: 0.2404 - val_accuracy: 0.9123\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9197 - val_loss: 0.2400 - val_accuracy: 0.9123\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9197 - val_loss: 0.2416 - val_accuracy: 0.9093\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9198 - val_loss: 0.2461 - val_accuracy: 0.9015\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9189 - val_loss: 0.2391 - val_accuracy: 0.9131\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9195 - val_loss: 0.2389 - val_accuracy: 0.9127\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9191 - val_loss: 0.2395 - val_accuracy: 0.9119\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9194 - val_loss: 0.2403 - val_accuracy: 0.9093\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9191 - val_loss: 0.2395 - val_accuracy: 0.9104\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9192 - val_loss: 0.2387 - val_accuracy: 0.9149\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9194 - val_loss: 0.2409 - val_accuracy: 0.9071\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9186 - val_loss: 0.2388 - val_accuracy: 0.9153\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9193 - val_loss: 0.2392 - val_accuracy: 0.9127\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9194 - val_loss: 0.2390 - val_accuracy: 0.9104\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9196 - val_loss: 0.2389 - val_accuracy: 0.9101\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9198 - val_loss: 0.2392 - val_accuracy: 0.9104\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9195 - val_loss: 0.2380 - val_accuracy: 0.9119\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9189 - val_loss: 0.2394 - val_accuracy: 0.9093\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9197 - val_loss: 0.2386 - val_accuracy: 0.9134\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9191 - val_loss: 0.2386 - val_accuracy: 0.9134\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9191 - val_loss: 0.2386 - val_accuracy: 0.9142\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9195 - val_loss: 0.2384 - val_accuracy: 0.9108\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9201 - val_loss: 0.2379 - val_accuracy: 0.9123\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9195 - val_loss: 0.2378 - val_accuracy: 0.9116\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9190 - val_loss: 0.2387 - val_accuracy: 0.9101\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9188 - val_loss: 0.2376 - val_accuracy: 0.9119\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9194 - val_loss: 0.2377 - val_accuracy: 0.9108\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9187 - val_loss: 0.2380 - val_accuracy: 0.9112\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9196 - val_loss: 0.2384 - val_accuracy: 0.9104\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9193 - val_loss: 0.2381 - val_accuracy: 0.9101\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9187 - val_loss: 0.2386 - val_accuracy: 0.9082\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9194 - val_loss: 0.2378 - val_accuracy: 0.9108\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9186 - val_loss: 0.2373 - val_accuracy: 0.9138\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9192 - val_loss: 0.2378 - val_accuracy: 0.9116\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9197 - val_loss: 0.2390 - val_accuracy: 0.9075\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9189 - val_loss: 0.2376 - val_accuracy: 0.9116\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9201 - val_loss: 0.2381 - val_accuracy: 0.9108\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9194 - val_loss: 0.2374 - val_accuracy: 0.9134\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9198 - val_loss: 0.2374 - val_accuracy: 0.9104\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9198 - val_loss: 0.2381 - val_accuracy: 0.9101\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9197 - val_loss: 0.2372 - val_accuracy: 0.9112\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9192 - val_loss: 0.2377 - val_accuracy: 0.9104\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9196 - val_loss: 0.2391 - val_accuracy: 0.9086\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9191 - val_loss: 0.2382 - val_accuracy: 0.9082\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9190 - val_loss: 0.2387 - val_accuracy: 0.9097\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9195 - val_loss: 0.2384 - val_accuracy: 0.9086\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9186 - val_loss: 0.2379 - val_accuracy: 0.9082\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9197 - val_loss: 0.2415 - val_accuracy: 0.9049\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9185 - val_loss: 0.2371 - val_accuracy: 0.9119\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9190 - val_loss: 0.2368 - val_accuracy: 0.9108\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9196 - val_loss: 0.2372 - val_accuracy: 0.9097\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9192 - val_loss: 0.2392 - val_accuracy: 0.9075\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9196 - val_loss: 0.2404 - val_accuracy: 0.9060\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9194 - val_loss: 0.2397 - val_accuracy: 0.9060\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9195 - val_loss: 0.2384 - val_accuracy: 0.9090\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9198 - val_loss: 0.2372 - val_accuracy: 0.9101\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9202 - val_loss: 0.2372 - val_accuracy: 0.9101\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9193 - val_loss: 0.2394 - val_accuracy: 0.9067\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9191 - val_loss: 0.2375 - val_accuracy: 0.9131\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9198 - val_loss: 0.2367 - val_accuracy: 0.9116\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9196 - val_loss: 0.2376 - val_accuracy: 0.9082\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9191 - val_loss: 0.2367 - val_accuracy: 0.9101\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9197 - val_loss: 0.2387 - val_accuracy: 0.9082\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9199 - val_loss: 0.2366 - val_accuracy: 0.9112\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9194 - val_loss: 0.2394 - val_accuracy: 0.9060\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9197 - val_loss: 0.2370 - val_accuracy: 0.9101\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9197 - val_loss: 0.2394 - val_accuracy: 0.9101\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9189 - val_loss: 0.2373 - val_accuracy: 0.9082\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9201 - val_loss: 0.2365 - val_accuracy: 0.9131\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9194 - val_loss: 0.2367 - val_accuracy: 0.9101\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9199 - val_loss: 0.2366 - val_accuracy: 0.9127\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9193 - val_loss: 0.2361 - val_accuracy: 0.9146\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9198 - val_loss: 0.2372 - val_accuracy: 0.9093\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9190 - val_loss: 0.2361 - val_accuracy: 0.9134\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9196 - val_loss: 0.2371 - val_accuracy: 0.9127\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9195 - val_loss: 0.2361 - val_accuracy: 0.9101\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9195 - val_loss: 0.2360 - val_accuracy: 0.9127\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9196 - val_loss: 0.2374 - val_accuracy: 0.9078\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.2201 - accuracy: 0.9166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████▌                                  | 6/10 [09:47<06:31, 97.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22005502879619598, 0.9165846109390259]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1250/40000 [00:00<00:03, 12492.21it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2500/40000 [00:00<00:03, 12377.33it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3738/40000 [00:00<00:02, 12335.42it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4972/40000 [00:00<00:02, 12321.86it/s]\u001b[A\n",
      " 16%|███████████▉                                                                 | 6205/40000 [00:00<00:02, 12317.82it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7438/40000 [00:00<00:02, 12321.82it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8672/40000 [00:00<00:02, 12326.57it/s]\u001b[A\n",
      " 25%|███████████████████                                                          | 9905/40000 [00:00<00:02, 12314.94it/s]\u001b[A\n",
      " 28%|█████████████████████▏                                                      | 11144/40000 [00:00<00:02, 12336.12it/s]\u001b[A\n",
      " 31%|███████████████████████▌                                                    | 12380/40000 [00:01<00:02, 12342.62it/s]\u001b[A\n",
      " 34%|█████████████████████████▊                                                  | 13615/40000 [00:01<00:02, 12342.14it/s]\u001b[A\n",
      " 37%|████████████████████████████▏                                               | 14853/40000 [00:01<00:02, 12352.60it/s]\u001b[A\n",
      " 40%|██████████████████████████████▌                                             | 16094/40000 [00:01<00:01, 12368.41it/s]\u001b[A\n",
      " 43%|████████████████████████████████▉                                           | 17332/40000 [00:01<00:01, 12369.98it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▎                                        | 18569/40000 [00:01<00:01, 12363.90it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▋                                      | 19806/40000 [00:01<00:01, 12363.14it/s]\u001b[A\n",
      " 53%|███████████████████████████████████████▉                                    | 21043/40000 [00:01<00:01, 12358.58it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▎                                 | 22279/40000 [00:01<00:01, 12352.82it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▋                               | 23515/40000 [00:01<00:01, 12345.77it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████                             | 24750/40000 [00:02<00:01, 12339.16it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▎                          | 25985/40000 [00:02<00:01, 12341.03it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▋                        | 27221/40000 [00:02<00:01, 12343.68it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████                      | 28456/40000 [00:02<00:00, 12340.81it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▍                   | 29693/40000 [00:02<00:00, 12349.05it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▊                 | 30931/40000 [00:02<00:00, 12356.26it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████               | 32167/40000 [00:02<00:00, 12337.44it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▍            | 33401/40000 [00:02<00:00, 12334.48it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▊          | 34635/40000 [00:02<00:00, 12324.76it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▏       | 35869/40000 [00:02<00:00, 12328.03it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▍     | 37102/40000 [00:03<00:00, 12322.86it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▊   | 38336/40000 [00:03<00:00, 12326.61it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12336.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "(40000, 4)\n",
      "(39996, 10) (39996, 4)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.2749 - accuracy: 0.5026 - val_loss: 1.0974 - val_accuracy: 0.6325\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9987 - accuracy: 0.6903 - val_loss: 0.9189 - val_accuracy: 0.7175\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8582 - accuracy: 0.7555 - val_loss: 0.8078 - val_accuracy: 0.7955\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7692 - accuracy: 0.7905 - val_loss: 0.7371 - val_accuracy: 0.7985\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.8085 - val_loss: 0.6850 - val_accuracy: 0.8168\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.8176 - val_loss: 0.6470 - val_accuracy: 0.8235\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.8241 - val_loss: 0.6187 - val_accuracy: 0.8257\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.8285 - val_loss: 0.5950 - val_accuracy: 0.8250\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.8271 - val_loss: 0.5749 - val_accuracy: 0.8291\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.8306 - val_loss: 0.5580 - val_accuracy: 0.8317\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.8317 - val_loss: 0.5429 - val_accuracy: 0.8325\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.8327 - val_loss: 0.5306 - val_accuracy: 0.8306\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.8332 - val_loss: 0.5192 - val_accuracy: 0.8317\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.8349 - val_loss: 0.5109 - val_accuracy: 0.8358\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8368 - val_loss: 0.5010 - val_accuracy: 0.8362\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8370 - val_loss: 0.4935 - val_accuracy: 0.8362\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8370 - val_loss: 0.4887 - val_accuracy: 0.8351\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8373 - val_loss: 0.4820 - val_accuracy: 0.8399\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8389 - val_loss: 0.4745 - val_accuracy: 0.8373\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8392 - val_loss: 0.4702 - val_accuracy: 0.8354\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8402 - val_loss: 0.4643 - val_accuracy: 0.8407\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8391 - val_loss: 0.4613 - val_accuracy: 0.8354\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8411 - val_loss: 0.4563 - val_accuracy: 0.8403\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8406 - val_loss: 0.4551 - val_accuracy: 0.8362\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8406 - val_loss: 0.4494 - val_accuracy: 0.8418\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8409 - val_loss: 0.4474 - val_accuracy: 0.8414\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8428 - val_loss: 0.4463 - val_accuracy: 0.8407\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8419 - val_loss: 0.4418 - val_accuracy: 0.8414\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8433 - val_loss: 0.4434 - val_accuracy: 0.8384\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8425 - val_loss: 0.4376 - val_accuracy: 0.8425\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8426 - val_loss: 0.4363 - val_accuracy: 0.8418\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8430 - val_loss: 0.4336 - val_accuracy: 0.8444\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8421 - val_loss: 0.4311 - val_accuracy: 0.8451\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8428 - val_loss: 0.4317 - val_accuracy: 0.8433\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8431 - val_loss: 0.4293 - val_accuracy: 0.8437\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8434 - val_loss: 0.4270 - val_accuracy: 0.8407\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8443 - val_loss: 0.4252 - val_accuracy: 0.8396\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8433 - val_loss: 0.4256 - val_accuracy: 0.8433\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8438 - val_loss: 0.4233 - val_accuracy: 0.8440\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8457 - val_loss: 0.4223 - val_accuracy: 0.8440\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8450 - val_loss: 0.4223 - val_accuracy: 0.8437\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8450 - val_loss: 0.4235 - val_accuracy: 0.8418\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8440 - val_loss: 0.4204 - val_accuracy: 0.8433\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8438 - val_loss: 0.4186 - val_accuracy: 0.8444\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8441 - val_loss: 0.4185 - val_accuracy: 0.8444\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8450 - val_loss: 0.4208 - val_accuracy: 0.8437\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8448 - val_loss: 0.4169 - val_accuracy: 0.8444\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8451 - val_loss: 0.4157 - val_accuracy: 0.8481\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8455 - val_loss: 0.4148 - val_accuracy: 0.8466\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8460 - val_loss: 0.4139 - val_accuracy: 0.8418\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8462 - val_loss: 0.4155 - val_accuracy: 0.8455\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8463 - val_loss: 0.4138 - val_accuracy: 0.8414\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8465 - val_loss: 0.4126 - val_accuracy: 0.8425\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8470 - val_loss: 0.4122 - val_accuracy: 0.8433\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8465 - val_loss: 0.4128 - val_accuracy: 0.8466\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8463 - val_loss: 0.4153 - val_accuracy: 0.8478\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8461 - val_loss: 0.4124 - val_accuracy: 0.8474\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8468 - val_loss: 0.4141 - val_accuracy: 0.8500\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8462 - val_loss: 0.4119 - val_accuracy: 0.8459\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8467 - val_loss: 0.4108 - val_accuracy: 0.8474\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8472 - val_loss: 0.4116 - val_accuracy: 0.8474\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8470 - val_loss: 0.4092 - val_accuracy: 0.8466\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8473 - val_loss: 0.4089 - val_accuracy: 0.8448\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8472 - val_loss: 0.4106 - val_accuracy: 0.8459\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8474 - val_loss: 0.4094 - val_accuracy: 0.8466\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8467 - val_loss: 0.4098 - val_accuracy: 0.8504\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8485 - val_loss: 0.4085 - val_accuracy: 0.8448\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8471 - val_loss: 0.4084 - val_accuracy: 0.8485\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8476 - val_loss: 0.4066 - val_accuracy: 0.8459\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8465 - val_loss: 0.4113 - val_accuracy: 0.8466\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8475 - val_loss: 0.4081 - val_accuracy: 0.8496\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8488 - val_loss: 0.4082 - val_accuracy: 0.8437\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8484 - val_loss: 0.4093 - val_accuracy: 0.8500\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8487 - val_loss: 0.4052 - val_accuracy: 0.8451\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8485 - val_loss: 0.4070 - val_accuracy: 0.8519\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8483 - val_loss: 0.4053 - val_accuracy: 0.8485\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8494 - val_loss: 0.4063 - val_accuracy: 0.8526\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8482 - val_loss: 0.4059 - val_accuracy: 0.8537\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8480 - val_loss: 0.4052 - val_accuracy: 0.8455\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8490 - val_loss: 0.4056 - val_accuracy: 0.8507\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8487 - val_loss: 0.4084 - val_accuracy: 0.8478\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8493 - val_loss: 0.4077 - val_accuracy: 0.8493\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8480 - val_loss: 0.4042 - val_accuracy: 0.8489\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8490 - val_loss: 0.4043 - val_accuracy: 0.8511\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8496 - val_loss: 0.4032 - val_accuracy: 0.8511\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8476 - val_loss: 0.4044 - val_accuracy: 0.8511\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8479 - val_loss: 0.4038 - val_accuracy: 0.8545\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8482 - val_loss: 0.4076 - val_accuracy: 0.8545\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8494 - val_loss: 0.4091 - val_accuracy: 0.8534\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8500 - val_loss: 0.4030 - val_accuracy: 0.8500\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8498 - val_loss: 0.4042 - val_accuracy: 0.8504\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8488 - val_loss: 0.4025 - val_accuracy: 0.8500\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8501 - val_loss: 0.4021 - val_accuracy: 0.8448\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8494 - val_loss: 0.4063 - val_accuracy: 0.8507\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8494 - val_loss: 0.4038 - val_accuracy: 0.8493\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8500 - val_loss: 0.4031 - val_accuracy: 0.8526\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8489 - val_loss: 0.4049 - val_accuracy: 0.8515\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8496 - val_loss: 0.4017 - val_accuracy: 0.8519\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8496 - val_loss: 0.4044 - val_accuracy: 0.8507\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8496 - val_loss: 0.4040 - val_accuracy: 0.8530\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8504 - val_loss: 0.4028 - val_accuracy: 0.8500\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8499 - val_loss: 0.4028 - val_accuracy: 0.8507\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8497 - val_loss: 0.4009 - val_accuracy: 0.8444\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8497 - val_loss: 0.4014 - val_accuracy: 0.8522\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8499 - val_loss: 0.4044 - val_accuracy: 0.8530\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8509 - val_loss: 0.4009 - val_accuracy: 0.8515\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8513 - val_loss: 0.4011 - val_accuracy: 0.8522\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8507 - val_loss: 0.3998 - val_accuracy: 0.8500\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8513 - val_loss: 0.4019 - val_accuracy: 0.8511\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8508 - val_loss: 0.3998 - val_accuracy: 0.8504\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8505 - val_loss: 0.4011 - val_accuracy: 0.8545\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8496 - val_loss: 0.3999 - val_accuracy: 0.8459\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8504 - val_loss: 0.3998 - val_accuracy: 0.8541\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8509 - val_loss: 0.4018 - val_accuracy: 0.8519\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8522 - val_loss: 0.4006 - val_accuracy: 0.8537\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8510 - val_loss: 0.3993 - val_accuracy: 0.8466\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8512 - val_loss: 0.3987 - val_accuracy: 0.8493\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8509 - val_loss: 0.4009 - val_accuracy: 0.8526\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8509 - val_loss: 0.4019 - val_accuracy: 0.8549\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8511 - val_loss: 0.4018 - val_accuracy: 0.8530\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8524 - val_loss: 0.4001 - val_accuracy: 0.8444\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8500 - val_loss: 0.3988 - val_accuracy: 0.8537\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8521 - val_loss: 0.3991 - val_accuracy: 0.8507\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8515 - val_loss: 0.3982 - val_accuracy: 0.8519\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8513 - val_loss: 0.4010 - val_accuracy: 0.8549\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8510 - val_loss: 0.3992 - val_accuracy: 0.8534\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8520 - val_loss: 0.3990 - val_accuracy: 0.8519\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8520 - val_loss: 0.3989 - val_accuracy: 0.8537\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8512 - val_loss: 0.3993 - val_accuracy: 0.8545\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8514 - val_loss: 0.3980 - val_accuracy: 0.8507\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8507 - val_loss: 0.3991 - val_accuracy: 0.8545\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8524 - val_loss: 0.3981 - val_accuracy: 0.8448\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8516 - val_loss: 0.4030 - val_accuracy: 0.8552\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8522 - val_loss: 0.3974 - val_accuracy: 0.8545\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8518 - val_loss: 0.3989 - val_accuracy: 0.8549\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8517 - val_loss: 0.3968 - val_accuracy: 0.8507\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8519 - val_loss: 0.3975 - val_accuracy: 0.8519\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8523 - val_loss: 0.3972 - val_accuracy: 0.8489\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8517 - val_loss: 0.3980 - val_accuracy: 0.8563\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8516 - val_loss: 0.3975 - val_accuracy: 0.8567\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8528 - val_loss: 0.3972 - val_accuracy: 0.8560\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8533 - val_loss: 0.3977 - val_accuracy: 0.8552\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8534 - val_loss: 0.3989 - val_accuracy: 0.8571\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8534 - val_loss: 0.3962 - val_accuracy: 0.8500\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8531 - val_loss: 0.3969 - val_accuracy: 0.8537\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8531 - val_loss: 0.3980 - val_accuracy: 0.8534\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8523 - val_loss: 0.3968 - val_accuracy: 0.8552\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8527 - val_loss: 0.3969 - val_accuracy: 0.8563\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8527 - val_loss: 0.3973 - val_accuracy: 0.8563\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8521 - val_loss: 0.3974 - val_accuracy: 0.8560\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████▏                         | 7/10 [11:25<04:53, 97.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3947819471359253, 0.8500643968582153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1211/40000 [00:00<00:03, 12103.14it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2447/40000 [00:00<00:03, 12248.47it/s]\u001b[A\n",
      "  9%|███████                                                                      | 3674/40000 [00:00<00:02, 12253.76it/s]\u001b[A\n",
      " 12%|█████████▍                                                                   | 4908/40000 [00:00<00:02, 12284.94it/s]\u001b[A\n",
      " 15%|███████████▊                                                                 | 6138/40000 [00:00<00:02, 12288.11it/s]\u001b[A\n",
      " 18%|██████████████▏                                                              | 7374/40000 [00:00<00:02, 12311.20it/s]\u001b[A\n",
      " 22%|████████████████▌                                                            | 8608/40000 [00:00<00:02, 12317.73it/s]\u001b[A\n",
      " 25%|██████████████████▉                                                          | 9844/40000 [00:00<00:02, 12328.64it/s]\u001b[A\n",
      " 28%|█████████████████████                                                       | 11084/40000 [00:00<00:02, 12348.41it/s]\u001b[A\n",
      " 31%|███████████████████████▍                                                    | 12324/40000 [00:01<00:02, 12363.59it/s]\u001b[A\n",
      " 34%|█████████████████████████▊                                                  | 13567/40000 [00:01<00:02, 12381.82it/s]\u001b[A\n",
      " 37%|████████████████████████████▏                                               | 14807/40000 [00:01<00:02, 12386.36it/s]\u001b[A\n",
      " 40%|██████████████████████████████▍                                             | 16046/40000 [00:01<00:01, 12381.88it/s]\u001b[A\n",
      " 43%|████████████████████████████████▊                                           | 17286/40000 [00:01<00:01, 12386.91it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▏                                        | 18525/40000 [00:01<00:01, 12374.51it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▌                                      | 19763/40000 [00:01<00:01, 12374.69it/s]\u001b[A\n",
      " 53%|███████████████████████████████████████▉                                    | 21001/40000 [00:01<00:01, 12372.11it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▎                                 | 22239/40000 [00:01<00:01, 12370.61it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▌                               | 23477/40000 [00:01<00:01, 12367.63it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▉                             | 24714/40000 [00:02<00:01, 12367.55it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▎                          | 25951/40000 [00:02<00:01, 12363.76it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▋                        | 27189/40000 [00:02<00:01, 12365.88it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████                      | 28426/40000 [00:02<00:00, 12355.28it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▎                   | 29665/40000 [00:02<00:00, 12363.68it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▋                 | 30902/40000 [00:02<00:00, 12358.39it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████               | 32140/40000 [00:02<00:00, 12363.82it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▍            | 33378/40000 [00:02<00:00, 12365.96it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▊          | 34615/40000 [00:02<00:00, 12362.48it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████        | 35852/40000 [00:02<00:00, 12354.63it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▍     | 37092/40000 [00:03<00:00, 12366.38it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▊   | 38330/40000 [00:03<00:00, 12370.18it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12349.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "(40000, 4)\n",
      "(39996, 10) (39996, 4)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.3057 - accuracy: 0.4103 - val_loss: 1.1329 - val_accuracy: 0.5828\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.0212 - accuracy: 0.6970 - val_loss: 0.9342 - val_accuracy: 0.7563\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8658 - accuracy: 0.7978 - val_loss: 0.8127 - val_accuracy: 0.8127\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7639 - accuracy: 0.8294 - val_loss: 0.7231 - val_accuracy: 0.8418\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.8474 - val_loss: 0.6598 - val_accuracy: 0.8522\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.8567 - val_loss: 0.6113 - val_accuracy: 0.8608\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.8649 - val_loss: 0.5732 - val_accuracy: 0.8668\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.8710 - val_loss: 0.5393 - val_accuracy: 0.8731\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.8754 - val_loss: 0.5144 - val_accuracy: 0.8761\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8784 - val_loss: 0.4918 - val_accuracy: 0.8780\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8814 - val_loss: 0.4727 - val_accuracy: 0.8825\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8821 - val_loss: 0.4560 - val_accuracy: 0.8858\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8846 - val_loss: 0.4414 - val_accuracy: 0.8892\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8858 - val_loss: 0.4295 - val_accuracy: 0.8884\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8871 - val_loss: 0.4185 - val_accuracy: 0.8884\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8873 - val_loss: 0.4080 - val_accuracy: 0.8873\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8873 - val_loss: 0.3986 - val_accuracy: 0.8910\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8895 - val_loss: 0.3923 - val_accuracy: 0.8877\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8893 - val_loss: 0.3838 - val_accuracy: 0.8903\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8901 - val_loss: 0.3769 - val_accuracy: 0.8907\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8901 - val_loss: 0.3713 - val_accuracy: 0.8918\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8909 - val_loss: 0.3668 - val_accuracy: 0.8884\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8913 - val_loss: 0.3605 - val_accuracy: 0.8948\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8912 - val_loss: 0.3605 - val_accuracy: 0.8873\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8919 - val_loss: 0.3514 - val_accuracy: 0.8925\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8920 - val_loss: 0.3489 - val_accuracy: 0.8914\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8921 - val_loss: 0.3446 - val_accuracy: 0.8922\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8919 - val_loss: 0.3404 - val_accuracy: 0.8922\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8929 - val_loss: 0.3383 - val_accuracy: 0.8925\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8939 - val_loss: 0.3377 - val_accuracy: 0.8899\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8936 - val_loss: 0.3327 - val_accuracy: 0.8922\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8931 - val_loss: 0.3303 - val_accuracy: 0.8944\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8935 - val_loss: 0.3278 - val_accuracy: 0.8933\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8934 - val_loss: 0.3262 - val_accuracy: 0.8948\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8934 - val_loss: 0.3255 - val_accuracy: 0.8940\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8938 - val_loss: 0.3217 - val_accuracy: 0.8951\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8942 - val_loss: 0.3211 - val_accuracy: 0.8951\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8941 - val_loss: 0.3197 - val_accuracy: 0.8940\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8936 - val_loss: 0.3183 - val_accuracy: 0.8944\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8946 - val_loss: 0.3166 - val_accuracy: 0.8951\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8939 - val_loss: 0.3167 - val_accuracy: 0.8944\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8938 - val_loss: 0.3121 - val_accuracy: 0.8951\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8939 - val_loss: 0.3147 - val_accuracy: 0.8944\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8943 - val_loss: 0.3099 - val_accuracy: 0.8981\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8943 - val_loss: 0.3098 - val_accuracy: 0.8963\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8943 - val_loss: 0.3090 - val_accuracy: 0.8974\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8937 - val_loss: 0.3116 - val_accuracy: 0.8940\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8944 - val_loss: 0.3059 - val_accuracy: 0.8974\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8948 - val_loss: 0.3057 - val_accuracy: 0.8970\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8936 - val_loss: 0.3041 - val_accuracy: 0.8970\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8942 - val_loss: 0.3053 - val_accuracy: 0.8966\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8946 - val_loss: 0.3028 - val_accuracy: 0.8966\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8942 - val_loss: 0.3024 - val_accuracy: 0.8970\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8942 - val_loss: 0.3024 - val_accuracy: 0.8966\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8953 - val_loss: 0.3018 - val_accuracy: 0.8981\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8943 - val_loss: 0.3001 - val_accuracy: 0.8970\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8951 - val_loss: 0.2998 - val_accuracy: 0.8985\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8945 - val_loss: 0.3005 - val_accuracy: 0.8981\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8951 - val_loss: 0.2991 - val_accuracy: 0.8985\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8950 - val_loss: 0.2979 - val_accuracy: 0.8978\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8949 - val_loss: 0.2970 - val_accuracy: 0.8981\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8948 - val_loss: 0.2975 - val_accuracy: 0.8974\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8945 - val_loss: 0.2967 - val_accuracy: 0.9004\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8952 - val_loss: 0.2958 - val_accuracy: 0.8993\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8945 - val_loss: 0.2958 - val_accuracy: 0.8978\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8953 - val_loss: 0.2949 - val_accuracy: 0.8981\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8953 - val_loss: 0.2949 - val_accuracy: 0.8993\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8939 - val_loss: 0.2947 - val_accuracy: 0.8966\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8955 - val_loss: 0.2970 - val_accuracy: 0.8951\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8951 - val_loss: 0.2948 - val_accuracy: 0.8966\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8952 - val_loss: 0.2935 - val_accuracy: 0.8978\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.8949 - val_loss: 0.2952 - val_accuracy: 0.8951\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8959 - val_loss: 0.2936 - val_accuracy: 0.8974\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8951 - val_loss: 0.2921 - val_accuracy: 0.9000\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8951 - val_loss: 0.2931 - val_accuracy: 0.8974\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8956 - val_loss: 0.2914 - val_accuracy: 0.8993\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8956 - val_loss: 0.2925 - val_accuracy: 0.8970\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.8960 - val_loss: 0.2915 - val_accuracy: 0.8996\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.8951 - val_loss: 0.2912 - val_accuracy: 0.8985\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8957 - val_loss: 0.2907 - val_accuracy: 0.8993\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8962 - val_loss: 0.2910 - val_accuracy: 0.8985\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8947 - val_loss: 0.2904 - val_accuracy: 0.8989\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8958 - val_loss: 0.2898 - val_accuracy: 0.8985\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8963 - val_loss: 0.2898 - val_accuracy: 0.8996\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.8954 - val_loss: 0.2904 - val_accuracy: 0.8978\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.8954 - val_loss: 0.2895 - val_accuracy: 0.8985\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.8953 - val_loss: 0.2901 - val_accuracy: 0.8978\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8950 - val_loss: 0.2898 - val_accuracy: 0.8993\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8956 - val_loss: 0.2889 - val_accuracy: 0.8993\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8957 - val_loss: 0.2883 - val_accuracy: 0.8996\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8952 - val_loss: 0.2893 - val_accuracy: 0.8978\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8954 - val_loss: 0.2887 - val_accuracy: 0.8985\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8949 - val_loss: 0.2892 - val_accuracy: 0.8993\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8949 - val_loss: 0.2890 - val_accuracy: 0.8970\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2919 - accuracy: 0.8955 - val_loss: 0.2887 - val_accuracy: 0.8974\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8946 - val_loss: 0.2882 - val_accuracy: 0.8993\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8951 - val_loss: 0.2870 - val_accuracy: 0.8993\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.8952 - val_loss: 0.2891 - val_accuracy: 0.8959\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8950 - val_loss: 0.2869 - val_accuracy: 0.9004\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.8955 - val_loss: 0.2874 - val_accuracy: 0.9004\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8947 - val_loss: 0.2879 - val_accuracy: 0.8985\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8952 - val_loss: 0.2876 - val_accuracy: 0.8989\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8957 - val_loss: 0.2916 - val_accuracy: 0.8959\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.8951 - val_loss: 0.2868 - val_accuracy: 0.8985\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8960 - val_loss: 0.2868 - val_accuracy: 0.8989\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8949 - val_loss: 0.2880 - val_accuracy: 0.8970\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8951 - val_loss: 0.2866 - val_accuracy: 0.8989\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8950 - val_loss: 0.2862 - val_accuracy: 0.9004\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.8964 - val_loss: 0.2855 - val_accuracy: 0.8985\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.8956 - val_loss: 0.2852 - val_accuracy: 0.9011\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8959 - val_loss: 0.2863 - val_accuracy: 0.8989\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8955 - val_loss: 0.2856 - val_accuracy: 0.9000\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8959 - val_loss: 0.2854 - val_accuracy: 0.8996\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8954 - val_loss: 0.2855 - val_accuracy: 0.9015\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8957 - val_loss: 0.2858 - val_accuracy: 0.8989\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8950 - val_loss: 0.2854 - val_accuracy: 0.9004\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.8956 - val_loss: 0.2847 - val_accuracy: 0.8985\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8962 - val_loss: 0.2888 - val_accuracy: 0.8963\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8963 - val_loss: 0.2864 - val_accuracy: 0.8970\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.8958 - val_loss: 0.2862 - val_accuracy: 0.8996\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8952 - val_loss: 0.2844 - val_accuracy: 0.9007\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8953 - val_loss: 0.2858 - val_accuracy: 0.8996\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8955 - val_loss: 0.2851 - val_accuracy: 0.9004\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8956 - val_loss: 0.2845 - val_accuracy: 0.9019\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8963 - val_loss: 0.2849 - val_accuracy: 0.8978\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8956 - val_loss: 0.2857 - val_accuracy: 0.8993\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8953 - val_loss: 0.2845 - val_accuracy: 0.8993\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8949 - val_loss: 0.2835 - val_accuracy: 0.9011\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8951 - val_loss: 0.2844 - val_accuracy: 0.9004\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8954 - val_loss: 0.2842 - val_accuracy: 0.9011\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.8956 - val_loss: 0.2833 - val_accuracy: 0.9011\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8953 - val_loss: 0.2831 - val_accuracy: 0.9019\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8956 - val_loss: 0.2837 - val_accuracy: 0.9000\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8957 - val_loss: 0.2841 - val_accuracy: 0.9007\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.8954 - val_loss: 0.2834 - val_accuracy: 0.9007\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8955 - val_loss: 0.2827 - val_accuracy: 0.9007\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8964 - val_loss: 0.2854 - val_accuracy: 0.9000\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8960 - val_loss: 0.2828 - val_accuracy: 0.9004\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8967 - val_loss: 0.2848 - val_accuracy: 0.8993\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8952 - val_loss: 0.2829 - val_accuracy: 0.9007\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8951 - val_loss: 0.2840 - val_accuracy: 0.9011\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8952 - val_loss: 0.2835 - val_accuracy: 0.8989\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8966 - val_loss: 0.2827 - val_accuracy: 0.8996\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8959 - val_loss: 0.2834 - val_accuracy: 0.9000\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8958 - val_loss: 0.2842 - val_accuracy: 0.9004\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.8956 - val_loss: 0.2839 - val_accuracy: 0.9000\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8954 - val_loss: 0.2821 - val_accuracy: 0.9011\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8966 - val_loss: 0.2854 - val_accuracy: 0.8993\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8949 - val_loss: 0.2820 - val_accuracy: 0.9015\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8956 - val_loss: 0.2830 - val_accuracy: 0.9004\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.2846 - accuracy: 0.8989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████▊                 | 8/10 [13:02<03:15, 97.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2846096456050873, 0.8989317417144775]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1187/40000 [00:00<00:03, 11866.62it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2415/40000 [00:00<00:03, 12104.62it/s]\u001b[A\n",
      "  9%|███████                                                                      | 3645/40000 [00:00<00:02, 12193.61it/s]\u001b[A\n",
      " 12%|█████████▍                                                                   | 4874/40000 [00:00<00:02, 12230.17it/s]\u001b[A\n",
      " 15%|███████████▊                                                                 | 6105/40000 [00:00<00:02, 12257.98it/s]\u001b[A\n",
      " 18%|██████████████                                                               | 7334/40000 [00:00<00:02, 12267.22it/s]\u001b[A\n",
      " 21%|████████████████▍                                                            | 8566/40000 [00:00<00:02, 12282.12it/s]\u001b[A\n",
      " 24%|██████████████████▊                                                          | 9795/40000 [00:00<00:02, 12272.34it/s]\u001b[A\n",
      " 28%|████████████████████▉                                                       | 11032/40000 [00:00<00:02, 12300.06it/s]\u001b[A\n",
      " 31%|███████████████████████▎                                                    | 12268/40000 [00:01<00:02, 12316.62it/s]\u001b[A\n",
      " 34%|█████████████████████████▋                                                  | 13504/40000 [00:01<00:02, 12329.39it/s]\u001b[A\n",
      " 37%|████████████████████████████                                                | 14737/40000 [00:01<00:02, 12277.69it/s]\u001b[A\n",
      " 40%|██████████████████████████████▎                                             | 15975/40000 [00:01<00:01, 12306.60it/s]\u001b[A\n",
      " 43%|████████████████████████████████▋                                           | 17212/40000 [00:01<00:01, 12322.78it/s]\u001b[A\n",
      " 46%|███████████████████████████████████                                         | 18445/40000 [00:01<00:01, 12323.03it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▍                                      | 19680/40000 [00:01<00:01, 12330.76it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▋                                    | 20914/40000 [00:01<00:01, 12329.67it/s]\u001b[A\n",
      " 55%|██████████████████████████████████████████                                  | 22147/40000 [00:01<00:01, 12322.03it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████▍                               | 23380/40000 [00:01<00:01, 12320.98it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▊                             | 24614/40000 [00:02<00:01, 12325.44it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████                           | 25847/40000 [00:02<00:01, 12324.37it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▍                        | 27081/40000 [00:02<00:01, 12327.56it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▊                      | 28314/40000 [00:02<00:00, 12323.53it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▏                   | 29551/40000 [00:02<00:00, 12337.24it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▍                 | 30786/40000 [00:02<00:00, 12338.14it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▊               | 32020/40000 [00:02<00:00, 12230.58it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▏            | 33244/40000 [00:02<00:00, 12216.79it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████▍          | 34473/40000 [00:02<00:00, 12236.37it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████▊        | 35705/40000 [00:02<00:00, 12260.47it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████▏     | 36933/40000 [00:03<00:00, 12265.32it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████▌   | 38161/40000 [00:03<00:00, 12269.51it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12280.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "(40000, 4)\n",
      "(39996, 10) (39996, 4)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.2250 - accuracy: 0.4566 - val_loss: 0.9800 - val_accuracy: 0.6612\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.8824 - accuracy: 0.7143 - val_loss: 0.7927 - val_accuracy: 0.7373\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.7513 - val_loss: 0.7026 - val_accuracy: 0.7560\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.7658 - val_loss: 0.6494 - val_accuracy: 0.7791\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.7720 - val_loss: 0.6153 - val_accuracy: 0.7825\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.7792 - val_loss: 0.5909 - val_accuracy: 0.8026\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7845 - val_loss: 0.5749 - val_accuracy: 0.7791\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7860 - val_loss: 0.5581 - val_accuracy: 0.8034\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7899 - val_loss: 0.5474 - val_accuracy: 0.8019\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7917 - val_loss: 0.5400 - val_accuracy: 0.7899\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7935 - val_loss: 0.5309 - val_accuracy: 0.8022\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7959 - val_loss: 0.5277 - val_accuracy: 0.7937\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7967 - val_loss: 0.5194 - val_accuracy: 0.8041\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.8037\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7992 - val_loss: 0.5079 - val_accuracy: 0.8112\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8002 - val_loss: 0.5059 - val_accuracy: 0.8071\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8001 - val_loss: 0.5065 - val_accuracy: 0.7925\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7998 - val_loss: 0.4993 - val_accuracy: 0.8034\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8003 - val_loss: 0.4965 - val_accuracy: 0.8093\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8005 - val_loss: 0.4950 - val_accuracy: 0.8090\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8026 - val_loss: 0.4918 - val_accuracy: 0.8041\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8030 - val_loss: 0.4909 - val_accuracy: 0.8075\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8024 - val_loss: 0.4893 - val_accuracy: 0.8108\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8024 - val_loss: 0.4873 - val_accuracy: 0.8205\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8041 - val_loss: 0.4883 - val_accuracy: 0.8075\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8041 - val_loss: 0.4839 - val_accuracy: 0.8086\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8031 - val_loss: 0.4853 - val_accuracy: 0.8112\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8044 - val_loss: 0.4819 - val_accuracy: 0.8108\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8044 - val_loss: 0.4818 - val_accuracy: 0.8086\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8037 - val_loss: 0.4803 - val_accuracy: 0.8112\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8032 - val_loss: 0.4793 - val_accuracy: 0.8104\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8047 - val_loss: 0.4789 - val_accuracy: 0.8104\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8058 - val_loss: 0.4780 - val_accuracy: 0.8101\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8057 - val_loss: 0.4759 - val_accuracy: 0.8205\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8047 - val_loss: 0.4778 - val_accuracy: 0.8093\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8060 - val_loss: 0.4771 - val_accuracy: 0.8078\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8056 - val_loss: 0.4746 - val_accuracy: 0.8138\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8064 - val_loss: 0.4746 - val_accuracy: 0.8104\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8054 - val_loss: 0.4759 - val_accuracy: 0.8123\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8076 - val_loss: 0.4732 - val_accuracy: 0.8123\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8067 - val_loss: 0.4740 - val_accuracy: 0.8078\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8044 - val_loss: 0.4710 - val_accuracy: 0.8190\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8063 - val_loss: 0.4722 - val_accuracy: 0.8119\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8076 - val_loss: 0.4753 - val_accuracy: 0.8030\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8069 - val_loss: 0.4698 - val_accuracy: 0.8112\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8074 - val_loss: 0.4730 - val_accuracy: 0.8049\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8085 - val_loss: 0.4746 - val_accuracy: 0.8045\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8063 - val_loss: 0.4686 - val_accuracy: 0.8187\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8070 - val_loss: 0.4687 - val_accuracy: 0.8142\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8077 - val_loss: 0.4724 - val_accuracy: 0.8049\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8062 - val_loss: 0.4692 - val_accuracy: 0.8157\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8066 - val_loss: 0.4697 - val_accuracy: 0.8034\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8070 - val_loss: 0.4690 - val_accuracy: 0.8123\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8078 - val_loss: 0.4665 - val_accuracy: 0.8194\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8073 - val_loss: 0.4668 - val_accuracy: 0.8194\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8093 - val_loss: 0.4689 - val_accuracy: 0.8112\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8073 - val_loss: 0.4662 - val_accuracy: 0.8190\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8086 - val_loss: 0.4661 - val_accuracy: 0.8201\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8086 - val_loss: 0.4696 - val_accuracy: 0.8078\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8086 - val_loss: 0.4647 - val_accuracy: 0.8175\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8074 - val_loss: 0.4662 - val_accuracy: 0.8190\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8081 - val_loss: 0.4664 - val_accuracy: 0.8157\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8078 - val_loss: 0.4664 - val_accuracy: 0.8078\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8076 - val_loss: 0.4651 - val_accuracy: 0.8228\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8076 - val_loss: 0.4676 - val_accuracy: 0.8082\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8075 - val_loss: 0.4646 - val_accuracy: 0.8097\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8070 - val_loss: 0.4655 - val_accuracy: 0.8112\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8092 - val_loss: 0.4657 - val_accuracy: 0.8116\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8079 - val_loss: 0.4658 - val_accuracy: 0.8049\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8080 - val_loss: 0.4648 - val_accuracy: 0.8149\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.8090 - val_loss: 0.4630 - val_accuracy: 0.8123\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8080 - val_loss: 0.4677 - val_accuracy: 0.8071\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8082 - val_loss: 0.4624 - val_accuracy: 0.8198\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8092 - val_loss: 0.4631 - val_accuracy: 0.8157\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8069 - val_loss: 0.4623 - val_accuracy: 0.8153\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8086 - val_loss: 0.4641 - val_accuracy: 0.8123\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8084 - val_loss: 0.4627 - val_accuracy: 0.8164\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8071 - val_loss: 0.4620 - val_accuracy: 0.8213\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8108 - val_loss: 0.4656 - val_accuracy: 0.8041\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8088 - val_loss: 0.4647 - val_accuracy: 0.8082\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8088 - val_loss: 0.4619 - val_accuracy: 0.8205\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8093 - val_loss: 0.4618 - val_accuracy: 0.8164\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8079 - val_loss: 0.4616 - val_accuracy: 0.8168\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8093 - val_loss: 0.4625 - val_accuracy: 0.8146\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8102 - val_loss: 0.4615 - val_accuracy: 0.8101\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8098 - val_loss: 0.4603 - val_accuracy: 0.8134\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8095 - val_loss: 0.4638 - val_accuracy: 0.8104\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8100 - val_loss: 0.4645 - val_accuracy: 0.8034\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8099 - val_loss: 0.4622 - val_accuracy: 0.8138\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8095 - val_loss: 0.4603 - val_accuracy: 0.8198\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8086 - val_loss: 0.4601 - val_accuracy: 0.8134\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8091 - val_loss: 0.4637 - val_accuracy: 0.8056\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8092 - val_loss: 0.4599 - val_accuracy: 0.8228\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8097 - val_loss: 0.4619 - val_accuracy: 0.8160\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8093 - val_loss: 0.4593 - val_accuracy: 0.8172\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8096 - val_loss: 0.4592 - val_accuracy: 0.8187\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8115 - val_loss: 0.4590 - val_accuracy: 0.8160\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.8096 - val_loss: 0.4589 - val_accuracy: 0.8187\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8113 - val_loss: 0.4608 - val_accuracy: 0.8127\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8103 - val_loss: 0.4616 - val_accuracy: 0.8056\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8110 - val_loss: 0.4594 - val_accuracy: 0.8138\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8101 - val_loss: 0.4615 - val_accuracy: 0.8119\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8092 - val_loss: 0.4615 - val_accuracy: 0.8052\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8098 - val_loss: 0.4603 - val_accuracy: 0.8142\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8097 - val_loss: 0.4595 - val_accuracy: 0.8123\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8106 - val_loss: 0.4596 - val_accuracy: 0.8153\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8105 - val_loss: 0.4676 - val_accuracy: 0.8075\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8115 - val_loss: 0.4578 - val_accuracy: 0.8175\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8091 - val_loss: 0.4578 - val_accuracy: 0.8157\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8103 - val_loss: 0.4598 - val_accuracy: 0.8101\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8113 - val_loss: 0.4575 - val_accuracy: 0.8179\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8096 - val_loss: 0.4579 - val_accuracy: 0.8198\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8111 - val_loss: 0.4643 - val_accuracy: 0.8052\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8103 - val_loss: 0.4570 - val_accuracy: 0.8183\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8121 - val_loss: 0.4599 - val_accuracy: 0.8060\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8103 - val_loss: 0.4570 - val_accuracy: 0.8179\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8101 - val_loss: 0.4595 - val_accuracy: 0.8134\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8111 - val_loss: 0.4597 - val_accuracy: 0.8123\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8113 - val_loss: 0.4584 - val_accuracy: 0.8138\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8102 - val_loss: 0.4587 - val_accuracy: 0.8146\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8105 - val_loss: 0.4590 - val_accuracy: 0.8127\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8117 - val_loss: 0.4576 - val_accuracy: 0.8123\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8110 - val_loss: 0.4576 - val_accuracy: 0.8187\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8094 - val_loss: 0.4584 - val_accuracy: 0.8097\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8095 - val_loss: 0.4614 - val_accuracy: 0.8104\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8112 - val_loss: 0.4577 - val_accuracy: 0.8123\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8108 - val_loss: 0.4589 - val_accuracy: 0.8127\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8116 - val_loss: 0.4563 - val_accuracy: 0.8201\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8102 - val_loss: 0.4565 - val_accuracy: 0.8187\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8105 - val_loss: 0.4560 - val_accuracy: 0.8175\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8109 - val_loss: 0.4569 - val_accuracy: 0.8209\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8122 - val_loss: 0.4575 - val_accuracy: 0.8153\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8111 - val_loss: 0.4575 - val_accuracy: 0.8201\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8115 - val_loss: 0.4565 - val_accuracy: 0.8138\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8123 - val_loss: 0.4563 - val_accuracy: 0.8190\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8114 - val_loss: 0.4594 - val_accuracy: 0.8093\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8108 - val_loss: 0.4563 - val_accuracy: 0.8187\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8114 - val_loss: 0.4555 - val_accuracy: 0.8164\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8120 - val_loss: 0.4585 - val_accuracy: 0.8112\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8121 - val_loss: 0.4597 - val_accuracy: 0.8067\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8130 - val_loss: 0.4570 - val_accuracy: 0.8108\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8123 - val_loss: 0.4570 - val_accuracy: 0.8104\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8123 - val_loss: 0.4550 - val_accuracy: 0.8179\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8111 - val_loss: 0.4566 - val_accuracy: 0.8157\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8117 - val_loss: 0.4550 - val_accuracy: 0.8179\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8121 - val_loss: 0.4551 - val_accuracy: 0.8190\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8118 - val_loss: 0.4545 - val_accuracy: 0.8175\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8132 - val_loss: 0.4555 - val_accuracy: 0.8213\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8120 - val_loss: 0.4575 - val_accuracy: 0.8075\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8103 - val_loss: 0.4552 - val_accuracy: 0.8138\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.4572 - accuracy: 0.8137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████▍        | 9/10 [14:41<01:37, 97.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45720335841178894, 0.8136979937553406]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1250/40000 [00:00<00:03, 12493.07it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2500/40000 [00:00<00:03, 12390.31it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3740/40000 [00:00<00:02, 12338.25it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4974/40000 [00:00<00:02, 12325.05it/s]\u001b[A\n",
      " 16%|███████████▉                                                                 | 6207/40000 [00:00<00:02, 12321.16it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7440/40000 [00:00<00:02, 12318.48it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8673/40000 [00:00<00:02, 12319.96it/s]\u001b[A\n",
      " 25%|███████████████████                                                          | 9905/40000 [00:00<00:02, 12319.63it/s]\u001b[A\n",
      " 28%|█████████████████████▏                                                      | 11137/40000 [00:00<00:02, 12315.72it/s]\u001b[A\n",
      " 31%|███████████████████████▌                                                    | 12370/40000 [00:01<00:02, 12318.52it/s]\u001b[A\n",
      " 34%|█████████████████████████▊                                                  | 13606/40000 [00:01<00:02, 12328.50it/s]\u001b[A\n",
      " 37%|████████████████████████████▏                                               | 14841/40000 [00:01<00:02, 12332.83it/s]\u001b[A\n",
      " 40%|██████████████████████████████▌                                             | 16075/40000 [00:01<00:01, 12333.82it/s]\u001b[A\n",
      " 43%|████████████████████████████████▉                                           | 17310/40000 [00:01<00:01, 12336.66it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▏                                        | 18544/40000 [00:01<00:01, 12326.95it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▌                                      | 19778/40000 [00:01<00:01, 12329.30it/s]\u001b[A\n",
      " 53%|███████████████████████████████████████▉                                    | 21012/40000 [00:01<00:01, 12330.06it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▎                                 | 22246/40000 [00:01<00:01, 12327.93it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▌                               | 23483/40000 [00:01<00:01, 12339.32it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▉                             | 24717/40000 [00:02<00:01, 12338.49it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▎                          | 25951/40000 [00:02<00:01, 12338.44it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▋                        | 27188/40000 [00:02<00:01, 12347.27it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████                      | 28427/40000 [00:02<00:00, 12359.18it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▎                   | 29663/40000 [00:02<00:00, 12340.32it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▋                 | 30899/40000 [00:02<00:00, 12344.21it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████               | 32136/40000 [00:02<00:00, 12350.20it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▍            | 33372/40000 [00:02<00:00, 12351.33it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▊          | 34608/40000 [00:02<00:00, 12351.70it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████        | 35844/40000 [00:02<00:00, 12345.45it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▍     | 37080/40000 [00:03<00:00, 12347.01it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▊   | 38315/40000 [00:03<00:00, 12340.19it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12329.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "(40000, 4)\n",
      "(39996, 10) (39996, 4)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.2498 - accuracy: 0.4794 - val_loss: 1.0407 - val_accuracy: 0.6690\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9329 - accuracy: 0.7229 - val_loss: 0.8233 - val_accuracy: 0.7937\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7662 - accuracy: 0.8277 - val_loss: 0.6973 - val_accuracy: 0.8437\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.8411 - val_loss: 0.6221 - val_accuracy: 0.8485\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.8450 - val_loss: 0.5725 - val_accuracy: 0.8429\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.8439 - val_loss: 0.5358 - val_accuracy: 0.8504\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.8453 - val_loss: 0.5148 - val_accuracy: 0.8425\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.8466 - val_loss: 0.4907 - val_accuracy: 0.8489\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8471 - val_loss: 0.4760 - val_accuracy: 0.8504\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8478 - val_loss: 0.4637 - val_accuracy: 0.8530\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8485 - val_loss: 0.4525 - val_accuracy: 0.8537\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8496 - val_loss: 0.4448 - val_accuracy: 0.8541\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8501 - val_loss: 0.4370 - val_accuracy: 0.8563\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8509 - val_loss: 0.4334 - val_accuracy: 0.8530\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8518 - val_loss: 0.4249 - val_accuracy: 0.8604\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8521 - val_loss: 0.4196 - val_accuracy: 0.8604\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8526 - val_loss: 0.4155 - val_accuracy: 0.8619\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8528 - val_loss: 0.4133 - val_accuracy: 0.8586\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8538 - val_loss: 0.4087 - val_accuracy: 0.8627\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8536 - val_loss: 0.4051 - val_accuracy: 0.8634\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8538 - val_loss: 0.4039 - val_accuracy: 0.8593\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8534 - val_loss: 0.3998 - val_accuracy: 0.8642\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8557 - val_loss: 0.3988 - val_accuracy: 0.8597\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8555 - val_loss: 0.3954 - val_accuracy: 0.8642\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8550 - val_loss: 0.3958 - val_accuracy: 0.8619\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8555 - val_loss: 0.3903 - val_accuracy: 0.8653\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8560 - val_loss: 0.3889 - val_accuracy: 0.8646\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8558 - val_loss: 0.3876 - val_accuracy: 0.8653\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8564 - val_loss: 0.3867 - val_accuracy: 0.8649\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8560 - val_loss: 0.3851 - val_accuracy: 0.8649\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8571 - val_loss: 0.3854 - val_accuracy: 0.8649\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8578 - val_loss: 0.3855 - val_accuracy: 0.8627\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8576 - val_loss: 0.3815 - val_accuracy: 0.8660\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8571 - val_loss: 0.3836 - val_accuracy: 0.8627\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8565 - val_loss: 0.3829 - val_accuracy: 0.8631\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8573 - val_loss: 0.3787 - val_accuracy: 0.8653\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8574 - val_loss: 0.3792 - val_accuracy: 0.8653\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8585 - val_loss: 0.3784 - val_accuracy: 0.8623\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8579 - val_loss: 0.3790 - val_accuracy: 0.8668\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8583 - val_loss: 0.3768 - val_accuracy: 0.8657\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8574 - val_loss: 0.3761 - val_accuracy: 0.8672\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8588 - val_loss: 0.3755 - val_accuracy: 0.8646\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8581 - val_loss: 0.3759 - val_accuracy: 0.8642\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8586 - val_loss: 0.3761 - val_accuracy: 0.8657\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8579 - val_loss: 0.3736 - val_accuracy: 0.8672\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8589 - val_loss: 0.3742 - val_accuracy: 0.8653\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8596 - val_loss: 0.3742 - val_accuracy: 0.8623\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8582 - val_loss: 0.3744 - val_accuracy: 0.8668\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8589 - val_loss: 0.3721 - val_accuracy: 0.8683\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8590 - val_loss: 0.3718 - val_accuracy: 0.8660\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8586 - val_loss: 0.3716 - val_accuracy: 0.8646\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8583 - val_loss: 0.3720 - val_accuracy: 0.8660\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8599 - val_loss: 0.3724 - val_accuracy: 0.8668\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8595 - val_loss: 0.3739 - val_accuracy: 0.8627\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8598 - val_loss: 0.3709 - val_accuracy: 0.8657\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8598 - val_loss: 0.3714 - val_accuracy: 0.8664\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8594 - val_loss: 0.3702 - val_accuracy: 0.8653\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8601 - val_loss: 0.3710 - val_accuracy: 0.8660\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8588 - val_loss: 0.3728 - val_accuracy: 0.8653\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8589 - val_loss: 0.3705 - val_accuracy: 0.8668\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8594 - val_loss: 0.3702 - val_accuracy: 0.8664\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8601 - val_loss: 0.3714 - val_accuracy: 0.8660\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8606 - val_loss: 0.3688 - val_accuracy: 0.8660\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8600 - val_loss: 0.3689 - val_accuracy: 0.8672\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8602 - val_loss: 0.3680 - val_accuracy: 0.8675\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8603 - val_loss: 0.3686 - val_accuracy: 0.8668\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8595 - val_loss: 0.3694 - val_accuracy: 0.8660\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8606 - val_loss: 0.3694 - val_accuracy: 0.8668\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8600 - val_loss: 0.3686 - val_accuracy: 0.8660\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8600 - val_loss: 0.3712 - val_accuracy: 0.8668\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8609 - val_loss: 0.3680 - val_accuracy: 0.8660\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8600 - val_loss: 0.3689 - val_accuracy: 0.8668\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8589 - val_loss: 0.3691 - val_accuracy: 0.8672\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8598 - val_loss: 0.3672 - val_accuracy: 0.8675\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8596 - val_loss: 0.3679 - val_accuracy: 0.8664\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8608 - val_loss: 0.3676 - val_accuracy: 0.8675\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8602 - val_loss: 0.3689 - val_accuracy: 0.8672\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8615 - val_loss: 0.3669 - val_accuracy: 0.8672\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8599 - val_loss: 0.3664 - val_accuracy: 0.8675\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8606 - val_loss: 0.3662 - val_accuracy: 0.8672\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8610 - val_loss: 0.3676 - val_accuracy: 0.8664\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8595 - val_loss: 0.3699 - val_accuracy: 0.8668\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8604 - val_loss: 0.3661 - val_accuracy: 0.8668\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8607 - val_loss: 0.3668 - val_accuracy: 0.8672\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8609 - val_loss: 0.3658 - val_accuracy: 0.8672\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8607 - val_loss: 0.3679 - val_accuracy: 0.8664\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8608 - val_loss: 0.3677 - val_accuracy: 0.8660\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8606 - val_loss: 0.3666 - val_accuracy: 0.8668\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8611 - val_loss: 0.3659 - val_accuracy: 0.8679\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8613 - val_loss: 0.3655 - val_accuracy: 0.8679\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8613 - val_loss: 0.3657 - val_accuracy: 0.8679\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8613 - val_loss: 0.3673 - val_accuracy: 0.8672\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8613 - val_loss: 0.3653 - val_accuracy: 0.8679\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8611 - val_loss: 0.3650 - val_accuracy: 0.8679\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8611 - val_loss: 0.3655 - val_accuracy: 0.8668\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8604 - val_loss: 0.3670 - val_accuracy: 0.8664\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8615 - val_loss: 0.3651 - val_accuracy: 0.8679\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8612 - val_loss: 0.3650 - val_accuracy: 0.8679\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8605 - val_loss: 0.3657 - val_accuracy: 0.8668\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8618 - val_loss: 0.3656 - val_accuracy: 0.8675\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8610 - val_loss: 0.3674 - val_accuracy: 0.8672\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8614 - val_loss: 0.3661 - val_accuracy: 0.8687\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8612 - val_loss: 0.3651 - val_accuracy: 0.8675\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8611 - val_loss: 0.3667 - val_accuracy: 0.8672\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8621 - val_loss: 0.3650 - val_accuracy: 0.8683\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8612 - val_loss: 0.3655 - val_accuracy: 0.8664\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8617 - val_loss: 0.3653 - val_accuracy: 0.8687\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8618 - val_loss: 0.3640 - val_accuracy: 0.8675\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8618 - val_loss: 0.3639 - val_accuracy: 0.8672\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8609 - val_loss: 0.3639 - val_accuracy: 0.8687\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8618 - val_loss: 0.3648 - val_accuracy: 0.8679\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8614 - val_loss: 0.3642 - val_accuracy: 0.8683\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8625 - val_loss: 0.3653 - val_accuracy: 0.8672\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8622 - val_loss: 0.3641 - val_accuracy: 0.8683\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8615 - val_loss: 0.3659 - val_accuracy: 0.8690\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8622 - val_loss: 0.3642 - val_accuracy: 0.8679\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8620 - val_loss: 0.3681 - val_accuracy: 0.8683\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8619 - val_loss: 0.3640 - val_accuracy: 0.8698\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8620 - val_loss: 0.3650 - val_accuracy: 0.8668\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8620 - val_loss: 0.3639 - val_accuracy: 0.8679\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8624 - val_loss: 0.3681 - val_accuracy: 0.8675\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8618 - val_loss: 0.3635 - val_accuracy: 0.8690\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8616 - val_loss: 0.3630 - val_accuracy: 0.8679\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8625 - val_loss: 0.3636 - val_accuracy: 0.8683\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8623 - val_loss: 0.3640 - val_accuracy: 0.8672\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8613 - val_loss: 0.3632 - val_accuracy: 0.8690\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8622 - val_loss: 0.3657 - val_accuracy: 0.8679\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8622 - val_loss: 0.3645 - val_accuracy: 0.8664\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8626 - val_loss: 0.3626 - val_accuracy: 0.8679\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8619 - val_loss: 0.3648 - val_accuracy: 0.8675\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8620 - val_loss: 0.3637 - val_accuracy: 0.8668\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8621 - val_loss: 0.3625 - val_accuracy: 0.8690\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8621 - val_loss: 0.3634 - val_accuracy: 0.8679\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8623 - val_loss: 0.3631 - val_accuracy: 0.8698\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8626 - val_loss: 0.3650 - val_accuracy: 0.8687\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8625 - val_loss: 0.3628 - val_accuracy: 0.8687\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8624 - val_loss: 0.3633 - val_accuracy: 0.8694\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8629 - val_loss: 0.3646 - val_accuracy: 0.8679\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8628 - val_loss: 0.3653 - val_accuracy: 0.8709\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8626 - val_loss: 0.3655 - val_accuracy: 0.8701\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8625 - val_loss: 0.3663 - val_accuracy: 0.8701\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8629 - val_loss: 0.3631 - val_accuracy: 0.8705\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8631 - val_loss: 0.3644 - val_accuracy: 0.8687\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8626 - val_loss: 0.3632 - val_accuracy: 0.8675\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8625 - val_loss: 0.3627 - val_accuracy: 0.8694\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8635 - val_loss: 0.3620 - val_accuracy: 0.8679\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8622 - val_loss: 0.3700 - val_accuracy: 0.8694\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8624 - val_loss: 0.3642 - val_accuracy: 0.8690\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8623 - val_loss: 0.3621 - val_accuracy: 0.8698\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8634 - val_loss: 0.3649 - val_accuracy: 0.8668\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.3803 - accuracy: 0.8623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 10/10 [16:19<00:00, 97.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38030391931533813, 0.8623380661010742]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "total_scores = []\n",
    "for i in tqdm(range(10)):\n",
    "    idealized_signals, labels = idealized(num = 10_000)\n",
    "    input_data = np.expand_dims(normalize_data(idealized_signals), axis = -1)\n",
    "    print(input_data[0,:,:].max(), input_data[0,:,:].min())\n",
    "    splits = input_data.shape[0]//1_000\n",
    "    X = []\n",
    "    print(input_data.shape)\n",
    "    for i in range(splits):\n",
    "        tensor = tf.convert_to_tensor(input_data[i*1_000:(i+1)*1_000, :,:,:], dtype=tf.float32)\n",
    "        X.append(autoencoder.encoder(tensor)[0])\n",
    "    X = np.vstack(X)\n",
    "    print(X.shape)\n",
    "    print(labels.shape)\n",
    "    X, labels = absolute_diff(X, labels)\n",
    "    print(X.shape, labels.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "    linear = keras.Sequential(name=\"my_sequential\")\n",
    "    linear.add(layers.Dense(4, activation=\"softmax\", name=\"layer2\"))\n",
    "\n",
    "    linear.compile(loss='categorical_crossentropy', \n",
    "                   optimizer=keras.optimizers.Adam(learning_rate = 5e-3), metrics=['accuracy'])\n",
    "    linear.fit(X_train, y_train, epochs=150, batch_size=128, validation_split = 0.1, shuffle=True)\n",
    "    results = linear.evaluate(X_test, y_test)\n",
    "    print(results)\n",
    "    total_scores.append(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6bd8485-e07e-4a7e-adaf-6709461d3e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8767482459545135\n",
      "0.037878422905213746\n",
      "tensorflow      WARNING  Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.89\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.90\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.91\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.92\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.93\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.94\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.95\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.96\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.97\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.98\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.99\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.100\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.101\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.102\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.103\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.104\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.105\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.106\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.107\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.108\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.109\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.110\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.111\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.112\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.113\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.114\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.115\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.116\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.117\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.118\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.119\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.120\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.121\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.122\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.123\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.124\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.125\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.126\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.127\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.128\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.129\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.130\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.131\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.132\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.133\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.134\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.135\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.136\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.137\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.138\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.139\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.140\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(total_scores))\n",
    "print(np.std(total_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
