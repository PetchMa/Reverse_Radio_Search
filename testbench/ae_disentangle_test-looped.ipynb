{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baed00ee-9461-4560-8813-31a571c86877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 12:29:59.343913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import setigen as stg\n",
    "from blimpy import Waterfall\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from astropy import units as u\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import silhouette_score\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f020ec-5663-42ab-8527-2b5d37948ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e00c928-f039-4774-8477-10c9e940e2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def painting(data):\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    for c in range(num_classes):\n",
    "        drift = 2*random.random()*(-1)**random.randint(0,2)\n",
    "        snr = random.randint(100, 150)\n",
    "        width = random.randint(20, 50)\n",
    "        for s in range(num_samples_per_class):\n",
    "            index = random.randint(0, data.shape[0]-1)\n",
    "            window = data[index, :,:]\n",
    "            \n",
    "            start = random.randint(50, 180)\n",
    "            \n",
    "            frame = stg.Frame.from_data(df=2.7939677238464355*u.Hz,\n",
    "                                        dt=18.253611008*u.s,\n",
    "                                        fch1=1289*u.MHz,\n",
    "                                        ascending=True,\n",
    "                                        data=window)\n",
    "            frame.add_signal(stg.constant_path(\n",
    "                                        f_start=frame.get_frequency(index=start),\n",
    "                                       drift_rate=drift*u.Hz/u.s),\n",
    "                                      stg.constant_t_profile(level=frame.get_intensity(snr=snr)),\n",
    "                                      stg.gaussian_f_profile(width=width*u.Hz),\n",
    "                                      stg.constant_bp_profile(level=1))\n",
    "            all_data.append(frame.data)\n",
    "            labels.append(c)\n",
    "    all_data = np.array(all_data)\n",
    "    labels = np.vstack(labels)\n",
    "    return all_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e49e4f-15bd-4a32-a6d5-7a3274be3b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from AE import AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531b40be-4015-40db-926c-0e681083194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 12:30:01.663475: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 12:30:02.043712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13888 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16, 256, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 256, 3)        30        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 128, 3)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 128, 3)       12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 128, 64)       1792      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 64, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 8, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 8, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2097408   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " latent (Dense)              (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,229,428\n",
      "Trainable params: 2,228,270\n",
      "Non-trainable params: 1,158\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "time_samples = 16\n",
    "freq_sample =  256\n",
    "encoder_inputs = keras.Input(shape=(time_samples, freq_sample, 1))\n",
    "x = layers.Conv2D(3, 3, activation=\"relu\", strides=1, padding=\"same\")(encoder_inputs)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x_shape = x.shape\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "z = layers.Dense(latent_dim, name=\"latent\", activation=\"linear\")(x)\n",
    "encoder = keras.Model(encoder_inputs, z, name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7131cf6f-ba9a-43ea-8b45-d3f79bd5acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                704       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8192)              2105344   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 8192)             32768     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 8, 64)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 16, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 64)       36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 16, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 64, 64)       36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 16, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 16, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 32, 128, 64)      36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 128, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 16, 128, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 32, 256, 3)       1731      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 16, 256, 3)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 16, 256, 3)       12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 16, 256, 1)       28        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,306,987\n",
      "Trainable params: 2,289,573\n",
      "Non-trainable params: 17,414\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(x_shape[1]* x_shape[2]* x_shape[3], activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Reshape((x_shape[1], x_shape[2], x_shape[3]))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(3, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"linear\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58ade6b-b495-49c2-b248-63bfadd8ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = 8\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"kl_loss\"\n",
    "        )\n",
    "        self.kl_additional = tf.keras.losses.KLDivergence()\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "        ]\n",
    "    def gaussanity_loss(self, data, base):\n",
    "        return self.kl_additional(data, base)\n",
    "    \n",
    "    def train_step(self, data_in):\n",
    "        data = data_in\n",
    "        print(data.shape)\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            \n",
    "            \n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        \n",
    "        mse_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(mse_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "        }\n",
    "    def test_step(self, data_in):\n",
    "        data, _ = data_in\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss \n",
    "        \n",
    "        mse_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(mse_loss)\n",
    "        return {\n",
    "            \"test_loss\": self.total_loss_tracker.result(),\n",
    "            \"test_kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"test_reconstruction_loss\": self.reconstruction_loss_tracker.result()\n",
    "        }\n",
    "    def __call__ (self, inputs):\n",
    "        return self.decoder(self.encoder(inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0074643-eba7-4961-aa51-3916eb75c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f85d00c4ee0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = VAE(encoder, decoder)\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3))\n",
    "autoencoder.load_weights(\"../autoencoder/models/full-weights-\"+'07-02-2023-11-08-47')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df2f403c-1e31-45be-9f8b-44277bc1bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    epsilon = 1\n",
    "    min_val = data.min()\n",
    "    data = data - min_val + epsilon\n",
    "    new_data = np.log(data)\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    final_data = (data - min_val) / (max_val - min_val)\n",
    "    return final_data\n",
    "    \n",
    "def normalize_data(data):\n",
    "    for i in tqdm(range(data.shape[0])):\n",
    "        data[i,:,:] = normalize(data[i,:,:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "218b0964-8671-484c-b24f-e9081b651743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def idealized(num=10_000):\n",
    "    drift = drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "    snr = 50*random.random() +20\n",
    "    width = 50*random.random() +20\n",
    "    start = random.randint(50, 180)\n",
    "    data = []\n",
    "    labels = []\n",
    "    for tag in range(4):\n",
    "        label_vec = np.zeros(4)\n",
    "        label_vec[tag] = 1\n",
    "        for i in range(num):\n",
    "            if tag == 0:\n",
    "#             everything but drif\n",
    "                snr = 50*random.random() +20\n",
    "                width = 50*random.random() +20\n",
    "                start = random.randint(50, 180)\n",
    "            elif tag == 1:\n",
    "#             everything but snr\n",
    "                drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "                width = 50*random.random() +20\n",
    "                start = random.randint(50, 180)\n",
    "            elif tag == 2:\n",
    "#             everything but width\n",
    "                drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "                snr = 50*random.random() +20\n",
    "                start = random.randint(50, 180)\n",
    "            elif tag == 3:\n",
    "#             everything but start\n",
    "                drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "                snr = 50*random.random() +20\n",
    "                width = 50*random.random() +20\n",
    "\n",
    "            frame = stg.Frame(fchans=256*u.pixel,\n",
    "                              tchans=16*u.pixel,\n",
    "                              df=2.7939677238464355*u.Hz,\n",
    "                              dt=18.253611008*u.s,\n",
    "                              fch1=6095.214842353016*u.MHz)\n",
    "            noise = frame.add_noise(x_mean=1, noise_type='chi2')\n",
    "            frame.add_signal(stg.constant_path(\n",
    "                                        f_start=frame.get_frequency(index=start),\n",
    "                                       drift_rate=drift*u.Hz/u.s),\n",
    "                                      stg.constant_t_profile(level=frame.get_intensity(snr=snr)),\n",
    "                                      stg.gaussian_f_profile(width=width*u.Hz),\n",
    "                                      stg.constant_bp_profile(level=1))\n",
    "            data.append(frame.data)\n",
    "            labels.append(label_vec)\n",
    "    data = np.array(data)\n",
    "    labels = np.vstack(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "840a6870-c527-4ab5-9bc4-ff56ca7e8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_diff(X, labels):\n",
    "    new_x = []\n",
    "    new_labels = []\n",
    "    one = np.arange(0,10000)\n",
    "    two = np.arange(10000,20000)\n",
    "    three = np.arange(20000,30000)\n",
    "    four = np.arange(30000,40000)\n",
    "    for i in range(X.shape[0] -1):\n",
    "        if np.argmax(labels[i,:]) == np.argmax(labels[i+1,:]): \n",
    "            index = np.argmax(labels[i,:])\n",
    "            if index == 0:\n",
    "                sample = np.random.choice(one, size = 1000)\n",
    "            elif index == 1:\n",
    "                sample = np.random.choice(two, size = 1000)\n",
    "            elif index == 2:\n",
    "                sample = np.random.choice(three, size = 1000)\n",
    "            elif index == 3:\n",
    "                sample = np.random.choice(four, size = 1000)\n",
    "            diff = abs(X[i,:] - X[sample,:])\n",
    "            diff = np.mean(diff, axis = 0)\n",
    "            new_x.append(diff)\n",
    "            new_labels.append(labels[i,:])\n",
    "            \n",
    "    return np.array(new_x), np.vstack(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9549969-98f3-4658-a0f7-ff09b604ff4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/10 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1251/40000 [00:00<00:03, 12506.82it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2502/40000 [00:00<00:03, 12438.68it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3746/40000 [00:00<00:02, 12425.13it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4989/40000 [00:00<00:02, 12426.04it/s]\u001b[A\n",
      " 16%|███████████▉                                                                 | 6232/40000 [00:00<00:02, 12425.90it/s]\u001b[A\n",
      " 19%|██████████████▍                                                              | 7476/40000 [00:00<00:02, 12427.46it/s]\u001b[A\n",
      " 22%|████████████████▊                                                            | 8719/40000 [00:00<00:02, 12427.66it/s]\u001b[A\n",
      " 25%|███████████████████▏                                                         | 9964/40000 [00:00<00:02, 12431.71it/s]\u001b[A\n",
      " 28%|█████████████████████▎                                                      | 11208/40000 [00:00<00:02, 12420.35it/s]\u001b[A\n",
      " 31%|███████████████████████▋                                                    | 12451/40000 [00:01<00:02, 12413.35it/s]\u001b[A\n",
      " 34%|██████████████████████████                                                  | 13693/40000 [00:01<00:02, 12375.67it/s]\u001b[A\n",
      " 37%|████████████████████████████▎                                               | 14931/40000 [00:01<00:02, 12375.77it/s]\u001b[A\n",
      " 40%|██████████████████████████████▋                                             | 16173/40000 [00:01<00:01, 12387.05it/s]\u001b[A\n",
      " 44%|█████████████████████████████████                                           | 17416/40000 [00:01<00:01, 12397.65it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▍                                        | 18656/40000 [00:01<00:01, 12394.99it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▊                                      | 19899/40000 [00:01<00:01, 12403.53it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▏                                   | 21143/40000 [00:01<00:01, 12412.68it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▌                                 | 22388/40000 [00:01<00:01, 12421.41it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▉                               | 23631/40000 [00:01<00:01, 12423.80it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▎                            | 24875/40000 [00:02<00:01, 12425.89it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▌                          | 26118/40000 [00:02<00:01, 12421.63it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▉                        | 27364/40000 [00:02<00:01, 12431.85it/s]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████████▎                     | 28608/40000 [00:02<00:00, 12428.86it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████▋                   | 29852/40000 [00:02<00:00, 12429.71it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████                 | 31095/40000 [00:02<00:00, 12426.72it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▍              | 32339/40000 [00:02<00:00, 12428.92it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▊            | 33584/40000 [00:02<00:00, 12432.62it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████▏         | 34828/40000 [00:02<00:00, 12434.24it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▌       | 36075/40000 [00:02<00:00, 12443.36it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▉     | 37320/40000 [00:03<00:00, 12435.61it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▎  | 38565/40000 [00:03<00:00, 12439.36it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12418.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 12:30:40.620144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2023-08-24 12:30:42.690834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 7.7491 - accuracy: 0.3962 - val_loss: 2.1013 - val_accuracy: 0.6474\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.3146 - accuracy: 0.6615 - val_loss: 0.7971 - val_accuracy: 0.6679\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.6950 - val_loss: 0.6265 - val_accuracy: 0.6843\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7054 - val_loss: 0.5589 - val_accuracy: 0.7410\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7160 - val_loss: 0.5460 - val_accuracy: 0.7384\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7250 - val_loss: 0.5275 - val_accuracy: 0.7343\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7267 - val_loss: 0.5193 - val_accuracy: 0.7310\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7298 - val_loss: 0.5043 - val_accuracy: 0.7511\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7376 - val_loss: 0.4996 - val_accuracy: 0.7388\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7332 - val_loss: 0.4999 - val_accuracy: 0.7190\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7350 - val_loss: 0.4864 - val_accuracy: 0.7425\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7466 - val_loss: 0.4748 - val_accuracy: 0.7780\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7445 - val_loss: 0.4896 - val_accuracy: 0.7243\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7455 - val_loss: 0.4842 - val_accuracy: 0.7276\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7487 - val_loss: 0.4848 - val_accuracy: 0.7310\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7531 - val_loss: 0.4601 - val_accuracy: 0.7657\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7544 - val_loss: 0.4715 - val_accuracy: 0.7313\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7503 - val_loss: 0.4900 - val_accuracy: 0.7325\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7430 - val_loss: 0.4667 - val_accuracy: 0.7552\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7532 - val_loss: 0.4596 - val_accuracy: 0.7448\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7547 - val_loss: 0.4486 - val_accuracy: 0.7806\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7564 - val_loss: 0.4476 - val_accuracy: 0.7933\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7595 - val_loss: 0.5456 - val_accuracy: 0.7049\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7490 - val_loss: 0.4509 - val_accuracy: 0.7709\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7550 - val_loss: 0.4893 - val_accuracy: 0.7153\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7575 - val_loss: 0.4802 - val_accuracy: 0.7157\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7603 - val_loss: 0.4446 - val_accuracy: 0.7422\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7624 - val_loss: 0.4743 - val_accuracy: 0.7198\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7608 - val_loss: 0.4514 - val_accuracy: 0.7500\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7617 - val_loss: 0.4332 - val_accuracy: 0.7810\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7573 - val_loss: 0.4356 - val_accuracy: 0.7761\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7591 - val_loss: 0.4318 - val_accuracy: 0.7582\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7562 - val_loss: 0.4399 - val_accuracy: 0.7959\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7637 - val_loss: 0.4311 - val_accuracy: 0.7705\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7678 - val_loss: 0.5290 - val_accuracy: 0.7422\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7563 - val_loss: 0.4426 - val_accuracy: 0.7257\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7583 - val_loss: 0.4281 - val_accuracy: 0.7847\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7611 - val_loss: 0.4330 - val_accuracy: 0.7903\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7679 - val_loss: 0.4336 - val_accuracy: 0.7556\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7624 - val_loss: 0.4305 - val_accuracy: 0.7910\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7583 - val_loss: 0.4386 - val_accuracy: 0.7347\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7646 - val_loss: 0.5018 - val_accuracy: 0.7127\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7617 - val_loss: 0.4228 - val_accuracy: 0.7765\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7668 - val_loss: 0.4257 - val_accuracy: 0.7687\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7634 - val_loss: 0.4819 - val_accuracy: 0.7172\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7656 - val_loss: 0.4293 - val_accuracy: 0.7963\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7607 - val_loss: 0.4236 - val_accuracy: 0.7668\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7615 - val_loss: 0.4363 - val_accuracy: 0.7787\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7630 - val_loss: 0.4671 - val_accuracy: 0.7205\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7646 - val_loss: 0.4279 - val_accuracy: 0.7444\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7564 - val_loss: 0.4476 - val_accuracy: 0.7623\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7659 - val_loss: 0.4276 - val_accuracy: 0.7810\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7610 - val_loss: 0.4347 - val_accuracy: 0.7556\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7657 - val_loss: 0.5110 - val_accuracy: 0.7198\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7643 - val_loss: 0.4310 - val_accuracy: 0.7858\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7624 - val_loss: 0.4190 - val_accuracy: 0.7672\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7607 - val_loss: 0.4227 - val_accuracy: 0.7519\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7581 - val_loss: 0.4184 - val_accuracy: 0.7631\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7687 - val_loss: 0.4222 - val_accuracy: 0.7657\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7659 - val_loss: 0.4249 - val_accuracy: 0.7556\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7589 - val_loss: 0.4419 - val_accuracy: 0.7291\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7617 - val_loss: 0.4263 - val_accuracy: 0.7336\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7692 - val_loss: 0.4219 - val_accuracy: 0.7515\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7628 - val_loss: 0.4186 - val_accuracy: 0.7888\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7584 - val_loss: 0.4305 - val_accuracy: 0.7407\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7671 - val_loss: 0.4245 - val_accuracy: 0.7552\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7626 - val_loss: 0.4206 - val_accuracy: 0.7701\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7675 - val_loss: 0.4252 - val_accuracy: 0.7384\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7592 - val_loss: 0.4501 - val_accuracy: 0.7254\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7600 - val_loss: 0.4317 - val_accuracy: 0.7317\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7647 - val_loss: 0.4363 - val_accuracy: 0.7373\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7629 - val_loss: 0.4505 - val_accuracy: 0.7313\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7605 - val_loss: 0.5415 - val_accuracy: 0.7149\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7611 - val_loss: 0.4308 - val_accuracy: 0.7892\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7620 - val_loss: 0.4447 - val_accuracy: 0.7220\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7678 - val_loss: 0.4151 - val_accuracy: 0.7925\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7658 - val_loss: 0.4131 - val_accuracy: 0.7813\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7680 - val_loss: 0.4184 - val_accuracy: 0.7649\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7608 - val_loss: 0.4244 - val_accuracy: 0.7396\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7643 - val_loss: 0.4226 - val_accuracy: 0.7769\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7611 - val_loss: 0.5003 - val_accuracy: 0.7433\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7599 - val_loss: 0.4307 - val_accuracy: 0.7358\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7655 - val_loss: 0.4149 - val_accuracy: 0.7675\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7697 - val_loss: 0.4547 - val_accuracy: 0.7463\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7633 - val_loss: 0.4296 - val_accuracy: 0.7892\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7595 - val_loss: 0.4172 - val_accuracy: 0.7634\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7637 - val_loss: 0.4139 - val_accuracy: 0.7731\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7624 - val_loss: 0.4244 - val_accuracy: 0.7340\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7680 - val_loss: 0.5028 - val_accuracy: 0.7179\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7658 - val_loss: 0.4244 - val_accuracy: 0.7597\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7639 - val_loss: 0.4242 - val_accuracy: 0.7381\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7612 - val_loss: 0.4906 - val_accuracy: 0.7160\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7655 - val_loss: 0.4182 - val_accuracy: 0.7813\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7667 - val_loss: 0.4405 - val_accuracy: 0.7739\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7637 - val_loss: 0.4147 - val_accuracy: 0.7948\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7652 - val_loss: 0.4207 - val_accuracy: 0.7429\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7643 - val_loss: 0.4272 - val_accuracy: 0.7340\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7631 - val_loss: 0.4127 - val_accuracy: 0.7616\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7665 - val_loss: 0.4539 - val_accuracy: 0.7269\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7630 - val_loss: 0.4098 - val_accuracy: 0.7840\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7595 - val_loss: 0.4252 - val_accuracy: 0.7373\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7596 - val_loss: 0.4144 - val_accuracy: 0.7877\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7637 - val_loss: 0.4322 - val_accuracy: 0.7690\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7627 - val_loss: 0.4460 - val_accuracy: 0.7522\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7633 - val_loss: 0.4718 - val_accuracy: 0.7440\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7559 - val_loss: 0.4174 - val_accuracy: 0.7515\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7642 - val_loss: 0.4160 - val_accuracy: 0.7955\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7680 - val_loss: 0.4315 - val_accuracy: 0.7784\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7625 - val_loss: 0.4392 - val_accuracy: 0.7325\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7677 - val_loss: 0.4177 - val_accuracy: 0.7601\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7660 - val_loss: 0.4201 - val_accuracy: 0.7437\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7592 - val_loss: 0.4158 - val_accuracy: 0.7601\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7653 - val_loss: 0.4224 - val_accuracy: 0.7451\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7638 - val_loss: 0.4267 - val_accuracy: 0.7795\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7612 - val_loss: 0.4157 - val_accuracy: 0.7586\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7636 - val_loss: 0.4444 - val_accuracy: 0.7257\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7706 - val_loss: 0.4551 - val_accuracy: 0.7228\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7602 - val_loss: 0.4124 - val_accuracy: 0.7735\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7673 - val_loss: 0.4298 - val_accuracy: 0.7325\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7643 - val_loss: 0.4157 - val_accuracy: 0.7787\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7632 - val_loss: 0.4150 - val_accuracy: 0.7750\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7644 - val_loss: 0.4277 - val_accuracy: 0.7675\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7661 - val_loss: 0.4235 - val_accuracy: 0.7873\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7678 - val_loss: 0.4462 - val_accuracy: 0.7530\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7650 - val_loss: 0.4529 - val_accuracy: 0.7250\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7637 - val_loss: 0.4155 - val_accuracy: 0.7802\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7615 - val_loss: 0.4212 - val_accuracy: 0.7425\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7697 - val_loss: 0.4212 - val_accuracy: 0.7619\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7633 - val_loss: 0.4088 - val_accuracy: 0.7825\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7685 - val_loss: 0.4172 - val_accuracy: 0.7549\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7578 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7676 - val_loss: 0.4159 - val_accuracy: 0.7914\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7634 - val_loss: 0.4180 - val_accuracy: 0.7899\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7621 - val_loss: 0.4278 - val_accuracy: 0.7825\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7671 - val_loss: 0.4109 - val_accuracy: 0.7888\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.7731 - val_loss: 0.4159 - val_accuracy: 0.7549\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7636 - val_loss: 0.4131 - val_accuracy: 0.7687\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7638 - val_loss: 0.4618 - val_accuracy: 0.7272\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7650 - val_loss: 0.4202 - val_accuracy: 0.7560\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7654 - val_loss: 0.4113 - val_accuracy: 0.7806\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7624 - val_loss: 0.4147 - val_accuracy: 0.7933\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7622 - val_loss: 0.4338 - val_accuracy: 0.7668\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7647 - val_loss: 0.4210 - val_accuracy: 0.7437\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7646 - val_loss: 0.4209 - val_accuracy: 0.7418\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7614 - val_loss: 0.5503 - val_accuracy: 0.7116\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7670 - val_loss: 0.4348 - val_accuracy: 0.7653\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7659 - val_loss: 0.4232 - val_accuracy: 0.7556\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7649 - val_loss: 0.4218 - val_accuracy: 0.7560\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7641 - val_loss: 0.4100 - val_accuracy: 0.7918\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7585 - val_loss: 0.4126 - val_accuracy: 0.7858\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.4025 - accuracy: 0.7973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                             | 1/10 [01:37<14:38, 97.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40248724818229675, 0.7972573637962341]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1189/40000 [00:00<00:03, 11881.26it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2425/40000 [00:00<00:03, 12157.76it/s]\u001b[A\n",
      "  9%|███████                                                                      | 3658/40000 [00:00<00:02, 12233.94it/s]\u001b[A\n",
      " 12%|█████████▍                                                                   | 4890/40000 [00:00<00:02, 12266.81it/s]\u001b[A\n",
      " 15%|███████████▊                                                                 | 6121/40000 [00:00<00:02, 12280.88it/s]\u001b[A\n",
      " 18%|██████████████▏                                                              | 7355/40000 [00:00<00:02, 12299.70it/s]\u001b[A\n",
      " 21%|████████████████▌                                                            | 8588/40000 [00:00<00:02, 12309.13it/s]\u001b[A\n",
      " 25%|██████████████████▉                                                          | 9823/40000 [00:00<00:02, 12321.77it/s]\u001b[A\n",
      " 28%|█████████████████████                                                       | 11056/40000 [00:00<00:02, 12309.12it/s]\u001b[A\n",
      " 31%|███████████████████████▎                                                    | 12293/40000 [00:01<00:02, 12324.83it/s]\u001b[A\n",
      " 34%|█████████████████████████▋                                                  | 13532/40000 [00:01<00:02, 12342.53it/s]\u001b[A\n",
      " 37%|████████████████████████████                                                | 14773/40000 [00:01<00:02, 12360.89it/s]\u001b[A\n",
      " 40%|██████████████████████████████▍                                             | 16010/40000 [00:01<00:01, 12358.46it/s]\u001b[A\n",
      " 43%|████████████████████████████████▊                                           | 17246/40000 [00:01<00:01, 12357.24it/s]\u001b[A\n",
      " 46%|███████████████████████████████████                                         | 18482/40000 [00:01<00:01, 12346.89it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▍                                      | 19719/40000 [00:01<00:01, 12351.17it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▊                                    | 20955/40000 [00:01<00:01, 12344.80it/s]\u001b[A\n",
      " 55%|██████████████████████████████████████████▏                                 | 22190/40000 [00:01<00:01, 12341.82it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▌                               | 23425/40000 [00:01<00:01, 12333.89it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▊                             | 24659/40000 [00:02<00:01, 12330.92it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▏                          | 25893/40000 [00:02<00:01, 12330.84it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▌                        | 27128/40000 [00:02<00:01, 12334.75it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▉                      | 28362/40000 [00:02<00:00, 12323.93it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▏                   | 29595/40000 [00:02<00:00, 12322.54it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▌                 | 30828/40000 [00:02<00:00, 12318.91it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▉               | 32060/40000 [00:02<00:00, 12309.62it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▎            | 33291/40000 [00:02<00:00, 12299.89it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████▌          | 34526/40000 [00:02<00:00, 12312.40it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████▉        | 35758/40000 [00:02<00:00, 12304.12it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████▎     | 36990/40000 [00:03<00:00, 12306.89it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▌   | 38221/40000 [00:03<00:00, 12304.99it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12306.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 7.9685 - accuracy: 0.3359 - val_loss: 2.3938 - val_accuracy: 0.5504\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.4512 - accuracy: 0.6621 - val_loss: 1.0126 - val_accuracy: 0.7142\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7759 - accuracy: 0.7645 - val_loss: 0.7060 - val_accuracy: 0.7646\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.8018 - val_loss: 0.6194 - val_accuracy: 0.8224\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.8215 - val_loss: 0.5877 - val_accuracy: 0.8332\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.8399 - val_loss: 0.5893 - val_accuracy: 0.8261\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.8490 - val_loss: 0.5246 - val_accuracy: 0.8530\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8572 - val_loss: 0.5084 - val_accuracy: 0.8541\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8617 - val_loss: 0.4998 - val_accuracy: 0.8418\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8562 - val_loss: 0.4834 - val_accuracy: 0.8451\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8633 - val_loss: 0.4685 - val_accuracy: 0.8481\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8661 - val_loss: 0.4863 - val_accuracy: 0.8571\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8664 - val_loss: 0.4485 - val_accuracy: 0.8701\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8678 - val_loss: 0.4410 - val_accuracy: 0.8496\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8686 - val_loss: 0.4572 - val_accuracy: 0.8295\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8647 - val_loss: 0.4203 - val_accuracy: 0.8601\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8662 - val_loss: 0.4174 - val_accuracy: 0.8593\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8713 - val_loss: 0.4098 - val_accuracy: 0.8623\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8710 - val_loss: 0.4087 - val_accuracy: 0.8549\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8708 - val_loss: 0.4023 - val_accuracy: 0.8623\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8716 - val_loss: 0.4031 - val_accuracy: 0.8601\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8700 - val_loss: 0.4185 - val_accuracy: 0.8701\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8704 - val_loss: 0.3955 - val_accuracy: 0.8776\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8728 - val_loss: 0.3880 - val_accuracy: 0.8675\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8718 - val_loss: 0.4001 - val_accuracy: 0.8761\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8746 - val_loss: 0.4282 - val_accuracy: 0.8713\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8725 - val_loss: 0.3909 - val_accuracy: 0.8787\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8721 - val_loss: 0.3868 - val_accuracy: 0.8746\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8750 - val_loss: 0.3825 - val_accuracy: 0.8619\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8682 - val_loss: 0.3990 - val_accuracy: 0.8787\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8766 - val_loss: 0.3907 - val_accuracy: 0.8769\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8748 - val_loss: 0.3793 - val_accuracy: 0.8705\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8733 - val_loss: 0.3769 - val_accuracy: 0.8597\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8766 - val_loss: 0.3898 - val_accuracy: 0.8593\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8731 - val_loss: 0.3837 - val_accuracy: 0.8728\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8743 - val_loss: 0.4106 - val_accuracy: 0.8672\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8727 - val_loss: 0.3764 - val_accuracy: 0.8750\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8725 - val_loss: 0.3776 - val_accuracy: 0.8776\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8743 - val_loss: 0.3752 - val_accuracy: 0.8631\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8721 - val_loss: 0.3741 - val_accuracy: 0.8631\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8725 - val_loss: 0.3720 - val_accuracy: 0.8716\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8760 - val_loss: 0.3642 - val_accuracy: 0.8705\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8747 - val_loss: 0.3744 - val_accuracy: 0.8709\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8757 - val_loss: 0.3930 - val_accuracy: 0.8802\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8733 - val_loss: 0.3727 - val_accuracy: 0.8634\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8760 - val_loss: 0.3873 - val_accuracy: 0.8451\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8744 - val_loss: 0.3789 - val_accuracy: 0.8817\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8755 - val_loss: 0.3744 - val_accuracy: 0.8672\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8750 - val_loss: 0.3884 - val_accuracy: 0.8675\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8766 - val_loss: 0.3746 - val_accuracy: 0.8586\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8782 - val_loss: 0.3625 - val_accuracy: 0.8735\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8747 - val_loss: 0.3711 - val_accuracy: 0.8578\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8762 - val_loss: 0.3786 - val_accuracy: 0.8776\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8769 - val_loss: 0.4036 - val_accuracy: 0.8448\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8709 - val_loss: 0.3759 - val_accuracy: 0.8795\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8758 - val_loss: 0.3676 - val_accuracy: 0.8780\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8772 - val_loss: 0.3812 - val_accuracy: 0.8631\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8764 - val_loss: 0.3776 - val_accuracy: 0.8687\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8776 - val_loss: 0.3783 - val_accuracy: 0.8795\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8728 - val_loss: 0.3688 - val_accuracy: 0.8575\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8738 - val_loss: 0.3635 - val_accuracy: 0.8743\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8747 - val_loss: 0.3619 - val_accuracy: 0.8757\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8751 - val_loss: 0.3602 - val_accuracy: 0.8672\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8727 - val_loss: 0.3944 - val_accuracy: 0.8396\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8749 - val_loss: 0.3728 - val_accuracy: 0.8784\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8737 - val_loss: 0.3708 - val_accuracy: 0.8757\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8722 - val_loss: 0.3641 - val_accuracy: 0.8776\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8701 - val_loss: 0.3788 - val_accuracy: 0.8746\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8761 - val_loss: 0.3871 - val_accuracy: 0.8590\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8739 - val_loss: 0.3634 - val_accuracy: 0.8694\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8739 - val_loss: 0.3642 - val_accuracy: 0.8799\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8764 - val_loss: 0.3786 - val_accuracy: 0.8720\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8746 - val_loss: 0.3673 - val_accuracy: 0.8769\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8738 - val_loss: 0.3836 - val_accuracy: 0.8634\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8725 - val_loss: 0.3646 - val_accuracy: 0.8701\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8770 - val_loss: 0.3724 - val_accuracy: 0.8705\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8758 - val_loss: 0.3828 - val_accuracy: 0.8489\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8776 - val_loss: 0.3807 - val_accuracy: 0.8672\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8758 - val_loss: 0.3667 - val_accuracy: 0.8675\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8740 - val_loss: 0.3643 - val_accuracy: 0.8728\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8756 - val_loss: 0.3946 - val_accuracy: 0.8784\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8756 - val_loss: 0.3808 - val_accuracy: 0.8810\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8722 - val_loss: 0.3609 - val_accuracy: 0.8690\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8737 - val_loss: 0.3717 - val_accuracy: 0.8679\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8743 - val_loss: 0.3623 - val_accuracy: 0.8769\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8744 - val_loss: 0.3713 - val_accuracy: 0.8813\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8745 - val_loss: 0.3650 - val_accuracy: 0.8631\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8764 - val_loss: 0.3922 - val_accuracy: 0.8813\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8786 - val_loss: 0.3724 - val_accuracy: 0.8664\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8769 - val_loss: 0.3766 - val_accuracy: 0.8795\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8775 - val_loss: 0.3676 - val_accuracy: 0.8787\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8738 - val_loss: 0.3625 - val_accuracy: 0.8679\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8745 - val_loss: 0.3861 - val_accuracy: 0.8649\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8761 - val_loss: 0.3767 - val_accuracy: 0.8795\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8730 - val_loss: 0.3828 - val_accuracy: 0.8489\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8746 - val_loss: 0.3649 - val_accuracy: 0.8791\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8764 - val_loss: 0.3625 - val_accuracy: 0.8698\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8747 - val_loss: 0.3671 - val_accuracy: 0.8780\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8759 - val_loss: 0.3637 - val_accuracy: 0.8791\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8770 - val_loss: 0.3718 - val_accuracy: 0.8578\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8747 - val_loss: 0.3725 - val_accuracy: 0.8575\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8782 - val_loss: 0.4084 - val_accuracy: 0.8388\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8757 - val_loss: 0.3809 - val_accuracy: 0.8563\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8756 - val_loss: 0.3754 - val_accuracy: 0.8731\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8759 - val_loss: 0.3628 - val_accuracy: 0.8757\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8752 - val_loss: 0.3682 - val_accuracy: 0.8634\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8761 - val_loss: 0.3663 - val_accuracy: 0.8724\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8763 - val_loss: 0.3829 - val_accuracy: 0.8754\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8735 - val_loss: 0.3801 - val_accuracy: 0.8791\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8752 - val_loss: 0.3800 - val_accuracy: 0.8754\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8730 - val_loss: 0.3720 - val_accuracy: 0.8601\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8753 - val_loss: 0.3633 - val_accuracy: 0.8646\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8734 - val_loss: 0.3688 - val_accuracy: 0.8746\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8717 - val_loss: 0.3613 - val_accuracy: 0.8750\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8772 - val_loss: 0.3617 - val_accuracy: 0.8746\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8759 - val_loss: 0.3720 - val_accuracy: 0.8694\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8767 - val_loss: 0.3662 - val_accuracy: 0.8631\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8750 - val_loss: 0.3836 - val_accuracy: 0.8448\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8741 - val_loss: 0.3613 - val_accuracy: 0.8739\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8780 - val_loss: 0.3999 - val_accuracy: 0.8597\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8759 - val_loss: 0.3735 - val_accuracy: 0.8776\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8778 - val_loss: 0.3642 - val_accuracy: 0.8757\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8753 - val_loss: 0.3723 - val_accuracy: 0.8631\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8770 - val_loss: 0.3753 - val_accuracy: 0.8739\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8742 - val_loss: 0.3646 - val_accuracy: 0.8720\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8752 - val_loss: 0.3764 - val_accuracy: 0.8672\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8773 - val_loss: 0.3643 - val_accuracy: 0.8765\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8755 - val_loss: 0.3993 - val_accuracy: 0.8784\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8761 - val_loss: 0.3692 - val_accuracy: 0.8795\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8743 - val_loss: 0.3737 - val_accuracy: 0.8716\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8767 - val_loss: 0.3869 - val_accuracy: 0.8791\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8759 - val_loss: 0.3610 - val_accuracy: 0.8679\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8782 - val_loss: 0.3629 - val_accuracy: 0.8724\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8745 - val_loss: 0.3731 - val_accuracy: 0.8549\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8746 - val_loss: 0.4075 - val_accuracy: 0.8716\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8727 - val_loss: 0.3639 - val_accuracy: 0.8694\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8759 - val_loss: 0.3954 - val_accuracy: 0.8705\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8735 - val_loss: 0.3946 - val_accuracy: 0.8646\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8747 - val_loss: 0.3611 - val_accuracy: 0.8713\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8747 - val_loss: 0.3632 - val_accuracy: 0.8664\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8756 - val_loss: 0.3744 - val_accuracy: 0.8638\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8751 - val_loss: 0.3768 - val_accuracy: 0.8806\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8744 - val_loss: 0.3824 - val_accuracy: 0.8806\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8716 - val_loss: 0.3689 - val_accuracy: 0.8604\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8774 - val_loss: 0.3974 - val_accuracy: 0.8608\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8766 - val_loss: 0.3638 - val_accuracy: 0.8806\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8756 - val_loss: 0.4464 - val_accuracy: 0.8728\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8715 - val_loss: 0.4392 - val_accuracy: 0.8377\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8745 - val_loss: 0.3761 - val_accuracy: 0.8746\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8756 - val_loss: 0.3640 - val_accuracy: 0.8716\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.3392 - accuracy: 0.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▏                                                                    | 2/10 [03:14<12:59, 97.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3391503095626831, 0.8814303874969482]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1234/40000 [00:00<00:03, 12335.28it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2473/40000 [00:00<00:03, 12365.53it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3713/40000 [00:00<00:02, 12378.29it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4951/40000 [00:00<00:02, 11971.11it/s]\u001b[A\n",
      " 15%|███████████▉                                                                 | 6192/40000 [00:00<00:02, 12125.34it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7407/40000 [00:00<00:02, 12013.98it/s]\u001b[A\n",
      " 22%|████████████████▌                                                            | 8610/40000 [00:00<00:02, 11991.10it/s]\u001b[A\n",
      " 25%|██████████████████▉                                                          | 9810/40000 [00:00<00:02, 11801.78it/s]\u001b[A\n",
      " 27%|████████████████████▉                                                       | 10992/40000 [00:00<00:02, 11724.35it/s]\u001b[A\n",
      " 30%|███████████████████████                                                     | 12166/40000 [00:01<00:02, 11701.50it/s]\u001b[A\n",
      " 33%|█████████████████████████▎                                                  | 13337/40000 [00:01<00:02, 11615.52it/s]\u001b[A\n",
      " 36%|███████████████████████████▌                                                | 14499/40000 [00:01<00:02, 11522.70it/s]\u001b[A\n",
      " 39%|█████████████████████████████▉                                              | 15746/40000 [00:01<00:02, 11802.19it/s]\u001b[A\n",
      " 42%|████████████████████████████████▎                                           | 16990/40000 [00:01<00:01, 11990.50it/s]\u001b[A\n",
      " 46%|██████████████████████████████████▋                                         | 18234/40000 [00:01<00:01, 12122.55it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████                                       | 19478/40000 [00:01<00:01, 12214.62it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▍                                    | 20724/40000 [00:01<00:01, 12285.75it/s]\u001b[A\n",
      " 55%|█████████████████████████████████████████▋                                  | 21971/40000 [00:01<00:01, 12338.55it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████                                | 23217/40000 [00:01<00:01, 12373.17it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████▍                             | 24462/40000 [00:02<00:01, 12395.57it/s]\u001b[A\n",
      " 64%|████████████████████████████████████████████████▊                           | 25705/40000 [00:02<00:01, 12405.63it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████▏                        | 26950/40000 [00:02<00:01, 12417.27it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████▌                      | 28192/40000 [00:02<00:00, 12391.92it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████▉                    | 29439/40000 [00:02<00:00, 12414.88it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▎                 | 30685/40000 [00:02<00:00, 12426.66it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▋               | 31930/40000 [00:02<00:00, 12433.32it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████             | 33175/40000 [00:02<00:00, 12437.86it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████▍          | 34421/40000 [00:02<00:00, 12444.41it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████▊        | 35669/40000 [00:02<00:00, 12452.87it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████▏     | 36915/40000 [00:03<00:00, 12444.21it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████▌   | 38162/40000 [00:03<00:00, 12449.85it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12211.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 6.4626 - accuracy: 0.4046 - val_loss: 2.5083 - val_accuracy: 0.5549\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.5159 - accuracy: 0.6029 - val_loss: 0.8694 - val_accuracy: 0.6933\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7729 - accuracy: 0.7237 - val_loss: 0.6703 - val_accuracy: 0.7119\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.7818 - val_loss: 0.5415 - val_accuracy: 0.8119\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.8015 - val_loss: 0.4725 - val_accuracy: 0.8347\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8219 - val_loss: 0.4502 - val_accuracy: 0.8164\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8180 - val_loss: 0.5644 - val_accuracy: 0.6903\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8190 - val_loss: 0.4125 - val_accuracy: 0.8545\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8347 - val_loss: 0.4077 - val_accuracy: 0.8653\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8322 - val_loss: 0.3991 - val_accuracy: 0.8563\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8342 - val_loss: 0.4059 - val_accuracy: 0.8172\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8386 - val_loss: 0.3911 - val_accuracy: 0.8593\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8346 - val_loss: 0.4205 - val_accuracy: 0.8459\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8420 - val_loss: 0.3892 - val_accuracy: 0.8377\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8460 - val_loss: 0.3796 - val_accuracy: 0.8608\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8412 - val_loss: 0.3960 - val_accuracy: 0.8056\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8480 - val_loss: 0.3770 - val_accuracy: 0.8474\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8416 - val_loss: 0.3736 - val_accuracy: 0.8672\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8467 - val_loss: 0.3708 - val_accuracy: 0.8519\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8488 - val_loss: 0.3734 - val_accuracy: 0.8608\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8439 - val_loss: 0.3653 - val_accuracy: 0.8642\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8479 - val_loss: 0.3567 - val_accuracy: 0.8672\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8489 - val_loss: 0.3783 - val_accuracy: 0.8343\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8501 - val_loss: 0.3621 - val_accuracy: 0.8575\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8492 - val_loss: 0.3962 - val_accuracy: 0.8493\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8525 - val_loss: 0.3620 - val_accuracy: 0.8534\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8499 - val_loss: 0.3648 - val_accuracy: 0.8522\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8494 - val_loss: 0.3521 - val_accuracy: 0.8739\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8552 - val_loss: 0.3560 - val_accuracy: 0.8694\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8548 - val_loss: 0.3555 - val_accuracy: 0.8597\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8532 - val_loss: 0.3536 - val_accuracy: 0.8549\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8566 - val_loss: 0.3430 - val_accuracy: 0.8687\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8552 - val_loss: 0.3412 - val_accuracy: 0.8664\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8510 - val_loss: 0.3604 - val_accuracy: 0.8642\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8562 - val_loss: 0.3378 - val_accuracy: 0.8705\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8553 - val_loss: 0.3427 - val_accuracy: 0.8713\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8450 - val_loss: 0.3412 - val_accuracy: 0.8705\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8575 - val_loss: 0.3425 - val_accuracy: 0.8705\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8571 - val_loss: 0.3357 - val_accuracy: 0.8709\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8569 - val_loss: 0.3399 - val_accuracy: 0.8724\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8553 - val_loss: 0.3513 - val_accuracy: 0.8366\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8576 - val_loss: 0.3566 - val_accuracy: 0.8597\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8561 - val_loss: 0.3344 - val_accuracy: 0.8728\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8548 - val_loss: 0.3726 - val_accuracy: 0.8578\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8580 - val_loss: 0.3439 - val_accuracy: 0.8731\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8557 - val_loss: 0.3429 - val_accuracy: 0.8534\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8579 - val_loss: 0.3368 - val_accuracy: 0.8575\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8572 - val_loss: 0.3446 - val_accuracy: 0.8634\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8544 - val_loss: 0.3337 - val_accuracy: 0.8582\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8572 - val_loss: 0.3305 - val_accuracy: 0.8675\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8591 - val_loss: 0.3419 - val_accuracy: 0.8694\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8553 - val_loss: 0.3319 - val_accuracy: 0.8627\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8598 - val_loss: 0.3644 - val_accuracy: 0.8571\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8599 - val_loss: 0.3796 - val_accuracy: 0.8112\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8574 - val_loss: 0.3600 - val_accuracy: 0.8340\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8574 - val_loss: 0.3334 - val_accuracy: 0.8731\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8559 - val_loss: 0.3535 - val_accuracy: 0.8698\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8576 - val_loss: 0.3287 - val_accuracy: 0.8690\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8583 - val_loss: 0.3500 - val_accuracy: 0.8679\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8597 - val_loss: 0.3720 - val_accuracy: 0.8157\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8600 - val_loss: 0.3794 - val_accuracy: 0.8179\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8534 - val_loss: 0.3316 - val_accuracy: 0.8810\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8560 - val_loss: 0.3383 - val_accuracy: 0.8679\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8553 - val_loss: 0.3418 - val_accuracy: 0.8384\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8586 - val_loss: 0.3315 - val_accuracy: 0.8593\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8615 - val_loss: 0.3242 - val_accuracy: 0.8638\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8553 - val_loss: 0.3760 - val_accuracy: 0.8086\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8597 - val_loss: 0.3444 - val_accuracy: 0.8366\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8553 - val_loss: 0.3300 - val_accuracy: 0.8787\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8600 - val_loss: 0.3490 - val_accuracy: 0.8646\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8623 - val_loss: 0.3278 - val_accuracy: 0.8556\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8571 - val_loss: 0.3327 - val_accuracy: 0.8504\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8564 - val_loss: 0.3263 - val_accuracy: 0.8575\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8609 - val_loss: 0.3393 - val_accuracy: 0.8728\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8553 - val_loss: 0.3769 - val_accuracy: 0.8560\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8586 - val_loss: 0.3364 - val_accuracy: 0.8444\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8593 - val_loss: 0.3332 - val_accuracy: 0.8690\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8607 - val_loss: 0.3280 - val_accuracy: 0.8746\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8610 - val_loss: 0.3257 - val_accuracy: 0.8716\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8565 - val_loss: 0.3623 - val_accuracy: 0.8646\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8588 - val_loss: 0.3359 - val_accuracy: 0.8627\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8620 - val_loss: 0.3444 - val_accuracy: 0.8653\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8611 - val_loss: 0.3318 - val_accuracy: 0.8709\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8622 - val_loss: 0.4430 - val_accuracy: 0.7709\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8567 - val_loss: 0.3527 - val_accuracy: 0.8224\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8578 - val_loss: 0.3564 - val_accuracy: 0.8328\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8587 - val_loss: 0.3341 - val_accuracy: 0.8724\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8590 - val_loss: 0.3581 - val_accuracy: 0.8545\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8574 - val_loss: 0.3426 - val_accuracy: 0.8381\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8577 - val_loss: 0.3368 - val_accuracy: 0.8746\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8579 - val_loss: 0.3281 - val_accuracy: 0.8507\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8590 - val_loss: 0.3207 - val_accuracy: 0.8750\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8573 - val_loss: 0.3238 - val_accuracy: 0.8616\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8606 - val_loss: 0.3816 - val_accuracy: 0.8101\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8623 - val_loss: 0.3273 - val_accuracy: 0.8545\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8618 - val_loss: 0.3234 - val_accuracy: 0.8731\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8618 - val_loss: 0.3300 - val_accuracy: 0.8668\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8611 - val_loss: 0.3301 - val_accuracy: 0.8608\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8598 - val_loss: 0.3418 - val_accuracy: 0.8340\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8584 - val_loss: 0.3318 - val_accuracy: 0.8687\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8574 - val_loss: 0.3263 - val_accuracy: 0.8515\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8598 - val_loss: 0.3393 - val_accuracy: 0.8343\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8613 - val_loss: 0.3284 - val_accuracy: 0.8496\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8607 - val_loss: 0.3569 - val_accuracy: 0.8601\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8598 - val_loss: 0.3255 - val_accuracy: 0.8545\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8632 - val_loss: 0.3211 - val_accuracy: 0.8716\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8636 - val_loss: 0.3600 - val_accuracy: 0.8586\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8603 - val_loss: 0.3247 - val_accuracy: 0.8690\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8583 - val_loss: 0.3421 - val_accuracy: 0.8325\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8608 - val_loss: 0.3425 - val_accuracy: 0.8354\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8552 - val_loss: 0.3335 - val_accuracy: 0.8466\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8626 - val_loss: 0.3218 - val_accuracy: 0.8668\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8623 - val_loss: 0.3194 - val_accuracy: 0.8754\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8583 - val_loss: 0.3571 - val_accuracy: 0.8463\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8609 - val_loss: 0.3204 - val_accuracy: 0.8772\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8586 - val_loss: 0.3270 - val_accuracy: 0.8493\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8593 - val_loss: 0.3290 - val_accuracy: 0.8552\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8580 - val_loss: 0.3183 - val_accuracy: 0.8638\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8619 - val_loss: 0.3242 - val_accuracy: 0.8690\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8587 - val_loss: 0.3300 - val_accuracy: 0.8560\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8599 - val_loss: 0.3450 - val_accuracy: 0.8690\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8602 - val_loss: 0.3403 - val_accuracy: 0.8429\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8589 - val_loss: 0.3756 - val_accuracy: 0.8104\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8610 - val_loss: 0.3352 - val_accuracy: 0.8653\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8596 - val_loss: 0.3291 - val_accuracy: 0.8705\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8623 - val_loss: 0.3696 - val_accuracy: 0.8552\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8566 - val_loss: 0.3289 - val_accuracy: 0.8463\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8582 - val_loss: 0.3253 - val_accuracy: 0.8567\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8574 - val_loss: 0.3327 - val_accuracy: 0.8384\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8620 - val_loss: 0.3287 - val_accuracy: 0.8757\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8602 - val_loss: 0.3202 - val_accuracy: 0.8757\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8615 - val_loss: 0.3221 - val_accuracy: 0.8713\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8625 - val_loss: 0.3224 - val_accuracy: 0.8765\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8614 - val_loss: 0.3238 - val_accuracy: 0.8601\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8611 - val_loss: 0.3254 - val_accuracy: 0.8720\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8595 - val_loss: 0.3503 - val_accuracy: 0.8377\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8604 - val_loss: 0.3228 - val_accuracy: 0.8660\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8605 - val_loss: 0.3376 - val_accuracy: 0.8381\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8567 - val_loss: 0.3172 - val_accuracy: 0.8709\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8594 - val_loss: 0.3492 - val_accuracy: 0.8429\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8607 - val_loss: 0.3395 - val_accuracy: 0.8709\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8603 - val_loss: 0.3337 - val_accuracy: 0.8571\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8608 - val_loss: 0.3260 - val_accuracy: 0.8709\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8603 - val_loss: 0.3271 - val_accuracy: 0.8575\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8552 - val_loss: 0.3244 - val_accuracy: 0.8672\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8598 - val_loss: 0.3504 - val_accuracy: 0.8649\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8594 - val_loss: 0.3213 - val_accuracy: 0.8750\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8620 - val_loss: 0.3418 - val_accuracy: 0.8321\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8580 - val_loss: 0.3423 - val_accuracy: 0.8381\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8603 - val_loss: 0.3448 - val_accuracy: 0.8291\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.3351 - accuracy: 0.8381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▊                                                            | 3/10 [04:52<11:21, 97.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.335074245929718, 0.8380938172340393]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1189/40000 [00:00<00:03, 11888.74it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2420/40000 [00:00<00:03, 12133.20it/s]\u001b[A\n",
      "  9%|███████                                                                      | 3652/40000 [00:00<00:02, 12216.09it/s]\u001b[A\n",
      " 12%|█████████▍                                                                   | 4882/40000 [00:00<00:02, 12248.81it/s]\u001b[A\n",
      " 15%|███████████▊                                                                 | 6107/40000 [00:00<00:02, 11778.80it/s]\u001b[A\n",
      " 18%|██████████████                                                               | 7322/40000 [00:00<00:02, 11900.98it/s]\u001b[A\n",
      " 21%|████████████████▍                                                            | 8566/40000 [00:00<00:02, 12073.49it/s]\u001b[A\n",
      " 25%|██████████████████▉                                                          | 9810/40000 [00:00<00:02, 12186.51it/s]\u001b[A\n",
      " 28%|█████████████████████                                                       | 11062/40000 [00:00<00:02, 12288.28it/s]\u001b[A\n",
      " 31%|███████████████████████▍                                                    | 12314/40000 [00:01<00:02, 12356.35it/s]\u001b[A\n",
      " 34%|█████████████████████████▊                                                  | 13567/40000 [00:01<00:02, 12406.79it/s]\u001b[A\n",
      " 37%|████████████████████████████▏                                               | 14819/40000 [00:01<00:02, 12438.04it/s]\u001b[A\n",
      " 40%|██████████████████████████████▌                                             | 16070/40000 [00:01<00:01, 12458.14it/s]\u001b[A\n",
      " 43%|████████████████████████████████▉                                           | 17322/40000 [00:01<00:01, 12475.00it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▎                                        | 18573/40000 [00:01<00:01, 12482.90it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▋                                      | 19824/40000 [00:01<00:01, 12489.36it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████                                    | 21074/40000 [00:01<00:01, 12476.93it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▍                                 | 22322/40000 [00:01<00:01, 12463.70it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▊                               | 23569/40000 [00:01<00:01, 12465.25it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▏                            | 24816/40000 [00:02<00:01, 12456.03it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▌                          | 26062/40000 [00:02<00:01, 12456.54it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▉                        | 27310/40000 [00:02<00:01, 12462.68it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████▎                     | 28558/40000 [00:02<00:00, 12466.21it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████▋                   | 29805/40000 [00:02<00:00, 12458.69it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████▉                 | 31051/40000 [00:02<00:00, 12454.60it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▎              | 32298/40000 [00:02<00:00, 12456.71it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▋            | 33544/40000 [00:02<00:00, 12452.83it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████          | 34790/40000 [00:02<00:00, 12414.83it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▍       | 36032/40000 [00:02<00:00, 12412.99it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▊     | 37275/40000 [00:03<00:00, 12417.91it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▏  | 38521/40000 [00:03<00:00, 12428.08it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12367.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 10.1943 - accuracy: 0.3277 - val_loss: 1.8601 - val_accuracy: 0.6716\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9743 - accuracy: 0.7666 - val_loss: 0.5332 - val_accuracy: 0.8373\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8760 - val_loss: 0.3449 - val_accuracy: 0.8981\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.9112 - val_loss: 0.2728 - val_accuracy: 0.9119\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9279 - val_loss: 0.2347 - val_accuracy: 0.9183\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9337 - val_loss: 0.2248 - val_accuracy: 0.9198\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9413 - val_loss: 0.2146 - val_accuracy: 0.9321\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9447 - val_loss: 0.2024 - val_accuracy: 0.9269\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9478 - val_loss: 0.1741 - val_accuracy: 0.9429\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9520 - val_loss: 0.1616 - val_accuracy: 0.9478\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9517 - val_loss: 0.1609 - val_accuracy: 0.9481\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9553 - val_loss: 0.1581 - val_accuracy: 0.9418\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9575 - val_loss: 0.1498 - val_accuracy: 0.9519\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9582 - val_loss: 0.1447 - val_accuracy: 0.9537\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9583 - val_loss: 0.1469 - val_accuracy: 0.9478\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9583 - val_loss: 0.1482 - val_accuracy: 0.9463\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9592 - val_loss: 0.1357 - val_accuracy: 0.9552\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9595 - val_loss: 0.1294 - val_accuracy: 0.9545\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9600 - val_loss: 0.1247 - val_accuracy: 0.9590\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9622 - val_loss: 0.1223 - val_accuracy: 0.9586\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9605 - val_loss: 0.1179 - val_accuracy: 0.9601\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9622 - val_loss: 0.1226 - val_accuracy: 0.9590\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9611 - val_loss: 0.1229 - val_accuracy: 0.9552\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9597 - val_loss: 0.1168 - val_accuracy: 0.9623\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9616 - val_loss: 0.1167 - val_accuracy: 0.9619\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9623 - val_loss: 0.1132 - val_accuracy: 0.9604\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9608 - val_loss: 0.1541 - val_accuracy: 0.9325\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9594 - val_loss: 0.1177 - val_accuracy: 0.9582\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.9622 - val_loss: 0.1126 - val_accuracy: 0.9601\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9604 - val_loss: 0.1122 - val_accuracy: 0.9631\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9643 - val_loss: 0.1061 - val_accuracy: 0.9642\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9592 - val_loss: 0.1060 - val_accuracy: 0.9601\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9624 - val_loss: 0.1123 - val_accuracy: 0.9590\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9610 - val_loss: 0.1141 - val_accuracy: 0.9582\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.9617 - val_loss: 0.1195 - val_accuracy: 0.9586\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9618 - val_loss: 0.1162 - val_accuracy: 0.9556\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9619 - val_loss: 0.1111 - val_accuracy: 0.9567\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9620 - val_loss: 0.1171 - val_accuracy: 0.9515\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9607 - val_loss: 0.1217 - val_accuracy: 0.9586\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9610 - val_loss: 0.1025 - val_accuracy: 0.9604\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.9635 - val_loss: 0.1094 - val_accuracy: 0.9593\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9612 - val_loss: 0.1103 - val_accuracy: 0.9616\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9609 - val_loss: 0.1298 - val_accuracy: 0.9534\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.9613 - val_loss: 0.1025 - val_accuracy: 0.9660\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9636 - val_loss: 0.1194 - val_accuracy: 0.9504\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9626 - val_loss: 0.1129 - val_accuracy: 0.9593\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9621 - val_loss: 0.1222 - val_accuracy: 0.9590\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9636 - val_loss: 0.1029 - val_accuracy: 0.9638\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9624 - val_loss: 0.1127 - val_accuracy: 0.9612\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9632 - val_loss: 0.1037 - val_accuracy: 0.9627\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9631 - val_loss: 0.1001 - val_accuracy: 0.9634\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.9611 - val_loss: 0.1022 - val_accuracy: 0.9623\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9619 - val_loss: 0.1255 - val_accuracy: 0.9437\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9648 - val_loss: 0.1025 - val_accuracy: 0.9657\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9616 - val_loss: 0.1073 - val_accuracy: 0.9634\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9643 - val_loss: 0.0980 - val_accuracy: 0.9627\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9634 - val_loss: 0.1001 - val_accuracy: 0.9664\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9636 - val_loss: 0.1092 - val_accuracy: 0.9619\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9645 - val_loss: 0.1125 - val_accuracy: 0.9522\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9635 - val_loss: 0.1212 - val_accuracy: 0.9489\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.9619 - val_loss: 0.1051 - val_accuracy: 0.9642\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9633 - val_loss: 0.1037 - val_accuracy: 0.9597\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9643 - val_loss: 0.0983 - val_accuracy: 0.9660\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9631 - val_loss: 0.0998 - val_accuracy: 0.9675\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9645 - val_loss: 0.1025 - val_accuracy: 0.9649\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9638 - val_loss: 0.1109 - val_accuracy: 0.9545\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9642 - val_loss: 0.1066 - val_accuracy: 0.9638\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9642 - val_loss: 0.1304 - val_accuracy: 0.9414\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9640 - val_loss: 0.1233 - val_accuracy: 0.9511\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9622 - val_loss: 0.1207 - val_accuracy: 0.9586\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9627 - val_loss: 0.1003 - val_accuracy: 0.9660\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9630 - val_loss: 0.1020 - val_accuracy: 0.9638\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9607 - val_loss: 0.1013 - val_accuracy: 0.9627\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9637 - val_loss: 0.0979 - val_accuracy: 0.9657\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.9630 - val_loss: 0.1099 - val_accuracy: 0.9597\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9636 - val_loss: 0.0986 - val_accuracy: 0.9649\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9637 - val_loss: 0.1006 - val_accuracy: 0.9604\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9645 - val_loss: 0.1084 - val_accuracy: 0.9608\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9646 - val_loss: 0.1003 - val_accuracy: 0.9672\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.9643 - val_loss: 0.1000 - val_accuracy: 0.9642\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9631 - val_loss: 0.1321 - val_accuracy: 0.9541\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9630 - val_loss: 0.1151 - val_accuracy: 0.9612\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9620 - val_loss: 0.1165 - val_accuracy: 0.9500\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9636 - val_loss: 0.1021 - val_accuracy: 0.9627\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9640 - val_loss: 0.0971 - val_accuracy: 0.9657\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9623 - val_loss: 0.1023 - val_accuracy: 0.9597\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9625 - val_loss: 0.1037 - val_accuracy: 0.9563\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9635 - val_loss: 0.1072 - val_accuracy: 0.9638\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.9614 - val_loss: 0.1029 - val_accuracy: 0.9612\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9639 - val_loss: 0.1139 - val_accuracy: 0.9619\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9645 - val_loss: 0.0956 - val_accuracy: 0.9664\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9650 - val_loss: 0.1313 - val_accuracy: 0.9545\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9628 - val_loss: 0.1104 - val_accuracy: 0.9515\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9592 - val_loss: 0.1037 - val_accuracy: 0.9657\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9641 - val_loss: 0.1176 - val_accuracy: 0.9586\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9640 - val_loss: 0.1076 - val_accuracy: 0.9590\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9636 - val_loss: 0.1076 - val_accuracy: 0.9634\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9641 - val_loss: 0.1074 - val_accuracy: 0.9627\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9634 - val_loss: 0.1020 - val_accuracy: 0.9586\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9621 - val_loss: 0.1044 - val_accuracy: 0.9638\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9621 - val_loss: 0.0966 - val_accuracy: 0.9675\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9652 - val_loss: 0.1071 - val_accuracy: 0.9642\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9628 - val_loss: 0.1064 - val_accuracy: 0.9646\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9640 - val_loss: 0.0972 - val_accuracy: 0.9627\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9638 - val_loss: 0.0982 - val_accuracy: 0.9668\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9652 - val_loss: 0.0984 - val_accuracy: 0.9683\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9612 - val_loss: 0.0963 - val_accuracy: 0.9668\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9636 - val_loss: 0.0970 - val_accuracy: 0.9675\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9636 - val_loss: 0.1090 - val_accuracy: 0.9545\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.9643 - val_loss: 0.1083 - val_accuracy: 0.9646\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9640 - val_loss: 0.1013 - val_accuracy: 0.9616\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9638 - val_loss: 0.0997 - val_accuracy: 0.9623\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9614 - val_loss: 0.0952 - val_accuracy: 0.9668\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9641 - val_loss: 0.0969 - val_accuracy: 0.9646\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.9645 - val_loss: 0.1055 - val_accuracy: 0.9623\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9641 - val_loss: 0.0993 - val_accuracy: 0.9619\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9631 - val_loss: 0.1042 - val_accuracy: 0.9634\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9640 - val_loss: 0.1253 - val_accuracy: 0.9578\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9656 - val_loss: 0.1084 - val_accuracy: 0.9601\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9635 - val_loss: 0.0983 - val_accuracy: 0.9675\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9634 - val_loss: 0.1012 - val_accuracy: 0.9582\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9640 - val_loss: 0.1117 - val_accuracy: 0.9623\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9629 - val_loss: 0.1083 - val_accuracy: 0.9556\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9653 - val_loss: 0.0999 - val_accuracy: 0.9638\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9625 - val_loss: 0.1026 - val_accuracy: 0.9690\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9637 - val_loss: 0.1006 - val_accuracy: 0.9657\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9649 - val_loss: 0.1103 - val_accuracy: 0.9657\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9655 - val_loss: 0.1500 - val_accuracy: 0.9336\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9637 - val_loss: 0.1057 - val_accuracy: 0.9612\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.9639 - val_loss: 0.0999 - val_accuracy: 0.9649\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9621 - val_loss: 0.0942 - val_accuracy: 0.9649\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9645 - val_loss: 0.0986 - val_accuracy: 0.9638\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9663 - val_loss: 0.0961 - val_accuracy: 0.9675\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9622 - val_loss: 0.0998 - val_accuracy: 0.9657\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9612 - val_loss: 0.1032 - val_accuracy: 0.9623\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.9635 - val_loss: 0.1190 - val_accuracy: 0.9601\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.9635 - val_loss: 0.1001 - val_accuracy: 0.9657\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9638 - val_loss: 0.0972 - val_accuracy: 0.9646\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.9640 - val_loss: 0.0976 - val_accuracy: 0.9675\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.9644 - val_loss: 0.1069 - val_accuracy: 0.9563\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9641 - val_loss: 0.0966 - val_accuracy: 0.9653\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.9646 - val_loss: 0.0979 - val_accuracy: 0.9660\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9646 - val_loss: 0.0949 - val_accuracy: 0.9687\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9637 - val_loss: 0.1186 - val_accuracy: 0.9619\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9641 - val_loss: 0.1120 - val_accuracy: 0.9623\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9636 - val_loss: 0.0954 - val_accuracy: 0.9649\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9641 - val_loss: 0.1013 - val_accuracy: 0.9668\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9644 - val_loss: 0.0976 - val_accuracy: 0.9631\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9641 - val_loss: 0.1008 - val_accuracy: 0.9664\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9645 - val_loss: 0.1345 - val_accuracy: 0.9392\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.1320 - accuracy: 0.9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▍                                                   | 4/10 [06:28<09:41, 96.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13203145563602448, 0.9434805512428284]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1184/40000 [00:00<00:03, 11834.40it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2413/40000 [00:00<00:03, 12099.11it/s]\u001b[A\n",
      "  9%|███████                                                                      | 3640/40000 [00:00<00:02, 12175.66it/s]\u001b[A\n",
      " 12%|█████████▎                                                                   | 4866/40000 [00:00<00:02, 12206.74it/s]\u001b[A\n",
      " 15%|███████████▋                                                                 | 6099/40000 [00:00<00:02, 12249.09it/s]\u001b[A\n",
      " 18%|██████████████                                                               | 7331/40000 [00:00<00:02, 12272.85it/s]\u001b[A\n",
      " 21%|████████████████▍                                                            | 8562/40000 [00:00<00:02, 12283.09it/s]\u001b[A\n",
      " 24%|██████████████████▊                                                          | 9792/40000 [00:00<00:02, 12285.55it/s]\u001b[A\n",
      " 28%|████████████████████▉                                                       | 11028/40000 [00:00<00:02, 12306.12it/s]\u001b[A\n",
      " 31%|███████████████████████▎                                                    | 12262/40000 [00:01<00:02, 12314.68it/s]\u001b[A\n",
      " 34%|█████████████████████████▋                                                  | 13496/40000 [00:01<00:02, 12322.02it/s]\u001b[A\n",
      " 37%|███████████████████████████▉                                                | 14729/40000 [00:01<00:02, 12323.63it/s]\u001b[A\n",
      " 40%|██████████████████████████████▎                                             | 15962/40000 [00:01<00:01, 12319.75it/s]\u001b[A\n",
      " 43%|████████████████████████████████▋                                           | 17199/40000 [00:01<00:01, 12332.39it/s]\u001b[A\n",
      " 46%|███████████████████████████████████                                         | 18433/40000 [00:01<00:01, 12332.42it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▎                                      | 19667/40000 [00:01<00:01, 12332.13it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▋                                    | 20901/40000 [00:01<00:01, 12314.70it/s]\u001b[A\n",
      " 55%|██████████████████████████████████████████                                  | 22133/40000 [00:01<00:01, 12308.30it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████▍                               | 23365/40000 [00:01<00:01, 12309.45it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████▋                             | 24596/40000 [00:02<00:01, 12256.82it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████                           | 25827/40000 [00:02<00:01, 12271.08it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▍                        | 27058/40000 [00:02<00:01, 12279.79it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▊                      | 28291/40000 [00:02<00:00, 12293.82it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████                    | 29525/40000 [00:02<00:00, 12305.66it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▍                 | 30759/40000 [00:02<00:00, 12314.72it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▊               | 31991/40000 [00:02<00:00, 12312.99it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▏            | 33225/40000 [00:02<00:00, 12318.44it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████▍          | 34459/40000 [00:02<00:00, 12322.26it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████▊        | 35692/40000 [00:02<00:00, 12316.63it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████▏     | 36927/40000 [00:03<00:00, 12324.14it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████▌   | 38160/40000 [00:03<00:00, 12313.48it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12290.85it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 7.5471 - accuracy: 0.4065 - val_loss: 1.7333 - val_accuracy: 0.6287\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.0815 - accuracy: 0.6799 - val_loss: 0.6352 - val_accuracy: 0.7261\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7603 - val_loss: 0.4210 - val_accuracy: 0.8213\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.7985 - val_loss: 0.3790 - val_accuracy: 0.8336\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8115 - val_loss: 0.3698 - val_accuracy: 0.8127\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8005 - val_loss: 0.3883 - val_accuracy: 0.7746\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8197 - val_loss: 0.3852 - val_accuracy: 0.7679\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8136 - val_loss: 0.3566 - val_accuracy: 0.7955\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8276 - val_loss: 0.4119 - val_accuracy: 0.7522\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8283 - val_loss: 0.3485 - val_accuracy: 0.8377\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8273 - val_loss: 0.3431 - val_accuracy: 0.8444\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8321 - val_loss: 0.3384 - val_accuracy: 0.8418\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8285 - val_loss: 0.3224 - val_accuracy: 0.8455\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8261 - val_loss: 0.3404 - val_accuracy: 0.8112\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8330 - val_loss: 0.3223 - val_accuracy: 0.8403\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8318 - val_loss: 0.3472 - val_accuracy: 0.8377\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8319 - val_loss: 0.3247 - val_accuracy: 0.8246\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8318 - val_loss: 0.3436 - val_accuracy: 0.8019\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8320 - val_loss: 0.3178 - val_accuracy: 0.8429\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8370 - val_loss: 0.3251 - val_accuracy: 0.8265\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8318 - val_loss: 0.3114 - val_accuracy: 0.8440\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8363 - val_loss: 0.3215 - val_accuracy: 0.8481\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8329 - val_loss: 0.3117 - val_accuracy: 0.8414\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8381 - val_loss: 0.3153 - val_accuracy: 0.8366\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8294 - val_loss: 0.3233 - val_accuracy: 0.8250\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8373 - val_loss: 0.3231 - val_accuracy: 0.8351\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8347 - val_loss: 0.3173 - val_accuracy: 0.8358\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8330 - val_loss: 0.3284 - val_accuracy: 0.8410\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8334 - val_loss: 0.3108 - val_accuracy: 0.8410\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8392 - val_loss: 0.3095 - val_accuracy: 0.8369\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8290 - val_loss: 0.3087 - val_accuracy: 0.8399\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8349 - val_loss: 0.3237 - val_accuracy: 0.8425\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8371 - val_loss: 0.3268 - val_accuracy: 0.8425\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8348 - val_loss: 0.3121 - val_accuracy: 0.8444\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8332 - val_loss: 0.3169 - val_accuracy: 0.8410\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8365 - val_loss: 0.3129 - val_accuracy: 0.8459\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8327 - val_loss: 0.3222 - val_accuracy: 0.8388\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8368 - val_loss: 0.3243 - val_accuracy: 0.8340\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8365 - val_loss: 0.3154 - val_accuracy: 0.8425\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8348 - val_loss: 0.3261 - val_accuracy: 0.8470\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8369 - val_loss: 0.3166 - val_accuracy: 0.8437\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8367 - val_loss: 0.3263 - val_accuracy: 0.8153\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8357 - val_loss: 0.3228 - val_accuracy: 0.8216\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8344 - val_loss: 0.3113 - val_accuracy: 0.8343\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8353 - val_loss: 0.3257 - val_accuracy: 0.8198\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8384 - val_loss: 0.3068 - val_accuracy: 0.8429\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8352 - val_loss: 0.3182 - val_accuracy: 0.8377\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8380 - val_loss: 0.3197 - val_accuracy: 0.8403\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8383 - val_loss: 0.3057 - val_accuracy: 0.8425\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8364 - val_loss: 0.3199 - val_accuracy: 0.8295\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8381 - val_loss: 0.3092 - val_accuracy: 0.8358\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8341 - val_loss: 0.3082 - val_accuracy: 0.8425\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8399 - val_loss: 0.3306 - val_accuracy: 0.8358\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8364 - val_loss: 0.3123 - val_accuracy: 0.8366\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8383 - val_loss: 0.3105 - val_accuracy: 0.8448\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8357 - val_loss: 0.3134 - val_accuracy: 0.8489\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8341 - val_loss: 0.3056 - val_accuracy: 0.8429\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8363 - val_loss: 0.3077 - val_accuracy: 0.8444\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8359 - val_loss: 0.3277 - val_accuracy: 0.8254\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8369 - val_loss: 0.3500 - val_accuracy: 0.8093\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8369 - val_loss: 0.3069 - val_accuracy: 0.8425\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8373 - val_loss: 0.3216 - val_accuracy: 0.8366\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8367 - val_loss: 0.3242 - val_accuracy: 0.8463\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8362 - val_loss: 0.3110 - val_accuracy: 0.8422\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8343 - val_loss: 0.3037 - val_accuracy: 0.8425\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8347 - val_loss: 0.3303 - val_accuracy: 0.8407\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8390 - val_loss: 0.3163 - val_accuracy: 0.8317\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8314 - val_loss: 0.3111 - val_accuracy: 0.8377\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8392 - val_loss: 0.3032 - val_accuracy: 0.8422\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8378 - val_loss: 0.3239 - val_accuracy: 0.8224\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8337 - val_loss: 0.3034 - val_accuracy: 0.8455\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8399 - val_loss: 0.3052 - val_accuracy: 0.8451\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8385 - val_loss: 0.3113 - val_accuracy: 0.8354\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8358 - val_loss: 0.3144 - val_accuracy: 0.8392\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8375 - val_loss: 0.3355 - val_accuracy: 0.8459\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8354 - val_loss: 0.3143 - val_accuracy: 0.8325\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8386 - val_loss: 0.3097 - val_accuracy: 0.8388\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8359 - val_loss: 0.3109 - val_accuracy: 0.8325\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8385 - val_loss: 0.3201 - val_accuracy: 0.8425\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8319 - val_loss: 0.3054 - val_accuracy: 0.8459\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8404 - val_loss: 0.3178 - val_accuracy: 0.8246\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8392 - val_loss: 0.3264 - val_accuracy: 0.8466\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8338 - val_loss: 0.3025 - val_accuracy: 0.8407\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8411 - val_loss: 0.3223 - val_accuracy: 0.8228\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8379 - val_loss: 0.3271 - val_accuracy: 0.8160\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8390 - val_loss: 0.3062 - val_accuracy: 0.8377\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8379 - val_loss: 0.3127 - val_accuracy: 0.8343\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8375 - val_loss: 0.3483 - val_accuracy: 0.8045\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8366 - val_loss: 0.3207 - val_accuracy: 0.8306\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8388 - val_loss: 0.3110 - val_accuracy: 0.8362\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8392 - val_loss: 0.3165 - val_accuracy: 0.8254\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8386 - val_loss: 0.3218 - val_accuracy: 0.8414\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8385 - val_loss: 0.3055 - val_accuracy: 0.8366\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8390 - val_loss: 0.3347 - val_accuracy: 0.8175\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8362 - val_loss: 0.3019 - val_accuracy: 0.8433\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8385 - val_loss: 0.3052 - val_accuracy: 0.8366\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8363 - val_loss: 0.3256 - val_accuracy: 0.8403\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8362 - val_loss: 0.3071 - val_accuracy: 0.8381\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8389 - val_loss: 0.3165 - val_accuracy: 0.8396\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8377 - val_loss: 0.3066 - val_accuracy: 0.8399\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8360 - val_loss: 0.3161 - val_accuracy: 0.8340\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8364 - val_loss: 0.3041 - val_accuracy: 0.8407\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8380 - val_loss: 0.3249 - val_accuracy: 0.8198\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8331 - val_loss: 0.3040 - val_accuracy: 0.8429\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8368 - val_loss: 0.3302 - val_accuracy: 0.8455\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8390 - val_loss: 0.3084 - val_accuracy: 0.8328\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8389 - val_loss: 0.3375 - val_accuracy: 0.8399\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8359 - val_loss: 0.4201 - val_accuracy: 0.8287\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8358 - val_loss: 0.3102 - val_accuracy: 0.8369\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8396 - val_loss: 0.3034 - val_accuracy: 0.8410\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8378 - val_loss: 0.3084 - val_accuracy: 0.8362\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8372 - val_loss: 0.3044 - val_accuracy: 0.8440\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8387 - val_loss: 0.3050 - val_accuracy: 0.8366\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8357 - val_loss: 0.3245 - val_accuracy: 0.8463\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8377 - val_loss: 0.3058 - val_accuracy: 0.8369\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8404 - val_loss: 0.3181 - val_accuracy: 0.8287\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8365 - val_loss: 0.3095 - val_accuracy: 0.8332\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8370 - val_loss: 0.3494 - val_accuracy: 0.8049\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8373 - val_loss: 0.3134 - val_accuracy: 0.8317\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8399 - val_loss: 0.3075 - val_accuracy: 0.8377\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8339 - val_loss: 0.3131 - val_accuracy: 0.8265\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8381 - val_loss: 0.3329 - val_accuracy: 0.8127\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8393 - val_loss: 0.3115 - val_accuracy: 0.8317\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8385 - val_loss: 0.3193 - val_accuracy: 0.8399\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8357 - val_loss: 0.3053 - val_accuracy: 0.8373\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8368 - val_loss: 0.3329 - val_accuracy: 0.8179\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8358 - val_loss: 0.3278 - val_accuracy: 0.8403\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8351 - val_loss: 0.3022 - val_accuracy: 0.8410\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8385 - val_loss: 0.3169 - val_accuracy: 0.8407\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8382 - val_loss: 0.3163 - val_accuracy: 0.8384\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8400 - val_loss: 0.3250 - val_accuracy: 0.8399\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8380 - val_loss: 0.3067 - val_accuracy: 0.8351\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8395 - val_loss: 0.3037 - val_accuracy: 0.8396\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8363 - val_loss: 0.3048 - val_accuracy: 0.8366\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8391 - val_loss: 0.3165 - val_accuracy: 0.8321\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8402 - val_loss: 0.3013 - val_accuracy: 0.8396\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8377 - val_loss: 0.3245 - val_accuracy: 0.8228\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8363 - val_loss: 0.3081 - val_accuracy: 0.8433\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8419 - val_loss: 0.3062 - val_accuracy: 0.8373\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8320 - val_loss: 0.3075 - val_accuracy: 0.8392\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8392 - val_loss: 0.3256 - val_accuracy: 0.8187\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8407 - val_loss: 0.3026 - val_accuracy: 0.8459\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8387 - val_loss: 0.3190 - val_accuracy: 0.8351\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8387 - val_loss: 0.3072 - val_accuracy: 0.8373\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8386 - val_loss: 0.3071 - val_accuracy: 0.8418\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8363 - val_loss: 0.3043 - val_accuracy: 0.8396\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8364 - val_loss: 0.3054 - val_accuracy: 0.8392\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8368 - val_loss: 0.3536 - val_accuracy: 0.7955\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8385 - val_loss: 0.3053 - val_accuracy: 0.8437\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8396 - val_loss: 0.3042 - val_accuracy: 0.8377\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████                                           | 5/10 [08:07<08:08, 97.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3013952672481537, 0.8446851968765259]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1259/40000 [00:00<00:03, 12581.16it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2518/40000 [00:00<00:03, 12492.69it/s]\u001b[A\n",
      "  9%|███████▎                                                                     | 3768/40000 [00:00<00:02, 12478.07it/s]\u001b[A\n",
      " 13%|█████████▋                                                                   | 5016/40000 [00:00<00:02, 12461.98it/s]\u001b[A\n",
      " 16%|████████████                                                                 | 6266/40000 [00:00<00:02, 12473.48it/s]\u001b[A\n",
      " 19%|██████████████▍                                                              | 7516/40000 [00:00<00:02, 12480.80it/s]\u001b[A\n",
      " 22%|████████████████▊                                                            | 8765/40000 [00:00<00:02, 12483.33it/s]\u001b[A\n",
      " 25%|███████████████████                                                         | 10014/40000 [00:00<00:02, 12483.40it/s]\u001b[A\n",
      " 28%|█████████████████████▍                                                      | 11263/40000 [00:00<00:02, 12461.49it/s]\u001b[A\n",
      " 31%|███████████████████████▊                                                    | 12510/40000 [00:01<00:02, 12443.44it/s]\u001b[A\n",
      " 34%|██████████████████████████▏                                                 | 13755/40000 [00:01<00:02, 12432.38it/s]\u001b[A\n",
      " 37%|████████████████████████████▍                                               | 14999/40000 [00:01<00:02, 12418.33it/s]\u001b[A\n",
      " 41%|██████████████████████████████▊                                             | 16241/40000 [00:01<00:01, 12405.99it/s]\u001b[A\n",
      " 44%|█████████████████████████████████▏                                          | 17482/40000 [00:01<00:01, 12405.87it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▌                                        | 18723/40000 [00:01<00:01, 12401.87it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▉                                      | 19964/40000 [00:01<00:01, 12397.58it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▎                                   | 21204/40000 [00:01<00:01, 12386.79it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▋                                 | 22443/40000 [00:01<00:01, 12362.70it/s]\u001b[A\n",
      " 59%|█████████████████████████████████████████████                               | 23690/40000 [00:01<00:01, 12393.15it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▎                            | 24930/40000 [00:02<00:01, 12368.31it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▋                          | 26167/40000 [00:02<00:01, 12353.28it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████                        | 27403/40000 [00:02<00:01, 12348.64it/s]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████████▍                     | 28638/40000 [00:02<00:00, 12345.83it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████▊                   | 29873/40000 [00:02<00:00, 12312.02it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████                 | 31105/40000 [00:02<00:00, 12304.37it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▍              | 32338/40000 [00:02<00:00, 12309.19it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▊            | 33570/40000 [00:02<00:00, 12312.24it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████          | 34802/40000 [00:02<00:00, 12314.21it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▍       | 36034/40000 [00:02<00:00, 12313.57it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▊     | 37266/40000 [00:03<00:00, 12313.10it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▏  | 38498/40000 [00:03<00:00, 12306.85it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12374.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 3.1305 - accuracy: 0.4827 - val_loss: 1.0101 - val_accuracy: 0.6123\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7678 - accuracy: 0.6902 - val_loss: 0.7262 - val_accuracy: 0.6653\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.7195 - val_loss: 0.6381 - val_accuracy: 0.7119\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.7334 - val_loss: 0.5942 - val_accuracy: 0.7172\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7435 - val_loss: 0.5791 - val_accuracy: 0.7071\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7520 - val_loss: 0.5769 - val_accuracy: 0.7112\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7435 - val_loss: 0.5528 - val_accuracy: 0.7213\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7492 - val_loss: 0.5594 - val_accuracy: 0.7190\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7469 - val_loss: 0.5325 - val_accuracy: 0.7776\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7576 - val_loss: 0.5293 - val_accuracy: 0.7743\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7569 - val_loss: 0.5298 - val_accuracy: 0.7228\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7663 - val_loss: 0.5133 - val_accuracy: 0.7556\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7672 - val_loss: 0.5025 - val_accuracy: 0.7869\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7664 - val_loss: 0.4996 - val_accuracy: 0.7869\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7692 - val_loss: 0.5099 - val_accuracy: 0.7888\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7692 - val_loss: 0.5144 - val_accuracy: 0.7310\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7623 - val_loss: 0.5736 - val_accuracy: 0.7078\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7687 - val_loss: 0.4924 - val_accuracy: 0.7638\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7708 - val_loss: 0.4897 - val_accuracy: 0.7646\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7594 - val_loss: 0.5637 - val_accuracy: 0.7642\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7668 - val_loss: 0.5278 - val_accuracy: 0.7321\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7663 - val_loss: 0.4843 - val_accuracy: 0.7810\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7645 - val_loss: 0.5078 - val_accuracy: 0.7351\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7682 - val_loss: 0.4971 - val_accuracy: 0.7481\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7933\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7689 - val_loss: 0.4794 - val_accuracy: 0.7586\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7661 - val_loss: 0.5108 - val_accuracy: 0.7877\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7713 - val_loss: 0.4784 - val_accuracy: 0.7616\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7714 - val_loss: 0.4843 - val_accuracy: 0.7687\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7695 - val_loss: 0.5330 - val_accuracy: 0.7761\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7694 - val_loss: 0.5166 - val_accuracy: 0.7302\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7671 - val_loss: 0.4886 - val_accuracy: 0.7478\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7712 - val_loss: 0.4819 - val_accuracy: 0.7496\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7690 - val_loss: 0.5230 - val_accuracy: 0.7765\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7709 - val_loss: 0.4808 - val_accuracy: 0.7813\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7714 - val_loss: 0.4767 - val_accuracy: 0.7590\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7678 - val_loss: 0.4773 - val_accuracy: 0.7552\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7660 - val_loss: 0.4981 - val_accuracy: 0.7716\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7691 - val_loss: 0.4872 - val_accuracy: 0.7489\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7710 - val_loss: 0.4826 - val_accuracy: 0.7451\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7762 - val_loss: 0.5457 - val_accuracy: 0.7228\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7690 - val_loss: 0.4760 - val_accuracy: 0.7549\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7699 - val_loss: 0.4833 - val_accuracy: 0.7623\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7691 - val_loss: 0.4746 - val_accuracy: 0.7575\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7698 - val_loss: 0.5127 - val_accuracy: 0.7437\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7727 - val_loss: 0.4725 - val_accuracy: 0.7821\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7751 - val_loss: 0.5046 - val_accuracy: 0.7784\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7741 - val_loss: 0.5039 - val_accuracy: 0.7817\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7729 - val_loss: 0.4800 - val_accuracy: 0.7705\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7692 - val_loss: 0.5334 - val_accuracy: 0.7757\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7671 - val_loss: 0.4721 - val_accuracy: 0.7549\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7683 - val_loss: 0.4706 - val_accuracy: 0.7881\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7696 - val_loss: 0.4993 - val_accuracy: 0.7451\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7711 - val_loss: 0.4688 - val_accuracy: 0.7765\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7710 - val_loss: 0.4904 - val_accuracy: 0.7485\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.5382 - val_accuracy: 0.7224\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7679 - val_loss: 0.4730 - val_accuracy: 0.7750\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7716 - val_loss: 0.4935 - val_accuracy: 0.7410\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7695 - val_loss: 0.4994 - val_accuracy: 0.7851\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7717 - val_loss: 0.4684 - val_accuracy: 0.7780\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7714 - val_loss: 0.4728 - val_accuracy: 0.7567\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7744 - val_loss: 0.4950 - val_accuracy: 0.7425\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7706 - val_loss: 0.4658 - val_accuracy: 0.7840\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7711 - val_loss: 0.4939 - val_accuracy: 0.7373\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7706 - val_loss: 0.4647 - val_accuracy: 0.7787\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7700 - val_loss: 0.4823 - val_accuracy: 0.7578\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7740 - val_loss: 0.5100 - val_accuracy: 0.7813\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7667 - val_loss: 0.4689 - val_accuracy: 0.7705\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7725 - val_loss: 0.4960 - val_accuracy: 0.7388\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7713 - val_loss: 0.5213 - val_accuracy: 0.7332\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7705 - val_loss: 0.4679 - val_accuracy: 0.7728\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7713 - val_loss: 0.5258 - val_accuracy: 0.7388\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.5192 - val_accuracy: 0.7769\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7689 - val_loss: 0.5344 - val_accuracy: 0.7246\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7657 - val_loss: 0.4962 - val_accuracy: 0.7795\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7675 - val_loss: 0.5108 - val_accuracy: 0.7720\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7717 - val_loss: 0.4976 - val_accuracy: 0.7519\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7717 - val_loss: 0.4764 - val_accuracy: 0.7586\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7702 - val_loss: 0.4771 - val_accuracy: 0.7840\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7675 - val_loss: 0.4658 - val_accuracy: 0.7720\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7700 - val_loss: 0.5790 - val_accuracy: 0.7713\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7720 - val_loss: 0.4740 - val_accuracy: 0.7765\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7707 - val_loss: 0.4836 - val_accuracy: 0.7515\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7724 - val_loss: 0.4724 - val_accuracy: 0.7683\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7689 - val_loss: 0.4883 - val_accuracy: 0.7888\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7666 - val_loss: 0.4699 - val_accuracy: 0.7597\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7706 - val_loss: 0.4696 - val_accuracy: 0.7787\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7712 - val_loss: 0.4763 - val_accuracy: 0.7634\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7712 - val_loss: 0.5264 - val_accuracy: 0.7325\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7699 - val_loss: 0.4759 - val_accuracy: 0.7698\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7712 - val_loss: 0.4709 - val_accuracy: 0.7724\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7698 - val_loss: 0.4675 - val_accuracy: 0.7754\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7690 - val_loss: 0.4814 - val_accuracy: 0.7608\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7718 - val_loss: 0.4665 - val_accuracy: 0.7735\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7712 - val_loss: 0.4884 - val_accuracy: 0.7817\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7729 - val_loss: 0.4881 - val_accuracy: 0.7795\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7713 - val_loss: 0.5630 - val_accuracy: 0.7687\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7691 - val_loss: 0.4806 - val_accuracy: 0.7746\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7708 - val_loss: 0.4694 - val_accuracy: 0.7772\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7716 - val_loss: 0.4738 - val_accuracy: 0.7552\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7668 - val_loss: 0.4732 - val_accuracy: 0.7590\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7717 - val_loss: 0.4793 - val_accuracy: 0.7478\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7726 - val_loss: 0.4671 - val_accuracy: 0.7780\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7703 - val_loss: 0.4978 - val_accuracy: 0.7410\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7694 - val_loss: 0.4978 - val_accuracy: 0.7806\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7702 - val_loss: 0.4863 - val_accuracy: 0.7791\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.4717 - val_accuracy: 0.7646\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7700 - val_loss: 0.4664 - val_accuracy: 0.7787\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7757\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7708 - val_loss: 0.4744 - val_accuracy: 0.7664\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7684 - val_loss: 0.4680 - val_accuracy: 0.7660\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7686 - val_loss: 0.5405 - val_accuracy: 0.7216\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7684 - val_loss: 0.4750 - val_accuracy: 0.7907\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7718 - val_loss: 0.5978 - val_accuracy: 0.7112\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7712 - val_loss: 0.5430 - val_accuracy: 0.7187\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7703 - val_loss: 0.4694 - val_accuracy: 0.7590\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7666 - val_loss: 0.4881 - val_accuracy: 0.7776\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7705 - val_loss: 0.4728 - val_accuracy: 0.7672\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7707 - val_loss: 0.5019 - val_accuracy: 0.7787\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7700 - val_loss: 0.4676 - val_accuracy: 0.7709\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7710 - val_loss: 0.5097 - val_accuracy: 0.7351\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7731 - val_loss: 0.4822 - val_accuracy: 0.7601\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7712 - val_loss: 0.4765 - val_accuracy: 0.7515\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7694 - val_loss: 0.5030 - val_accuracy: 0.7832\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7728 - val_loss: 0.5040 - val_accuracy: 0.7332\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7689 - val_loss: 0.5001 - val_accuracy: 0.7795\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7685 - val_loss: 0.4768 - val_accuracy: 0.7701\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7732 - val_loss: 0.4949 - val_accuracy: 0.7354\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7674 - val_loss: 0.4648 - val_accuracy: 0.7743\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7702 - val_loss: 0.4770 - val_accuracy: 0.7780\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7714 - val_loss: 0.4652 - val_accuracy: 0.7754\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7680 - val_loss: 0.5272 - val_accuracy: 0.7515\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7683 - val_loss: 0.4672 - val_accuracy: 0.7799\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7705 - val_loss: 0.5241 - val_accuracy: 0.7291\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7704 - val_loss: 0.5060 - val_accuracy: 0.7328\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7674 - val_loss: 0.4838 - val_accuracy: 0.7466\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7711 - val_loss: 0.4643 - val_accuracy: 0.7731\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7664 - val_loss: 0.4878 - val_accuracy: 0.7851\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7663 - val_loss: 0.4766 - val_accuracy: 0.7929\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7673 - val_loss: 0.4750 - val_accuracy: 0.7541\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7712 - val_loss: 0.4737 - val_accuracy: 0.7724\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7703 - val_loss: 0.4666 - val_accuracy: 0.7690\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7668 - val_loss: 0.4630 - val_accuracy: 0.7799\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7692 - val_loss: 0.4706 - val_accuracy: 0.7694\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7704 - val_loss: 0.5049 - val_accuracy: 0.7321\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7654 - val_loss: 0.5315 - val_accuracy: 0.7287\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7695 - val_loss: 0.5082 - val_accuracy: 0.7381\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7678 - val_loss: 0.4812 - val_accuracy: 0.7698\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7701 - val_loss: 0.4745 - val_accuracy: 0.7563\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7666 - val_loss: 0.4732 - val_accuracy: 0.7597\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.4654 - accuracy: 0.7698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████▌                                  | 6/10 [09:46<06:32, 98.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4654460549354553, 0.7698310613632202]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1187/40000 [00:00<00:03, 11865.12it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2418/40000 [00:00<00:03, 12121.74it/s]\u001b[A\n",
      "  9%|███████                                                                      | 3642/40000 [00:00<00:02, 12172.06it/s]\u001b[A\n",
      " 12%|█████████▍                                                                   | 4873/40000 [00:00<00:02, 12226.18it/s]\u001b[A\n",
      " 15%|███████████▊                                                                 | 6107/40000 [00:00<00:02, 12264.09it/s]\u001b[A\n",
      " 18%|██████████████                                                               | 7337/40000 [00:00<00:02, 12275.70it/s]\u001b[A\n",
      " 21%|████████████████▍                                                            | 8569/40000 [00:00<00:02, 12289.93it/s]\u001b[A\n",
      " 25%|██████████████████▊                                                          | 9802/40000 [00:00<00:02, 12300.98it/s]\u001b[A\n",
      " 28%|████████████████████▉                                                       | 11037/40000 [00:00<00:02, 12313.64it/s]\u001b[A\n",
      " 31%|███████████████████████▎                                                    | 12269/40000 [00:01<00:02, 12314.51it/s]\u001b[A\n",
      " 34%|█████████████████████████▋                                                  | 13503/40000 [00:01<00:02, 12320.50it/s]\u001b[A\n",
      " 37%|████████████████████████████                                                | 14738/40000 [00:01<00:02, 12328.22it/s]\u001b[A\n",
      " 40%|██████████████████████████████▎                                             | 15972/40000 [00:01<00:01, 12329.09it/s]\u001b[A\n",
      " 43%|████████████████████████████████▋                                           | 17205/40000 [00:01<00:01, 12326.89it/s]\u001b[A\n",
      " 46%|███████████████████████████████████                                         | 18443/40000 [00:01<00:01, 12340.31it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▍                                      | 19679/40000 [00:01<00:01, 12345.84it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▋                                    | 20916/40000 [00:01<00:01, 12351.17it/s]\u001b[A\n",
      " 55%|██████████████████████████████████████████                                  | 22152/40000 [00:01<00:01, 12346.18it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████▍                               | 23387/40000 [00:01<00:01, 12343.30it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▊                             | 24622/40000 [00:02<00:01, 12344.80it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▏                          | 25857/40000 [00:02<00:01, 12334.29it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▍                        | 27091/40000 [00:02<00:01, 12334.08it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▊                      | 28333/40000 [00:02<00:00, 12357.13it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▏                   | 29569/40000 [00:02<00:00, 12320.75it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▌                 | 30802/40000 [00:02<00:00, 12318.70it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▊               | 32036/40000 [00:02<00:00, 12323.65it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▏            | 33269/40000 [00:02<00:00, 12321.75it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████▌          | 34505/40000 [00:02<00:00, 12331.49it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████▉        | 35739/40000 [00:02<00:00, 12331.79it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████▏     | 36973/40000 [00:03<00:00, 12322.19it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▌   | 38206/40000 [00:03<00:00, 12322.87it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12307.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 7.3383 - accuracy: 0.2903 - val_loss: 1.7075 - val_accuracy: 0.5433\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9616 - accuracy: 0.6743 - val_loss: 0.6412 - val_accuracy: 0.7201\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7350 - val_loss: 0.5474 - val_accuracy: 0.7175\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7387 - val_loss: 0.5037 - val_accuracy: 0.7228\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7425 - val_loss: 0.5728 - val_accuracy: 0.7194\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7522 - val_loss: 0.4764 - val_accuracy: 0.7444\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7531 - val_loss: 0.4290 - val_accuracy: 0.7593\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7544 - val_loss: 0.4972 - val_accuracy: 0.7265\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7571 - val_loss: 0.4426 - val_accuracy: 0.7530\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7577 - val_loss: 0.4095 - val_accuracy: 0.7660\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7625 - val_loss: 0.4737 - val_accuracy: 0.7287\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7543 - val_loss: 0.4205 - val_accuracy: 0.7549\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.7622 - val_loss: 0.4172 - val_accuracy: 0.7463\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.7609 - val_loss: 0.4294 - val_accuracy: 0.7493\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7637 - val_loss: 0.4172 - val_accuracy: 0.7552\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.7620 - val_loss: 0.4669 - val_accuracy: 0.7507\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.7568 - val_loss: 0.4132 - val_accuracy: 0.7537\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.7627 - val_loss: 0.3980 - val_accuracy: 0.7586\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.7645 - val_loss: 0.3878 - val_accuracy: 0.7646\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.7649 - val_loss: 0.4122 - val_accuracy: 0.7425\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.7636 - val_loss: 0.3915 - val_accuracy: 0.7567\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.7601 - val_loss: 0.4007 - val_accuracy: 0.7440\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.7601 - val_loss: 0.3885 - val_accuracy: 0.7612\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.7657 - val_loss: 0.4001 - val_accuracy: 0.7537\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.7678 - val_loss: 0.3813 - val_accuracy: 0.7713\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.7657 - val_loss: 0.3853 - val_accuracy: 0.7679\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.7672 - val_loss: 0.3829 - val_accuracy: 0.7563\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.7613 - val_loss: 0.3952 - val_accuracy: 0.7590\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.7642 - val_loss: 0.3754 - val_accuracy: 0.7705\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.7615 - val_loss: 0.3778 - val_accuracy: 0.7716\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.7697 - val_loss: 0.3951 - val_accuracy: 0.7429\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.7615 - val_loss: 0.4083 - val_accuracy: 0.7545\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.7605 - val_loss: 0.3718 - val_accuracy: 0.7724\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.7630 - val_loss: 0.3779 - val_accuracy: 0.7709\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.7647 - val_loss: 0.4135 - val_accuracy: 0.7332\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.7652 - val_loss: 0.3884 - val_accuracy: 0.7597\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.7687 - val_loss: 0.3741 - val_accuracy: 0.7649\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.7647 - val_loss: 0.3843 - val_accuracy: 0.7675\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.7637 - val_loss: 0.4233 - val_accuracy: 0.7358\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.7609 - val_loss: 0.3910 - val_accuracy: 0.7489\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.7613 - val_loss: 0.3803 - val_accuracy: 0.7690\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.7687 - val_loss: 0.3946 - val_accuracy: 0.7582\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.7642 - val_loss: 0.3739 - val_accuracy: 0.7619\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.7651 - val_loss: 0.3758 - val_accuracy: 0.7582\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.7677 - val_loss: 0.3788 - val_accuracy: 0.7590\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.7661 - val_loss: 0.3737 - val_accuracy: 0.7776\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.7625 - val_loss: 0.3976 - val_accuracy: 0.7478\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.7638 - val_loss: 0.3839 - val_accuracy: 0.7537\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.7675 - val_loss: 0.3688 - val_accuracy: 0.7705\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.7632 - val_loss: 0.4052 - val_accuracy: 0.7410\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.7637 - val_loss: 0.3725 - val_accuracy: 0.7705\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.7610 - val_loss: 0.3728 - val_accuracy: 0.7683\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.7654 - val_loss: 0.3892 - val_accuracy: 0.7463\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.7667 - val_loss: 0.3705 - val_accuracy: 0.7739\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.7618 - val_loss: 0.3722 - val_accuracy: 0.7694\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.7645 - val_loss: 0.4102 - val_accuracy: 0.7351\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.7673 - val_loss: 0.3702 - val_accuracy: 0.7586\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.7608 - val_loss: 0.4087 - val_accuracy: 0.7552\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.7670 - val_loss: 0.3793 - val_accuracy: 0.7493\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.7636 - val_loss: 0.3737 - val_accuracy: 0.7537\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.7642 - val_loss: 0.3653 - val_accuracy: 0.7657\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.7624 - val_loss: 0.3773 - val_accuracy: 0.7575\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.7663 - val_loss: 0.3630 - val_accuracy: 0.7713\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.7654 - val_loss: 0.3683 - val_accuracy: 0.7713\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.7644 - val_loss: 0.3819 - val_accuracy: 0.7664\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.7623 - val_loss: 0.3686 - val_accuracy: 0.7634\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.7681 - val_loss: 0.3721 - val_accuracy: 0.7597\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.7642 - val_loss: 0.3617 - val_accuracy: 0.7590\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.7667 - val_loss: 0.3762 - val_accuracy: 0.7653\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.7661 - val_loss: 0.3812 - val_accuracy: 0.7653\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.7665 - val_loss: 0.3628 - val_accuracy: 0.7705\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.7687 - val_loss: 0.4014 - val_accuracy: 0.7396\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.7624 - val_loss: 0.4386 - val_accuracy: 0.7317\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.7646 - val_loss: 0.4149 - val_accuracy: 0.7545\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.7614 - val_loss: 0.3742 - val_accuracy: 0.7642\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.7605 - val_loss: 0.3642 - val_accuracy: 0.7746\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.7675 - val_loss: 0.3746 - val_accuracy: 0.7534\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.7651 - val_loss: 0.4454 - val_accuracy: 0.7317\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.7705 - val_loss: 0.3775 - val_accuracy: 0.7552\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.7638 - val_loss: 0.3659 - val_accuracy: 0.7597\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.7712 - val_loss: 0.3953 - val_accuracy: 0.7567\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.7666 - val_loss: 0.4204 - val_accuracy: 0.7537\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.7680 - val_loss: 0.3723 - val_accuracy: 0.7646\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.7613 - val_loss: 0.3643 - val_accuracy: 0.7701\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.7712 - val_loss: 0.3708 - val_accuracy: 0.7575\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.7605 - val_loss: 0.3729 - val_accuracy: 0.7646\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.7720 - val_loss: 0.4289 - val_accuracy: 0.7354\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.7634 - val_loss: 0.3657 - val_accuracy: 0.7616\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.7638 - val_loss: 0.3643 - val_accuracy: 0.7716\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.7707 - val_loss: 0.3749 - val_accuracy: 0.7549\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.7678 - val_loss: 0.3764 - val_accuracy: 0.7608\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.7656 - val_loss: 0.3745 - val_accuracy: 0.7660\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.7660 - val_loss: 0.3861 - val_accuracy: 0.7578\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.7673 - val_loss: 0.3632 - val_accuracy: 0.7679\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.7637 - val_loss: 0.3635 - val_accuracy: 0.7757\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.7623 - val_loss: 0.3663 - val_accuracy: 0.7724\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.7729 - val_loss: 0.3726 - val_accuracy: 0.7537\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.7692 - val_loss: 0.3590 - val_accuracy: 0.7709\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.7612 - val_loss: 0.4041 - val_accuracy: 0.7552\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.7680 - val_loss: 0.3865 - val_accuracy: 0.7455\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.7648 - val_loss: 0.4203 - val_accuracy: 0.7347\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.7736 - val_loss: 0.3651 - val_accuracy: 0.7739\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.7646 - val_loss: 0.3888 - val_accuracy: 0.7582\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.7660 - val_loss: 0.3939 - val_accuracy: 0.7493\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.7670 - val_loss: 0.3673 - val_accuracy: 0.7679\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.7672 - val_loss: 0.3601 - val_accuracy: 0.7713\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.7654 - val_loss: 0.3641 - val_accuracy: 0.7642\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.7623 - val_loss: 0.3649 - val_accuracy: 0.7705\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.7666 - val_loss: 0.3602 - val_accuracy: 0.7687\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.7680 - val_loss: 0.3608 - val_accuracy: 0.7787\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.7657 - val_loss: 0.3695 - val_accuracy: 0.7660\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.7724 - val_loss: 0.3643 - val_accuracy: 0.7679\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.7688 - val_loss: 0.3676 - val_accuracy: 0.7690\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.7632 - val_loss: 0.4180 - val_accuracy: 0.7396\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.7687 - val_loss: 0.3806 - val_accuracy: 0.7511\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.7665 - val_loss: 0.3947 - val_accuracy: 0.7466\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.7664 - val_loss: 0.3763 - val_accuracy: 0.7549\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.7705 - val_loss: 0.3919 - val_accuracy: 0.7586\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.7653 - val_loss: 0.3850 - val_accuracy: 0.7593\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.7702 - val_loss: 0.3626 - val_accuracy: 0.7660\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.7681 - val_loss: 0.3600 - val_accuracy: 0.7716\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.7661 - val_loss: 0.3898 - val_accuracy: 0.7429\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.7664 - val_loss: 0.4057 - val_accuracy: 0.7369\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.7664 - val_loss: 0.3780 - val_accuracy: 0.7590\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.7672 - val_loss: 0.4104 - val_accuracy: 0.7381\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.7651 - val_loss: 0.4191 - val_accuracy: 0.7396\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.7678 - val_loss: 0.3645 - val_accuracy: 0.7642\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.7687 - val_loss: 0.3622 - val_accuracy: 0.7731\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.7630 - val_loss: 0.3766 - val_accuracy: 0.7485\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.7707 - val_loss: 0.3602 - val_accuracy: 0.7705\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.7626 - val_loss: 0.3756 - val_accuracy: 0.7601\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.7670 - val_loss: 0.3832 - val_accuracy: 0.7556\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.7656 - val_loss: 0.3896 - val_accuracy: 0.7601\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.7656 - val_loss: 0.3729 - val_accuracy: 0.7552\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.7676 - val_loss: 0.3634 - val_accuracy: 0.7743\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.7685 - val_loss: 0.3850 - val_accuracy: 0.7485\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.7634 - val_loss: 0.3621 - val_accuracy: 0.7657\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.7696 - val_loss: 0.3876 - val_accuracy: 0.7537\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.7668 - val_loss: 0.3697 - val_accuracy: 0.7612\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.7709 - val_loss: 0.3617 - val_accuracy: 0.7724\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.7709 - val_loss: 0.3857 - val_accuracy: 0.7608\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.7678 - val_loss: 0.3587 - val_accuracy: 0.7679\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.7688 - val_loss: 0.3753 - val_accuracy: 0.7507\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.7661 - val_loss: 0.3804 - val_accuracy: 0.7440\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.7696 - val_loss: 0.3745 - val_accuracy: 0.7534\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.7689 - val_loss: 0.3662 - val_accuracy: 0.7634\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.7724 - val_loss: 0.3714 - val_accuracy: 0.7552\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.7668 - val_loss: 0.3769 - val_accuracy: 0.7608\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.7671 - val_loss: 0.4511 - val_accuracy: 0.7545\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.7668 - val_loss: 0.3606 - val_accuracy: 0.7649\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.3508 - accuracy: 0.7704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████▏                         | 7/10 [11:22<04:52, 97.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3507855236530304, 0.7703613638877869]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1189/40000 [00:00<00:03, 11886.13it/s]\u001b[A\n",
      "  6%|████▋                                                                        | 2429/40000 [00:00<00:03, 12187.50it/s]\u001b[A\n",
      "  9%|███████                                                                      | 3673/40000 [00:00<00:02, 12300.94it/s]\u001b[A\n",
      " 12%|█████████▍                                                                   | 4919/40000 [00:00<00:02, 12359.83it/s]\u001b[A\n",
      " 15%|███████████▊                                                                 | 6163/40000 [00:00<00:02, 12385.32it/s]\u001b[A\n",
      " 19%|██████████████▏                                                              | 7402/40000 [00:00<00:02, 12377.62it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8646/40000 [00:00<00:02, 12395.07it/s]\u001b[A\n",
      " 25%|███████████████████                                                          | 9889/40000 [00:00<00:02, 12404.73it/s]\u001b[A\n",
      " 28%|█████████████████████▏                                                      | 11135/40000 [00:00<00:02, 12421.53it/s]\u001b[A\n",
      " 31%|███████████████████████▌                                                    | 12385/40000 [00:01<00:02, 12445.19it/s]\u001b[A\n",
      " 34%|█████████████████████████▉                                                  | 13634/40000 [00:01<00:02, 12458.06it/s]\u001b[A\n",
      " 37%|████████████████████████████▎                                               | 14880/40000 [00:01<00:02, 12449.23it/s]\u001b[A\n",
      " 40%|██████████████████████████████▋                                             | 16125/40000 [00:01<00:01, 12444.28it/s]\u001b[A\n",
      " 43%|█████████████████████████████████                                           | 17371/40000 [00:01<00:01, 12447.05it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▎                                        | 18618/40000 [00:01<00:01, 12451.28it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▋                                      | 19864/40000 [00:01<00:01, 12191.54it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████                                    | 21108/40000 [00:01<00:01, 12262.62it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▍                                 | 22353/40000 [00:01<00:01, 12315.53it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▊                               | 23586/40000 [00:01<00:01, 12109.21it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▏                            | 24832/40000 [00:02<00:01, 12212.12it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▌                          | 26068/40000 [00:02<00:01, 12254.05it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▉                        | 27313/40000 [00:02<00:01, 12310.79it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████▎                     | 28558/40000 [00:02<00:00, 12351.31it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████▋                   | 29805/40000 [00:02<00:00, 12385.35it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████▉                 | 31044/40000 [00:02<00:00, 12097.05it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▎              | 32287/40000 [00:02<00:00, 12194.64it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▋            | 33531/40000 [00:02<00:00, 12264.81it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████          | 34775/40000 [00:02<00:00, 12316.45it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████▍       | 36020/40000 [00:02<00:00, 12355.42it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▊     | 37266/40000 [00:03<00:00, 12384.28it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▏  | 38509/40000 [00:03<00:00, 12396.11it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12308.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 5.5294 - accuracy: 0.4798 - val_loss: 1.6737 - val_accuracy: 0.6313\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.9859 - accuracy: 0.6596 - val_loss: 0.7864 - val_accuracy: 0.6347\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6877 - val_loss: 0.6231 - val_accuracy: 0.7597\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7082 - val_loss: 0.5763 - val_accuracy: 0.7664\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7095 - val_loss: 0.5639 - val_accuracy: 0.7519\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7209 - val_loss: 0.5675 - val_accuracy: 0.6970\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7163 - val_loss: 0.5557 - val_accuracy: 0.6996\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7142 - val_loss: 0.5414 - val_accuracy: 0.7299\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7165 - val_loss: 0.5596 - val_accuracy: 0.7429\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7238 - val_loss: 0.5517 - val_accuracy: 0.7418\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7198 - val_loss: 0.5433 - val_accuracy: 0.7007\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7213 - val_loss: 0.5655 - val_accuracy: 0.7011\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7252 - val_loss: 0.5389 - val_accuracy: 0.7093\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7183 - val_loss: 0.5689 - val_accuracy: 0.6787\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7210 - val_loss: 0.5588 - val_accuracy: 0.7004\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7217 - val_loss: 0.5331 - val_accuracy: 0.7168\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7257 - val_loss: 0.5331 - val_accuracy: 0.7369\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7232 - val_loss: 0.5472 - val_accuracy: 0.7138\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7258 - val_loss: 0.5434 - val_accuracy: 0.7590\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7264 - val_loss: 0.5451 - val_accuracy: 0.7030\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7226 - val_loss: 0.5524 - val_accuracy: 0.7362\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7236 - val_loss: 0.5749 - val_accuracy: 0.6881\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7242 - val_loss: 0.5374 - val_accuracy: 0.7119\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7233 - val_loss: 0.5576 - val_accuracy: 0.6978\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7254 - val_loss: 0.5281 - val_accuracy: 0.7422\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7261 - val_loss: 0.5339 - val_accuracy: 0.7187\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7277 - val_loss: 0.5395 - val_accuracy: 0.7160\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7239 - val_loss: 0.5514 - val_accuracy: 0.7090\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7282 - val_loss: 0.5245 - val_accuracy: 0.7172\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7270 - val_loss: 0.5294 - val_accuracy: 0.7112\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7260 - val_loss: 0.5227 - val_accuracy: 0.7284\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7230 - val_loss: 0.5399 - val_accuracy: 0.7060\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7257 - val_loss: 0.5309 - val_accuracy: 0.7216\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7263 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7234 - val_loss: 0.5287 - val_accuracy: 0.7243\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7267 - val_loss: 0.5256 - val_accuracy: 0.7213\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7295 - val_loss: 0.5277 - val_accuracy: 0.7306\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7275 - val_loss: 0.5486 - val_accuracy: 0.7052\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7281 - val_loss: 0.5288 - val_accuracy: 0.7235\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7313 - val_loss: 0.5620 - val_accuracy: 0.7396\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7240 - val_loss: 0.5363 - val_accuracy: 0.7067\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7294 - val_loss: 0.5388 - val_accuracy: 0.7112\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7284 - val_loss: 0.5224 - val_accuracy: 0.7239\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7297 - val_loss: 0.5292 - val_accuracy: 0.7131\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7314 - val_loss: 0.5247 - val_accuracy: 0.7493\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7271 - val_loss: 0.5413 - val_accuracy: 0.7134\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7283 - val_loss: 0.5452 - val_accuracy: 0.7440\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7294 - val_loss: 0.5229 - val_accuracy: 0.7213\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7279 - val_loss: 0.5228 - val_accuracy: 0.7261\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7327 - val_loss: 0.5217 - val_accuracy: 0.7205\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7265 - val_loss: 0.5319 - val_accuracy: 0.7060\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7271 - val_loss: 0.5228 - val_accuracy: 0.7131\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7312 - val_loss: 0.5140 - val_accuracy: 0.7239\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7263 - val_loss: 0.5482 - val_accuracy: 0.7489\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7312 - val_loss: 0.5184 - val_accuracy: 0.7179\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7280 - val_loss: 0.5278 - val_accuracy: 0.7101\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7300 - val_loss: 0.5155 - val_accuracy: 0.7366\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7264 - val_loss: 0.5225 - val_accuracy: 0.7399\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7282 - val_loss: 0.5127 - val_accuracy: 0.7310\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7285 - val_loss: 0.5340 - val_accuracy: 0.7123\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7286 - val_loss: 0.5306 - val_accuracy: 0.7575\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7305 - val_loss: 0.5261 - val_accuracy: 0.7116\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7322 - val_loss: 0.5185 - val_accuracy: 0.7119\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7297 - val_loss: 0.5424 - val_accuracy: 0.7019\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7307 - val_loss: 0.5235 - val_accuracy: 0.7321\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7280 - val_loss: 0.5209 - val_accuracy: 0.7243\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7296 - val_loss: 0.5139 - val_accuracy: 0.7246\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7301 - val_loss: 0.5171 - val_accuracy: 0.7325\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7280 - val_loss: 0.5249 - val_accuracy: 0.7164\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7290 - val_loss: 0.5131 - val_accuracy: 0.7257\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7280 - val_loss: 0.5089 - val_accuracy: 0.7265\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7283 - val_loss: 0.5142 - val_accuracy: 0.7299\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7250 - val_loss: 0.5087 - val_accuracy: 0.7246\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7322 - val_loss: 0.5197 - val_accuracy: 0.7302\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7284 - val_loss: 0.5120 - val_accuracy: 0.7175\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7301 - val_loss: 0.5142 - val_accuracy: 0.7205\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7294 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7321 - val_loss: 0.5156 - val_accuracy: 0.7250\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7255 - val_loss: 0.5148 - val_accuracy: 0.7493\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7329 - val_loss: 0.5211 - val_accuracy: 0.7231\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7297 - val_loss: 0.5179 - val_accuracy: 0.7183\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7326 - val_loss: 0.5109 - val_accuracy: 0.7205\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7296 - val_loss: 0.5098 - val_accuracy: 0.7287\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7265 - val_loss: 0.5114 - val_accuracy: 0.7280\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7326 - val_loss: 0.5422 - val_accuracy: 0.7489\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7294 - val_loss: 0.5275 - val_accuracy: 0.7549\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7281 - val_loss: 0.5250 - val_accuracy: 0.7194\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7328 - val_loss: 0.5406 - val_accuracy: 0.7422\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7305 - val_loss: 0.5600 - val_accuracy: 0.6959\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7271 - val_loss: 0.5337 - val_accuracy: 0.7563\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7308 - val_loss: 0.5162 - val_accuracy: 0.7261\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7290 - val_loss: 0.5119 - val_accuracy: 0.7291\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7308 - val_loss: 0.5346 - val_accuracy: 0.7101\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7326 - val_loss: 0.5174 - val_accuracy: 0.7433\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7306 - val_loss: 0.5156 - val_accuracy: 0.7313\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7309 - val_loss: 0.5208 - val_accuracy: 0.7183\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7302 - val_loss: 0.5182 - val_accuracy: 0.7287\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7292 - val_loss: 0.6058 - val_accuracy: 0.6694\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7270 - val_loss: 0.6548 - val_accuracy: 0.7153\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7233 - val_loss: 0.5874 - val_accuracy: 0.7097\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7330 - val_loss: 0.5144 - val_accuracy: 0.7343\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7289 - val_loss: 0.5106 - val_accuracy: 0.7194\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7325 - val_loss: 0.5127 - val_accuracy: 0.7332\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7289 - val_loss: 0.5057 - val_accuracy: 0.7336\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7317 - val_loss: 0.5172 - val_accuracy: 0.7463\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7308 - val_loss: 0.5061 - val_accuracy: 0.7250\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7301 - val_loss: 0.5082 - val_accuracy: 0.7310\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7311 - val_loss: 0.5064 - val_accuracy: 0.7224\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7291 - val_loss: 0.5217 - val_accuracy: 0.7209\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7300 - val_loss: 0.5128 - val_accuracy: 0.7381\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7277 - val_loss: 0.5086 - val_accuracy: 0.7261\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7295 - val_loss: 0.5072 - val_accuracy: 0.7306\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7297 - val_loss: 0.5562 - val_accuracy: 0.7067\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7301 - val_loss: 0.5583 - val_accuracy: 0.7384\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7302 - val_loss: 0.5810 - val_accuracy: 0.7377\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7290 - val_loss: 0.5071 - val_accuracy: 0.7246\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7281 - val_loss: 0.5386 - val_accuracy: 0.7541\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7293 - val_loss: 0.5052 - val_accuracy: 0.7276\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7300 - val_loss: 0.5303 - val_accuracy: 0.7496\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7319 - val_loss: 0.5156 - val_accuracy: 0.7377\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7322 - val_loss: 0.5048 - val_accuracy: 0.7250\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7280 - val_loss: 0.5176 - val_accuracy: 0.7220\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7275 - val_loss: 0.5078 - val_accuracy: 0.7235\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7321 - val_loss: 0.5093 - val_accuracy: 0.7313\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7325 - val_loss: 0.5257 - val_accuracy: 0.7097\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7308 - val_loss: 0.5288 - val_accuracy: 0.7112\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7296 - val_loss: 0.5225 - val_accuracy: 0.7549\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7286 - val_loss: 0.5262 - val_accuracy: 0.7179\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7322 - val_loss: 0.5079 - val_accuracy: 0.7310\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7306 - val_loss: 0.5097 - val_accuracy: 0.7313\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7301 - val_loss: 0.5457 - val_accuracy: 0.7022\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7317 - val_loss: 0.5420 - val_accuracy: 0.7063\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7287 - val_loss: 0.5056 - val_accuracy: 0.7265\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7294 - val_loss: 0.5297 - val_accuracy: 0.7090\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7321 - val_loss: 0.5117 - val_accuracy: 0.7358\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7326 - val_loss: 0.5038 - val_accuracy: 0.7250\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7314 - val_loss: 0.5302 - val_accuracy: 0.7142\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7312 - val_loss: 0.5150 - val_accuracy: 0.7216\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7305 - val_loss: 0.5085 - val_accuracy: 0.7235\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7319 - val_loss: 0.5323 - val_accuracy: 0.7101\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7283 - val_loss: 0.5314 - val_accuracy: 0.7090\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7302 - val_loss: 0.5178 - val_accuracy: 0.7201\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7268 - val_loss: 0.5442 - val_accuracy: 0.7131\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7254 - val_loss: 0.5357 - val_accuracy: 0.7507\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7308 - val_loss: 0.5122 - val_accuracy: 0.7179\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7292 - val_loss: 0.5078 - val_accuracy: 0.7299\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7304 - val_loss: 0.5094 - val_accuracy: 0.7302\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7310 - val_loss: 0.5180 - val_accuracy: 0.7537\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7297 - val_loss: 0.5251 - val_accuracy: 0.7489\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7318 - val_loss: 0.5403 - val_accuracy: 0.7037\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████▊                 | 8/10 [13:00<03:15, 97.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.516614556312561, 0.7120993733406067]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1250/40000 [00:00<00:03, 12492.15it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2500/40000 [00:00<00:03, 12392.57it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3740/40000 [00:00<00:02, 12349.24it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4975/40000 [00:00<00:02, 12325.28it/s]\u001b[A\n",
      " 16%|███████████▉                                                                 | 6208/40000 [00:00<00:02, 12303.96it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7439/40000 [00:00<00:02, 12304.93it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8670/40000 [00:00<00:02, 12304.27it/s]\u001b[A\n",
      " 25%|███████████████████                                                          | 9901/40000 [00:00<00:02, 12299.58it/s]\u001b[A\n",
      " 28%|█████████████████████▏                                                      | 11131/40000 [00:00<00:02, 12286.40it/s]\u001b[A\n",
      " 31%|███████████████████████▍                                                    | 12360/40000 [00:01<00:02, 12270.48it/s]\u001b[A\n",
      " 34%|█████████████████████████▊                                                  | 13588/40000 [00:01<00:02, 12268.39it/s]\u001b[A\n",
      " 37%|████████████████████████████▏                                               | 14815/40000 [00:01<00:02, 12268.09it/s]\u001b[A\n",
      " 40%|██████████████████████████████▍                                             | 16042/40000 [00:01<00:01, 12199.34it/s]\u001b[A\n",
      " 43%|████████████████████████████████▊                                           | 17266/40000 [00:01<00:01, 12208.95it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▏                                        | 18493/40000 [00:01<00:01, 12224.27it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▍                                      | 19718/40000 [00:01<00:01, 12229.51it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▊                                    | 20948/40000 [00:01<00:01, 12249.39it/s]\u001b[A\n",
      " 55%|██████████████████████████████████████████▏                                 | 22180/40000 [00:01<00:01, 12268.08it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▍                               | 23412/40000 [00:01<00:01, 12283.27it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▊                             | 24644/40000 [00:02<00:01, 12293.30it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▏                          | 25875/40000 [00:02<00:01, 12296.27it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▌                        | 27109/40000 [00:02<00:01, 12306.36it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▊                      | 28342/40000 [00:02<00:00, 12312.01it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▏                   | 29574/40000 [00:02<00:00, 12312.33it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▌                 | 30806/40000 [00:02<00:00, 12310.43it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▊               | 32038/40000 [00:02<00:00, 12295.39it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▏            | 33268/40000 [00:02<00:00, 12293.74it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████▌          | 34498/40000 [00:02<00:00, 12295.35it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████▉        | 35729/40000 [00:02<00:00, 12298.92it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████▏     | 36959/40000 [00:03<00:00, 12298.40it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████▌   | 38189/40000 [00:03<00:00, 12298.14it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12283.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 4.9267 - accuracy: 0.4301 - val_loss: 1.2216 - val_accuracy: 0.6384\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7937 - accuracy: 0.6797 - val_loss: 0.5902 - val_accuracy: 0.6929\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7038 - val_loss: 0.5488 - val_accuracy: 0.6948\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7159 - val_loss: 0.5372 - val_accuracy: 0.7037\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7139 - val_loss: 0.5582 - val_accuracy: 0.6937\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7156 - val_loss: 0.5866 - val_accuracy: 0.6966\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7207 - val_loss: 0.5123 - val_accuracy: 0.7138\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7238 - val_loss: 0.5066 - val_accuracy: 0.7112\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7232 - val_loss: 0.4986 - val_accuracy: 0.7250\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7201 - val_loss: 0.5014 - val_accuracy: 0.7131\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7317 - val_loss: 0.4802 - val_accuracy: 0.7291\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7317 - val_loss: 0.5445 - val_accuracy: 0.7280\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7287 - val_loss: 0.4726 - val_accuracy: 0.7433\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7284 - val_loss: 0.5075 - val_accuracy: 0.7127\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7303 - val_loss: 0.5053 - val_accuracy: 0.7108\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7345 - val_loss: 0.5244 - val_accuracy: 0.7123\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7348 - val_loss: 0.5578 - val_accuracy: 0.7104\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7335 - val_loss: 0.4822 - val_accuracy: 0.7172\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7369 - val_loss: 0.4503 - val_accuracy: 0.7474\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7363 - val_loss: 0.4416 - val_accuracy: 0.7302\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7340 - val_loss: 0.4533 - val_accuracy: 0.7351\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7367 - val_loss: 0.4451 - val_accuracy: 0.7463\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7396 - val_loss: 0.5025 - val_accuracy: 0.7086\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7364 - val_loss: 0.4547 - val_accuracy: 0.7399\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7365 - val_loss: 0.4427 - val_accuracy: 0.7302\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7388 - val_loss: 0.4420 - val_accuracy: 0.7410\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7447 - val_loss: 0.4316 - val_accuracy: 0.7396\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7401 - val_loss: 0.4406 - val_accuracy: 0.7470\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7406 - val_loss: 0.4424 - val_accuracy: 0.7384\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7435 - val_loss: 0.4277 - val_accuracy: 0.7373\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7379 - val_loss: 0.4337 - val_accuracy: 0.7433\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7444 - val_loss: 0.4634 - val_accuracy: 0.7198\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7467 - val_loss: 0.4356 - val_accuracy: 0.7399\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7424 - val_loss: 0.4458 - val_accuracy: 0.7437\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7402 - val_loss: 0.4257 - val_accuracy: 0.7504\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7460 - val_loss: 0.4244 - val_accuracy: 0.7366\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7457 - val_loss: 0.4317 - val_accuracy: 0.7343\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7416 - val_loss: 0.4669 - val_accuracy: 0.7183\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7432 - val_loss: 0.4290 - val_accuracy: 0.7399\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7476 - val_loss: 0.4433 - val_accuracy: 0.7243\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7412 - val_loss: 0.4328 - val_accuracy: 0.7280\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7427 - val_loss: 0.4527 - val_accuracy: 0.7407\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7409 - val_loss: 0.4253 - val_accuracy: 0.7373\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7452 - val_loss: 0.5232 - val_accuracy: 0.7407\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7420 - val_loss: 0.4257 - val_accuracy: 0.7496\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7465 - val_loss: 0.4381 - val_accuracy: 0.7437\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7456 - val_loss: 0.4207 - val_accuracy: 0.7347\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7452 - val_loss: 0.4179 - val_accuracy: 0.7448\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7438 - val_loss: 0.4595 - val_accuracy: 0.7201\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7471 - val_loss: 0.4446 - val_accuracy: 0.7209\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7460 - val_loss: 0.4227 - val_accuracy: 0.7295\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7439 - val_loss: 0.4131 - val_accuracy: 0.7534\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7444 - val_loss: 0.4146 - val_accuracy: 0.7526\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7437 - val_loss: 0.4171 - val_accuracy: 0.7466\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7468 - val_loss: 0.4321 - val_accuracy: 0.7299\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7393 - val_loss: 0.4383 - val_accuracy: 0.7291\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7469 - val_loss: 0.4286 - val_accuracy: 0.7332\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7472 - val_loss: 0.4182 - val_accuracy: 0.7440\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7466 - val_loss: 0.4182 - val_accuracy: 0.7433\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7479 - val_loss: 0.4303 - val_accuracy: 0.7388\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7448 - val_loss: 0.4143 - val_accuracy: 0.7478\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7428 - val_loss: 0.4196 - val_accuracy: 0.7407\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7437 - val_loss: 0.4281 - val_accuracy: 0.7466\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7487 - val_loss: 0.4202 - val_accuracy: 0.7489\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7456 - val_loss: 0.4129 - val_accuracy: 0.7522\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7419 - val_loss: 0.4242 - val_accuracy: 0.7347\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7417 - val_loss: 0.4102 - val_accuracy: 0.7466\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7463 - val_loss: 0.4118 - val_accuracy: 0.7354\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7482 - val_loss: 0.4164 - val_accuracy: 0.7470\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7436 - val_loss: 0.4269 - val_accuracy: 0.7437\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7492 - val_loss: 0.4211 - val_accuracy: 0.7414\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7474 - val_loss: 0.4193 - val_accuracy: 0.7392\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7462 - val_loss: 0.4139 - val_accuracy: 0.7478\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7420 - val_loss: 0.4076 - val_accuracy: 0.7384\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7470 - val_loss: 0.4546 - val_accuracy: 0.7228\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7461 - val_loss: 0.4452 - val_accuracy: 0.7295\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7492 - val_loss: 0.4425 - val_accuracy: 0.7440\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7394 - val_loss: 0.4118 - val_accuracy: 0.7422\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7480 - val_loss: 0.4074 - val_accuracy: 0.7504\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7452 - val_loss: 0.4107 - val_accuracy: 0.7478\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7467 - val_loss: 0.4123 - val_accuracy: 0.7511\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7455 - val_loss: 0.4283 - val_accuracy: 0.7321\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7457 - val_loss: 0.4254 - val_accuracy: 0.7496\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7440 - val_loss: 0.4295 - val_accuracy: 0.7410\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7469 - val_loss: 0.4569 - val_accuracy: 0.7194\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7416 - val_loss: 0.4612 - val_accuracy: 0.7228\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7452 - val_loss: 0.4085 - val_accuracy: 0.7459\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7459 - val_loss: 0.4077 - val_accuracy: 0.7567\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7500 - val_loss: 0.4144 - val_accuracy: 0.7500\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7530 - val_loss: 0.4105 - val_accuracy: 0.7504\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7477 - val_loss: 0.4126 - val_accuracy: 0.7563\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7445 - val_loss: 0.4131 - val_accuracy: 0.7552\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7481 - val_loss: 0.4051 - val_accuracy: 0.7485\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7482 - val_loss: 0.4458 - val_accuracy: 0.7448\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7404 - val_loss: 0.4172 - val_accuracy: 0.7466\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7449 - val_loss: 0.4961 - val_accuracy: 0.7190\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7446 - val_loss: 0.4138 - val_accuracy: 0.7481\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7466 - val_loss: 0.4096 - val_accuracy: 0.7369\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7459 - val_loss: 0.4080 - val_accuracy: 0.7396\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7448 - val_loss: 0.4067 - val_accuracy: 0.7444\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7481 - val_loss: 0.4210 - val_accuracy: 0.7407\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7445 - val_loss: 0.4463 - val_accuracy: 0.7455\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7428 - val_loss: 0.4165 - val_accuracy: 0.7425\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7430 - val_loss: 0.4228 - val_accuracy: 0.7358\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7433 - val_loss: 0.4408 - val_accuracy: 0.7463\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7423 - val_loss: 0.4058 - val_accuracy: 0.7563\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7450 - val_loss: 0.4105 - val_accuracy: 0.7466\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7484 - val_loss: 0.4043 - val_accuracy: 0.7448\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7463 - val_loss: 0.4731 - val_accuracy: 0.7440\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7470 - val_loss: 0.4629 - val_accuracy: 0.7220\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7462 - val_loss: 0.4586 - val_accuracy: 0.7429\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7400 - val_loss: 0.4073 - val_accuracy: 0.7455\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7447 - val_loss: 0.4160 - val_accuracy: 0.7530\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7456 - val_loss: 0.4434 - val_accuracy: 0.7433\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7432 - val_loss: 0.4089 - val_accuracy: 0.7474\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7464 - val_loss: 0.4133 - val_accuracy: 0.7455\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7479 - val_loss: 0.4037 - val_accuracy: 0.7549\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7450 - val_loss: 0.4139 - val_accuracy: 0.7496\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7467 - val_loss: 0.4077 - val_accuracy: 0.7414\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7476 - val_loss: 0.4087 - val_accuracy: 0.7500\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7490 - val_loss: 0.4020 - val_accuracy: 0.7511\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7519 - val_loss: 0.4181 - val_accuracy: 0.7440\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7473 - val_loss: 0.5215 - val_accuracy: 0.7429\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7459 - val_loss: 0.4295 - val_accuracy: 0.7343\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7457 - val_loss: 0.4020 - val_accuracy: 0.7485\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7467 - val_loss: 0.4219 - val_accuracy: 0.7478\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7486 - val_loss: 0.4024 - val_accuracy: 0.7597\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7463 - val_loss: 0.4054 - val_accuracy: 0.7407\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7466 - val_loss: 0.4061 - val_accuracy: 0.7381\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7478 - val_loss: 0.4044 - val_accuracy: 0.7463\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7505 - val_loss: 0.4061 - val_accuracy: 0.7403\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7472 - val_loss: 0.4049 - val_accuracy: 0.7388\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7420 - val_loss: 0.4032 - val_accuracy: 0.7575\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7457 - val_loss: 0.4287 - val_accuracy: 0.7463\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7490 - val_loss: 0.4230 - val_accuracy: 0.7451\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7473 - val_loss: 0.4116 - val_accuracy: 0.7444\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7452 - val_loss: 0.4185 - val_accuracy: 0.7425\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7485 - val_loss: 0.4036 - val_accuracy: 0.7519\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7428 - val_loss: 0.4227 - val_accuracy: 0.7474\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7478 - val_loss: 0.4038 - val_accuracy: 0.7381\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7459 - val_loss: 0.4123 - val_accuracy: 0.7455\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7434 - val_loss: 0.5460 - val_accuracy: 0.7190\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7462 - val_loss: 0.4028 - val_accuracy: 0.7418\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7469 - val_loss: 0.4050 - val_accuracy: 0.7362\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7460 - val_loss: 0.4076 - val_accuracy: 0.7451\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7467 - val_loss: 0.4213 - val_accuracy: 0.7351\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7451 - val_loss: 0.5245 - val_accuracy: 0.7425\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7448 - val_loss: 0.4591 - val_accuracy: 0.7444\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7439 - val_loss: 0.4083 - val_accuracy: 0.7433\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7489 - val_loss: 0.4057 - val_accuracy: 0.7604\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.4048 - accuracy: 0.7572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████▍        | 9/10 [14:38<01:37, 97.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4047967493534088, 0.757178544998169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▍                                                                          | 1253/40000 [00:00<00:03, 12523.06it/s]\u001b[A\n",
      "  6%|████▊                                                                        | 2506/40000 [00:00<00:03, 12395.53it/s]\u001b[A\n",
      "  9%|███████▏                                                                     | 3746/40000 [00:00<00:02, 12359.91it/s]\u001b[A\n",
      " 12%|█████████▌                                                                   | 4983/40000 [00:00<00:02, 12354.67it/s]\u001b[A\n",
      " 16%|███████████▉                                                                 | 6219/40000 [00:00<00:02, 12345.59it/s]\u001b[A\n",
      " 19%|██████████████▎                                                              | 7454/40000 [00:00<00:02, 12328.84it/s]\u001b[A\n",
      " 22%|████████████████▋                                                            | 8687/40000 [00:00<00:02, 12260.72it/s]\u001b[A\n",
      " 25%|███████████████████                                                          | 9914/40000 [00:00<00:02, 12258.92it/s]\u001b[A\n",
      " 28%|█████████████████████▏                                                      | 11145/40000 [00:00<00:02, 12272.07it/s]\u001b[A\n",
      " 31%|███████████████████████▌                                                    | 12374/40000 [00:01<00:02, 12275.97it/s]\u001b[A\n",
      " 34%|█████████████████████████▊                                                  | 13606/40000 [00:01<00:02, 12288.76it/s]\u001b[A\n",
      " 37%|████████████████████████████▏                                               | 14838/40000 [00:01<00:02, 12297.79it/s]\u001b[A\n",
      " 40%|██████████████████████████████▌                                             | 16068/40000 [00:01<00:01, 12294.07it/s]\u001b[A\n",
      " 43%|████████████████████████████████▉                                           | 17303/40000 [00:01<00:01, 12308.27it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▏                                        | 18535/40000 [00:01<00:01, 12310.66it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▌                                      | 19768/40000 [00:01<00:01, 12313.29it/s]\u001b[A\n",
      " 53%|███████████████████████████████████████▉                                    | 21003/40000 [00:01<00:01, 12323.12it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▎                                 | 22240/40000 [00:01<00:01, 12335.42it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▌                               | 23474/40000 [00:01<00:01, 12331.24it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▉                             | 24711/40000 [00:02<00:01, 12342.29it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▎                          | 25946/40000 [00:02<00:01, 12343.23it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▋                        | 27183/40000 [00:02<00:01, 12349.62it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▉                      | 28421/40000 [00:02<00:00, 12357.39it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████▎                   | 29658/40000 [00:02<00:00, 12360.38it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▋                 | 30895/40000 [00:02<00:00, 12358.43it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████               | 32131/40000 [00:02<00:00, 12351.18it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████▍            | 33367/40000 [00:02<00:00, 12350.98it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▋          | 34603/40000 [00:02<00:00, 12335.56it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████        | 35837/40000 [00:02<00:00, 12310.44it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████▍     | 37075/40000 [00:03<00:00, 12330.61it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████▊   | 38311/40000 [00:03<00:00, 12338.92it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 12324.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 11.3151 - accuracy: 0.2854 - val_loss: 3.4414 - val_accuracy: 0.5545\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 1.7154 - accuracy: 0.6386 - val_loss: 0.7906 - val_accuracy: 0.6731\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.6974 - val_loss: 0.6465 - val_accuracy: 0.7011\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.7216 - val_loss: 0.5525 - val_accuracy: 0.7414\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7298 - val_loss: 0.5208 - val_accuracy: 0.7526\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7461 - val_loss: 0.4969 - val_accuracy: 0.7545\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7496 - val_loss: 0.4754 - val_accuracy: 0.7899\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7493 - val_loss: 0.4800 - val_accuracy: 0.7313\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7567 - val_loss: 0.4521 - val_accuracy: 0.7780\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7592 - val_loss: 0.5161 - val_accuracy: 0.7104\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7615 - val_loss: 0.4575 - val_accuracy: 0.7336\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7670 - val_loss: 0.4500 - val_accuracy: 0.7440\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7668 - val_loss: 0.4758 - val_accuracy: 0.7403\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7663 - val_loss: 0.4247 - val_accuracy: 0.8011\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7677 - val_loss: 0.5775 - val_accuracy: 0.7168\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7639 - val_loss: 0.4295 - val_accuracy: 0.7604\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7744 - val_loss: 0.4289 - val_accuracy: 0.7765\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7724 - val_loss: 0.4210 - val_accuracy: 0.7840\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7687 - val_loss: 0.4137 - val_accuracy: 0.8108\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7759 - val_loss: 0.4033 - val_accuracy: 0.8149\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7683 - val_loss: 0.4078 - val_accuracy: 0.7649\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7802 - val_loss: 0.4736 - val_accuracy: 0.7466\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7681 - val_loss: 0.4057 - val_accuracy: 0.7836\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7767 - val_loss: 0.4025 - val_accuracy: 0.7720\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7790 - val_loss: 0.4024 - val_accuracy: 0.7862\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7818 - val_loss: 0.4536 - val_accuracy: 0.7299\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7734 - val_loss: 0.4059 - val_accuracy: 0.8119\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7770 - val_loss: 0.4853 - val_accuracy: 0.7470\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7824 - val_loss: 0.4345 - val_accuracy: 0.7388\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7778 - val_loss: 0.3993 - val_accuracy: 0.8030\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7755 - val_loss: 0.3997 - val_accuracy: 0.8112\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.4008 - val_accuracy: 0.7586\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7767 - val_loss: 0.3939 - val_accuracy: 0.7951\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7837 - val_loss: 0.4156 - val_accuracy: 0.7481\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7813 - val_loss: 0.4212 - val_accuracy: 0.7474\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7790 - val_loss: 0.4048 - val_accuracy: 0.7672\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7783 - val_loss: 0.4174 - val_accuracy: 0.7787\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7780 - val_loss: 0.3890 - val_accuracy: 0.8093\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7860 - val_loss: 0.3898 - val_accuracy: 0.8201\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7785 - val_loss: 0.3979 - val_accuracy: 0.7716\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7757 - val_loss: 0.3945 - val_accuracy: 0.8034\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7809 - val_loss: 0.3851 - val_accuracy: 0.8138\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7826 - val_loss: 0.4422 - val_accuracy: 0.7340\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.7871 - val_loss: 0.4165 - val_accuracy: 0.7780\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7778 - val_loss: 0.3950 - val_accuracy: 0.7631\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7791 - val_loss: 0.3868 - val_accuracy: 0.8101\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7789 - val_loss: 0.4629 - val_accuracy: 0.7545\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7795 - val_loss: 0.4021 - val_accuracy: 0.8104\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.7833 - val_loss: 0.4257 - val_accuracy: 0.7444\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7802 - val_loss: 0.3830 - val_accuracy: 0.8011\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7754 - val_loss: 0.3872 - val_accuracy: 0.8246\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7832 - val_loss: 0.3902 - val_accuracy: 0.7660\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7819 - val_loss: 0.3829 - val_accuracy: 0.8041\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.7841 - val_loss: 0.4315 - val_accuracy: 0.7354\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7794 - val_loss: 0.3816 - val_accuracy: 0.8052\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.7838 - val_loss: 0.4038 - val_accuracy: 0.7604\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7840 - val_loss: 0.3819 - val_accuracy: 0.8071\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7763 - val_loss: 0.4709 - val_accuracy: 0.7299\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.7857 - val_loss: 0.3890 - val_accuracy: 0.7963\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.7865 - val_loss: 0.4619 - val_accuracy: 0.7332\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.7812 - val_loss: 0.3821 - val_accuracy: 0.8272\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.7853 - val_loss: 0.3911 - val_accuracy: 0.7937\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.7863 - val_loss: 0.3862 - val_accuracy: 0.8179\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7848 - val_loss: 0.3955 - val_accuracy: 0.8078\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.7821 - val_loss: 0.4079 - val_accuracy: 0.7493\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.7817 - val_loss: 0.3885 - val_accuracy: 0.7619\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.7861 - val_loss: 0.3854 - val_accuracy: 0.8004\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.7871 - val_loss: 0.3811 - val_accuracy: 0.7854\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.7831 - val_loss: 0.5265 - val_accuracy: 0.7511\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.7847 - val_loss: 0.3963 - val_accuracy: 0.8071\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.7868 - val_loss: 0.4186 - val_accuracy: 0.7989\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.7810 - val_loss: 0.3907 - val_accuracy: 0.8123\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.7826 - val_loss: 0.3858 - val_accuracy: 0.8097\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.7823 - val_loss: 0.3855 - val_accuracy: 0.8183\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.7796 - val_loss: 0.4093 - val_accuracy: 0.7448\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.7811 - val_loss: 0.3928 - val_accuracy: 0.8127\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.7794 - val_loss: 0.4276 - val_accuracy: 0.7422\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.7890 - val_loss: 0.3961 - val_accuracy: 0.8082\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.7802 - val_loss: 0.4234 - val_accuracy: 0.7836\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.7814 - val_loss: 0.4367 - val_accuracy: 0.7597\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.7869 - val_loss: 0.3763 - val_accuracy: 0.8160\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.7836 - val_loss: 0.4118 - val_accuracy: 0.7466\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.7811 - val_loss: 0.3878 - val_accuracy: 0.8179\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.7824 - val_loss: 0.3990 - val_accuracy: 0.8052\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.7846 - val_loss: 0.3799 - val_accuracy: 0.7989\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.7854 - val_loss: 0.4045 - val_accuracy: 0.8030\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.7867 - val_loss: 0.4039 - val_accuracy: 0.7526\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.7818 - val_loss: 0.3989 - val_accuracy: 0.7530\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7767 - val_loss: 0.3779 - val_accuracy: 0.8257\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.7875 - val_loss: 0.4180 - val_accuracy: 0.7448\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.7836 - val_loss: 0.3769 - val_accuracy: 0.7873\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.7839 - val_loss: 0.3804 - val_accuracy: 0.8086\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.7802 - val_loss: 0.3764 - val_accuracy: 0.8194\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.7841 - val_loss: 0.3748 - val_accuracy: 0.8160\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.7872 - val_loss: 0.4060 - val_accuracy: 0.7474\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.7876 - val_loss: 0.3787 - val_accuracy: 0.7929\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.7828 - val_loss: 0.3754 - val_accuracy: 0.8049\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7715 - val_loss: 0.4016 - val_accuracy: 0.7489\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.7843 - val_loss: 0.3850 - val_accuracy: 0.7657\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.7849 - val_loss: 0.4115 - val_accuracy: 0.7877\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.7848 - val_loss: 0.3861 - val_accuracy: 0.8063\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.7861 - val_loss: 0.3965 - val_accuracy: 0.7556\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.7873 - val_loss: 0.3742 - val_accuracy: 0.8007\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.7798 - val_loss: 0.4463 - val_accuracy: 0.7410\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.7822 - val_loss: 0.4358 - val_accuracy: 0.7354\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.7833 - val_loss: 0.3872 - val_accuracy: 0.7765\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.7832 - val_loss: 0.4024 - val_accuracy: 0.7459\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.7821 - val_loss: 0.3834 - val_accuracy: 0.8179\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7771 - val_loss: 0.3755 - val_accuracy: 0.8164\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.7849 - val_loss: 0.3853 - val_accuracy: 0.7791\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.7839 - val_loss: 0.3921 - val_accuracy: 0.7619\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.7870 - val_loss: 0.4259 - val_accuracy: 0.7407\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.7858 - val_loss: 0.3763 - val_accuracy: 0.7959\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.7860 - val_loss: 0.4427 - val_accuracy: 0.7377\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.7810 - val_loss: 0.4861 - val_accuracy: 0.7504\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.7830 - val_loss: 0.3798 - val_accuracy: 0.7750\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.7856 - val_loss: 0.3800 - val_accuracy: 0.8090\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.7858 - val_loss: 0.4124 - val_accuracy: 0.7451\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.7832 - val_loss: 0.3811 - val_accuracy: 0.8146\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.7855 - val_loss: 0.3864 - val_accuracy: 0.8213\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.7852 - val_loss: 0.3924 - val_accuracy: 0.7537\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.7846 - val_loss: 0.3799 - val_accuracy: 0.7791\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.7858 - val_loss: 0.3788 - val_accuracy: 0.7873\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.7840 - val_loss: 0.3963 - val_accuracy: 0.7601\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.7869 - val_loss: 0.3935 - val_accuracy: 0.8093\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.7884 - val_loss: 0.4018 - val_accuracy: 0.7567\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.7815 - val_loss: 0.4703 - val_accuracy: 0.7354\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.7842 - val_loss: 0.3792 - val_accuracy: 0.7996\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.7813 - val_loss: 0.4019 - val_accuracy: 0.7519\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.7829 - val_loss: 0.4299 - val_accuracy: 0.7586\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.7793 - val_loss: 0.3997 - val_accuracy: 0.8056\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.7836 - val_loss: 0.3782 - val_accuracy: 0.7918\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.7861 - val_loss: 0.3830 - val_accuracy: 0.8034\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7765 - val_loss: 0.3813 - val_accuracy: 0.7780\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.7853 - val_loss: 0.3772 - val_accuracy: 0.8146\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.7829 - val_loss: 0.3815 - val_accuracy: 0.7724\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.7831 - val_loss: 0.3832 - val_accuracy: 0.7743\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.7864 - val_loss: 0.3965 - val_accuracy: 0.8075\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.7860 - val_loss: 0.3786 - val_accuracy: 0.8239\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.7827 - val_loss: 0.4066 - val_accuracy: 0.7455\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7779 - val_loss: 0.3821 - val_accuracy: 0.8209\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.7853 - val_loss: 0.4364 - val_accuracy: 0.7381\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7790 - val_loss: 0.3752 - val_accuracy: 0.7937\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.7872 - val_loss: 0.3766 - val_accuracy: 0.7881\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.7858 - val_loss: 0.3861 - val_accuracy: 0.7619\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.7880 - val_loss: 0.3967 - val_accuracy: 0.8116\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.7846 - val_loss: 0.3732 - val_accuracy: 0.8067\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.7858 - val_loss: 0.4263 - val_accuracy: 0.7410\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.7856 - val_loss: 0.3951 - val_accuracy: 0.8101\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7762 - val_loss: 0.4062 - val_accuracy: 0.8134\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.4110 - accuracy: 0.8118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 10/10 [16:15<00:00, 97.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41098394989967346, 0.811803936958313]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "total_scores = []\n",
    "for i in tqdm(range(10)):\n",
    "    idealized_signals, labels = idealized(num = 10_000)\n",
    "    input_data = np.expand_dims(normalize_data(idealized_signals), axis = -1)\n",
    "    print(input_data[0,:,:].max(), input_data[0,:,:].min())\n",
    "    splits = input_data.shape[0]//1_000\n",
    "    X = []\n",
    "    print(input_data.shape)\n",
    "    for i in range(splits):\n",
    "        tensor = tf.convert_to_tensor(input_data[i*1_000:(i+1)*1_000, :,:,:], dtype=tf.float32)\n",
    "        X.append(autoencoder.encoder(tensor))\n",
    "    X = np.vstack(X)\n",
    "    print(X.shape)\n",
    "    X, labels = absolute_diff(X, labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "    linear = keras.Sequential(name=\"my_sequential\")\n",
    "    linear.add(layers.Dense(4, activation=\"sigmoid\", name=\"layer2\"))\n",
    "\n",
    "    linear.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate = 5e-3), metrics=['accuracy'])\n",
    "    linear.fit(X_train, y_train, epochs=150, batch_size=128, validation_split = 0.1, shuffle=True)\n",
    "    results = linear.evaluate(X_test, y_test)\n",
    "    print(results)\n",
    "    total_scores.append(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6bd8485-e07e-4a7e-adaf-6709461d3e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8126221597194672\n",
      "0.06369298150509034\n",
      "tensorflow      WARNING  Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).cluster_loss_tracker.total\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).cluster_loss_tracker.count\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.89\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.90\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.91\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.92\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.93\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.94\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.95\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.96\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.97\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.98\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.99\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.100\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.101\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.102\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.103\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.104\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.105\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.106\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.107\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.108\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.109\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.110\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.111\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.112\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.113\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.114\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.115\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.116\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.117\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.118\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.119\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.120\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.121\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.122\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.123\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.124\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(total_scores))\n",
    "print(np.std(total_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
