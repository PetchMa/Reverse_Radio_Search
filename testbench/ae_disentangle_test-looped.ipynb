{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baed00ee-9461-4560-8813-31a571c86877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 05:13:17.542574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import setigen as stg\n",
    "from blimpy import Waterfall\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from astropy import units as u\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import silhouette_score\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f020ec-5663-42ab-8527-2b5d37948ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e00c928-f039-4774-8477-10c9e940e2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def painting(data):\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    for c in range(num_classes):\n",
    "        drift = 2*random.random()*(-1)**random.randint(0,2)\n",
    "        snr = random.randint(100, 150)\n",
    "        width = random.randint(20, 50)\n",
    "        for s in range(num_samples_per_class):\n",
    "            index = random.randint(0, data.shape[0]-1)\n",
    "            window = data[index, :,:]\n",
    "            \n",
    "            start = random.randint(50, 180)\n",
    "            \n",
    "            frame = stg.Frame.from_data(df=2.7939677238464355*u.Hz,\n",
    "                                        dt=18.253611008*u.s,\n",
    "                                        fch1=1289*u.MHz,\n",
    "                                        ascending=True,\n",
    "                                        data=window)\n",
    "            frame.add_signal(stg.constant_path(\n",
    "                                        f_start=frame.get_frequency(index=start),\n",
    "                                       drift_rate=drift*u.Hz/u.s),\n",
    "                                      stg.constant_t_profile(level=frame.get_intensity(snr=snr)),\n",
    "                                      stg.gaussian_f_profile(width=width*u.Hz),\n",
    "                                      stg.constant_bp_profile(level=1))\n",
    "            all_data.append(frame.data)\n",
    "            labels.append(c)\n",
    "    all_data = np.array(all_data)\n",
    "    labels = np.vstack(labels)\n",
    "    return all_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e49e4f-15bd-4a32-a6d5-7a3274be3b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from AE import AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531b40be-4015-40db-926c-0e681083194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 05:13:19.498343: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 05:13:19.991713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13888 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16, 256, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 256, 3)        30        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 128, 3)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 128, 3)       12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 128, 64)       1792      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 64, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 8, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 8, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2097408   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " latent (Dense)              (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,229,428\n",
      "Trainable params: 2,228,270\n",
      "Non-trainable params: 1,158\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "time_samples = 16\n",
    "freq_sample =  256\n",
    "encoder_inputs = keras.Input(shape=(time_samples, freq_sample, 1))\n",
    "x = layers.Conv2D(3, 3, activation=\"relu\", strides=1, padding=\"same\")(encoder_inputs)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x_shape = x.shape\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "z = layers.Dense(latent_dim, name=\"latent\", activation=\"linear\")(x)\n",
    "encoder = keras.Model(encoder_inputs, z, name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7131cf6f-ba9a-43ea-8b45-d3f79bd5acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                704       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8192)              2105344   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 8192)             32768     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 8, 64)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 16, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 64)       36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 16, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 64, 64)       36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 16, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 16, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 32, 128, 64)      36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 128, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 16, 128, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 32, 256, 3)       1731      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 16, 256, 3)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 16, 256, 3)       12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 16, 256, 1)       28        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,306,987\n",
      "Trainable params: 2,289,573\n",
      "Non-trainable params: 17,414\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(x_shape[1]* x_shape[2]* x_shape[3], activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Reshape((x_shape[1], x_shape[2], x_shape[3]))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(3, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"linear\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58ade6b-b495-49c2-b248-63bfadd8ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = 8\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"kl_loss\"\n",
    "        )\n",
    "        self.kl_additional = tf.keras.losses.KLDivergence()\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "        ]\n",
    "    def gaussanity_loss(self, data, base):\n",
    "        return self.kl_additional(data, base)\n",
    "    \n",
    "    def train_step(self, data_in):\n",
    "        data = data_in\n",
    "        print(data.shape)\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            \n",
    "            \n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        \n",
    "        mse_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(mse_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "        }\n",
    "    def test_step(self, data_in):\n",
    "        data, _ = data_in\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss \n",
    "        \n",
    "        mse_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(mse_loss)\n",
    "        return {\n",
    "            \"test_loss\": self.total_loss_tracker.result(),\n",
    "            \"test_kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"test_reconstruction_loss\": self.reconstruction_loss_tracker.result()\n",
    "        }\n",
    "    def __call__ (self, inputs):\n",
    "        return self.decoder(self.encoder(inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0074643-eba7-4961-aa51-3916eb75c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f4ca53cb970>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = VAE(encoder, decoder)\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3))\n",
    "autoencoder.load_weights(\"../autoencoder/models/full-weights-\"+'07-02-2023-11-08-47')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df2f403c-1e31-45be-9f8b-44277bc1bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    epsilon = 1\n",
    "    min_val = data.min()\n",
    "    data = data - min_val + epsilon\n",
    "    new_data = np.log(data)\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    final_data = (data - min_val) / (max_val - min_val)\n",
    "    return final_data\n",
    "    \n",
    "def normalize_data(data):\n",
    "    for i in tqdm(range(data.shape[0])):\n",
    "        data[i,:,:] = normalize(data[i,:,:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "218b0964-8671-484c-b24f-e9081b651743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def idealized(num=10_000):\n",
    "    drift = 0\n",
    "    snr = 20\n",
    "    width = 10\n",
    "    start = 256//2\n",
    "    data = []\n",
    "    labels = []\n",
    "    for tag in range(4):\n",
    "        label_vec = np.zeros(4)\n",
    "        label_vec[tag] = 1\n",
    "        for i in range(num):\n",
    "            if tag == 0:\n",
    "                drift = (-1)**(random.randint(0,2)) * 2 *random.random()\n",
    "            elif tag == 1:\n",
    "                snr = 50*random.random() +20\n",
    "            elif tag == 2:\n",
    "                width = 50*random.random() +20\n",
    "            elif tag == 3:\n",
    "                start = random.randint(50, 180)\n",
    "\n",
    "            frame = stg.Frame(fchans=256*u.pixel,\n",
    "                              tchans=16*u.pixel,\n",
    "                              df=2.7939677238464355*u.Hz,\n",
    "                              dt=18.253611008*u.s,\n",
    "                              fch1=6095.214842353016*u.MHz)\n",
    "            noise = frame.add_noise(x_mean=1, noise_type='chi2')\n",
    "            frame.add_signal(stg.constant_path(\n",
    "                                        f_start=frame.get_frequency(index=start),\n",
    "                                       drift_rate=drift*u.Hz/u.s),\n",
    "                                      stg.constant_t_profile(level=frame.get_intensity(snr=snr)),\n",
    "                                      stg.gaussian_f_profile(width=width*u.Hz),\n",
    "                                      stg.constant_bp_profile(level=1))\n",
    "            data.append(frame.data)\n",
    "            labels.append(label_vec)\n",
    "    data = np.array(data)\n",
    "    labels = np.vstack(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9549969-98f3-4658-a0f7-ff09b604ff4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/10 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1191/40000 [00:00<00:03, 11906.32it/s]\u001b[A\n",
      "  6%|████▌                                                                        | 2382/40000 [00:00<00:03, 11805.19it/s]\u001b[A\n",
      "  9%|██████▊                                                                      | 3567/40000 [00:00<00:03, 11824.83it/s]\u001b[A\n",
      " 12%|█████████▏                                                                   | 4750/40000 [00:00<00:02, 11814.14it/s]\u001b[A\n",
      " 15%|███████████▍                                                                 | 5932/40000 [00:00<00:02, 11797.74it/s]\u001b[A\n",
      " 18%|█████████████▋                                                               | 7112/40000 [00:00<00:02, 11796.23it/s]\u001b[A\n",
      " 21%|███████████████▉                                                             | 8292/40000 [00:00<00:02, 11619.37it/s]\u001b[A\n",
      " 24%|██████████████████▏                                                          | 9471/40000 [00:00<00:02, 11670.48it/s]\u001b[A\n",
      " 27%|████████████████████▏                                                       | 10639/40000 [00:00<00:02, 11636.86it/s]\u001b[A\n",
      " 30%|██████████████████████▍                                                     | 11803/40000 [00:01<00:02, 11461.81it/s]\u001b[A\n",
      " 32%|████████████████████████▋                                                   | 12976/40000 [00:01<00:02, 11539.64it/s]\u001b[A\n",
      " 35%|██████████████████████████▉                                                 | 14150/40000 [00:01<00:02, 11599.72it/s]\u001b[A\n",
      " 38%|█████████████████████████████                                               | 15311/40000 [00:01<00:02, 11500.60it/s]\u001b[A\n",
      " 41%|███████████████████████████████▎                                            | 16490/40000 [00:01<00:02, 11586.85it/s]\u001b[A\n",
      " 44%|█████████████████████████████████▌                                          | 17671/40000 [00:01<00:01, 11651.23it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▊                                        | 18837/40000 [00:01<00:01, 11572.95it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████                                      | 20025/40000 [00:01<00:01, 11663.18it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▎                                   | 21192/40000 [00:01<00:01, 11296.28it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▌                                 | 22378/40000 [00:01<00:01, 11460.64it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▊                               | 23559/40000 [00:02<00:01, 11561.68it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████                             | 24745/40000 [00:02<00:01, 11647.58it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▎                          | 25929/40000 [00:02<00:01, 11704.22it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▌                        | 27113/40000 [00:02<00:01, 11741.75it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▋                      | 28288/40000 [00:02<00:00, 11739.37it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████▉                    | 29472/40000 [00:02<00:00, 11768.40it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▏                 | 30650/40000 [00:02<00:00, 11647.69it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▍               | 31837/40000 [00:02<00:00, 11713.03it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████▋             | 33026/40000 [00:02<00:00, 11764.06it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████           | 34215/40000 [00:02<00:00, 11799.74it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████▎        | 35396/40000 [00:03<00:00, 11750.06it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████▍      | 36572/40000 [00:03<00:00, 11579.54it/s]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████▋    | 37757/40000 [00:03<00:00, 11658.17it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 11665.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 14.1809 - accuracy: 0.3994 - val_loss: 7.9241 - val_accuracy: 0.5224\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 4.3001 - accuracy: 0.5888 - val_loss: 3.0050 - val_accuracy: 0.6377\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 2.5753 - accuracy: 0.6599 - val_loss: 2.2501 - val_accuracy: 0.6664\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 1.8281 - accuracy: 0.6793 - val_loss: 1.5073 - val_accuracy: 0.6847\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 1.1514 - accuracy: 0.7039 - val_loss: 0.9116 - val_accuracy: 0.7220\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.6988 - accuracy: 0.7589 - val_loss: 0.5736 - val_accuracy: 0.7944\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.4689 - accuracy: 0.8241 - val_loss: 0.4149 - val_accuracy: 0.8448\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.3616 - accuracy: 0.8659 - val_loss: 0.3346 - val_accuracy: 0.8735\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.3036 - accuracy: 0.8883 - val_loss: 0.2877 - val_accuracy: 0.8929\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.2671 - accuracy: 0.9019 - val_loss: 0.2563 - val_accuracy: 0.9015\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.2419 - accuracy: 0.9115 - val_loss: 0.2352 - val_accuracy: 0.9149\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.2231 - accuracy: 0.9189 - val_loss: 0.2187 - val_accuracy: 0.9209\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.2082 - accuracy: 0.9249 - val_loss: 0.2055 - val_accuracy: 0.9228\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1971 - accuracy: 0.9279 - val_loss: 0.1975 - val_accuracy: 0.9280\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1870 - accuracy: 0.9313 - val_loss: 0.1849 - val_accuracy: 0.9328\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1792 - accuracy: 0.9343 - val_loss: 0.1763 - val_accuracy: 0.9366\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1728 - accuracy: 0.9364 - val_loss: 0.1722 - val_accuracy: 0.9384\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1669 - accuracy: 0.9388 - val_loss: 0.1653 - val_accuracy: 0.9422\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1621 - accuracy: 0.9393 - val_loss: 0.1606 - val_accuracy: 0.9414\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1579 - accuracy: 0.9417 - val_loss: 0.1568 - val_accuracy: 0.9433\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1540 - accuracy: 0.9427 - val_loss: 0.1550 - val_accuracy: 0.9433\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1504 - accuracy: 0.9437 - val_loss: 0.1505 - val_accuracy: 0.9433\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1475 - accuracy: 0.9454 - val_loss: 0.1506 - val_accuracy: 0.9440\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1447 - accuracy: 0.9468 - val_loss: 0.1460 - val_accuracy: 0.9455\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1426 - accuracy: 0.9476 - val_loss: 0.1426 - val_accuracy: 0.9493\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1404 - accuracy: 0.9469 - val_loss: 0.1402 - val_accuracy: 0.9478\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1384 - accuracy: 0.9479 - val_loss: 0.1394 - val_accuracy: 0.9466\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1364 - accuracy: 0.9481 - val_loss: 0.1381 - val_accuracy: 0.9470\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1349 - accuracy: 0.9488 - val_loss: 0.1353 - val_accuracy: 0.9481\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1336 - accuracy: 0.9490 - val_loss: 0.1341 - val_accuracy: 0.9470\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1321 - accuracy: 0.9488 - val_loss: 0.1321 - val_accuracy: 0.9474\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1304 - accuracy: 0.9505 - val_loss: 0.1310 - val_accuracy: 0.9493\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1289 - accuracy: 0.9505 - val_loss: 0.1303 - val_accuracy: 0.9493\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1281 - accuracy: 0.9503 - val_loss: 0.1284 - val_accuracy: 0.9504\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1264 - accuracy: 0.9512 - val_loss: 0.1277 - val_accuracy: 0.9504\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1256 - accuracy: 0.9511 - val_loss: 0.1270 - val_accuracy: 0.9537\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1248 - accuracy: 0.9526 - val_loss: 0.1262 - val_accuracy: 0.9507\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1239 - accuracy: 0.9523 - val_loss: 0.1263 - val_accuracy: 0.9534\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1227 - accuracy: 0.9528 - val_loss: 0.1240 - val_accuracy: 0.9526\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1225 - accuracy: 0.9527 - val_loss: 0.1229 - val_accuracy: 0.9522\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1216 - accuracy: 0.9528 - val_loss: 0.1252 - val_accuracy: 0.9507\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1210 - accuracy: 0.9533 - val_loss: 0.1244 - val_accuracy: 0.9534\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1204 - accuracy: 0.9531 - val_loss: 0.1216 - val_accuracy: 0.9530\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1191 - accuracy: 0.9553 - val_loss: 0.1210 - val_accuracy: 0.9522\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9542 - val_loss: 0.1199 - val_accuracy: 0.9545\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1185 - accuracy: 0.9539 - val_loss: 0.1199 - val_accuracy: 0.9519\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1173 - accuracy: 0.9546 - val_loss: 0.1194 - val_accuracy: 0.9534\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1169 - accuracy: 0.9541 - val_loss: 0.1214 - val_accuracy: 0.9522\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1171 - accuracy: 0.9543 - val_loss: 0.1189 - val_accuracy: 0.9549\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1162 - accuracy: 0.9551 - val_loss: 0.1190 - val_accuracy: 0.9545\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1154 - accuracy: 0.9554 - val_loss: 0.1168 - val_accuracy: 0.9556\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1156 - accuracy: 0.9551 - val_loss: 0.1175 - val_accuracy: 0.9519\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1146 - accuracy: 0.9553 - val_loss: 0.1166 - val_accuracy: 0.9560\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1144 - accuracy: 0.9553 - val_loss: 0.1170 - val_accuracy: 0.9541\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1143 - accuracy: 0.9555 - val_loss: 0.1167 - val_accuracy: 0.9552\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1141 - accuracy: 0.9553 - val_loss: 0.1177 - val_accuracy: 0.9519\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1133 - accuracy: 0.9560 - val_loss: 0.1166 - val_accuracy: 0.9530\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1132 - accuracy: 0.9553 - val_loss: 0.1176 - val_accuracy: 0.9545\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1127 - accuracy: 0.9563 - val_loss: 0.1144 - val_accuracy: 0.9563\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1122 - accuracy: 0.9563 - val_loss: 0.1156 - val_accuracy: 0.9537\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1121 - accuracy: 0.9567 - val_loss: 0.1149 - val_accuracy: 0.9549\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1117 - accuracy: 0.9568 - val_loss: 0.1145 - val_accuracy: 0.9556\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1124 - accuracy: 0.9567 - val_loss: 0.1147 - val_accuracy: 0.9534\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1117 - accuracy: 0.9568 - val_loss: 0.1135 - val_accuracy: 0.9556\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1111 - accuracy: 0.9572 - val_loss: 0.1139 - val_accuracy: 0.9549\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1112 - accuracy: 0.9565 - val_loss: 0.1132 - val_accuracy: 0.9556\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1108 - accuracy: 0.9575 - val_loss: 0.1137 - val_accuracy: 0.9560\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1104 - accuracy: 0.9573 - val_loss: 0.1128 - val_accuracy: 0.9560\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1104 - accuracy: 0.9571 - val_loss: 0.1119 - val_accuracy: 0.9552\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9570 - val_loss: 0.1151 - val_accuracy: 0.9522\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1111 - accuracy: 0.9561 - val_loss: 0.1134 - val_accuracy: 0.9556\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1099 - accuracy: 0.9575 - val_loss: 0.1139 - val_accuracy: 0.9567\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1094 - accuracy: 0.9573 - val_loss: 0.1160 - val_accuracy: 0.9522\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1095 - accuracy: 0.9572 - val_loss: 0.1125 - val_accuracy: 0.9545\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1092 - accuracy: 0.9573 - val_loss: 0.1120 - val_accuracy: 0.9556\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1092 - accuracy: 0.9574 - val_loss: 0.1112 - val_accuracy: 0.9545\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.9577 - val_loss: 0.1115 - val_accuracy: 0.9545\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1084 - accuracy: 0.9576 - val_loss: 0.1114 - val_accuracy: 0.9567\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1085 - accuracy: 0.9572 - val_loss: 0.1105 - val_accuracy: 0.9567\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1085 - accuracy: 0.9581 - val_loss: 0.1100 - val_accuracy: 0.9552\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1084 - accuracy: 0.9574 - val_loss: 0.1103 - val_accuracy: 0.9560\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1081 - accuracy: 0.9575 - val_loss: 0.1112 - val_accuracy: 0.9571\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1080 - accuracy: 0.9580 - val_loss: 0.1115 - val_accuracy: 0.9541\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1081 - accuracy: 0.9580 - val_loss: 0.1097 - val_accuracy: 0.9567\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1082 - accuracy: 0.9578 - val_loss: 0.1100 - val_accuracy: 0.9556\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1078 - accuracy: 0.9578 - val_loss: 0.1099 - val_accuracy: 0.9560\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1070 - accuracy: 0.9580 - val_loss: 0.1108 - val_accuracy: 0.9571\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1076 - accuracy: 0.9582 - val_loss: 0.1094 - val_accuracy: 0.9556\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1069 - accuracy: 0.9580 - val_loss: 0.1102 - val_accuracy: 0.9549\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1072 - accuracy: 0.9583 - val_loss: 0.1109 - val_accuracy: 0.9552\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1068 - accuracy: 0.9578 - val_loss: 0.1091 - val_accuracy: 0.9556\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1073 - accuracy: 0.9581 - val_loss: 0.1090 - val_accuracy: 0.9567\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1067 - accuracy: 0.9586 - val_loss: 0.1113 - val_accuracy: 0.9541\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1064 - accuracy: 0.9588 - val_loss: 0.1104 - val_accuracy: 0.9541\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1070 - accuracy: 0.9580 - val_loss: 0.1088 - val_accuracy: 0.9567\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1066 - accuracy: 0.9581 - val_loss: 0.1087 - val_accuracy: 0.9567\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1064 - accuracy: 0.9594 - val_loss: 0.1088 - val_accuracy: 0.9549\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1066 - accuracy: 0.9576 - val_loss: 0.1095 - val_accuracy: 0.9556\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1065 - accuracy: 0.9588 - val_loss: 0.1086 - val_accuracy: 0.9582\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1062 - accuracy: 0.9590 - val_loss: 0.1084 - val_accuracy: 0.9560\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1056 - accuracy: 0.9587 - val_loss: 0.1083 - val_accuracy: 0.9563\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 0.1061 - accuracy: 0.9583 - val_loss: 0.1096 - val_accuracy: 0.9541\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1058 - accuracy: 0.9584 - val_loss: 0.1081 - val_accuracy: 0.9563\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1070 - accuracy: 0.9583 - val_loss: 0.1134 - val_accuracy: 0.9541\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1061 - accuracy: 0.9579 - val_loss: 0.1081 - val_accuracy: 0.9575\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1063 - accuracy: 0.9581 - val_loss: 0.1077 - val_accuracy: 0.9563\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1061 - accuracy: 0.9585 - val_loss: 0.1078 - val_accuracy: 0.9567\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1057 - accuracy: 0.9587 - val_loss: 0.1077 - val_accuracy: 0.9556\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1060 - accuracy: 0.9587 - val_loss: 0.1077 - val_accuracy: 0.9571\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1051 - accuracy: 0.9591 - val_loss: 0.1098 - val_accuracy: 0.9567\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1056 - accuracy: 0.9585 - val_loss: 0.1081 - val_accuracy: 0.9586\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1051 - accuracy: 0.9586 - val_loss: 0.1114 - val_accuracy: 0.9530\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1050 - accuracy: 0.9591 - val_loss: 0.1081 - val_accuracy: 0.9552\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1051 - accuracy: 0.9588 - val_loss: 0.1079 - val_accuracy: 0.9563\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1051 - accuracy: 0.9591 - val_loss: 0.1074 - val_accuracy: 0.9552\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1052 - accuracy: 0.9587 - val_loss: 0.1083 - val_accuracy: 0.9575\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1058 - accuracy: 0.9585 - val_loss: 0.1082 - val_accuracy: 0.9560\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1056 - accuracy: 0.9587 - val_loss: 0.1109 - val_accuracy: 0.9534\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1052 - accuracy: 0.9585 - val_loss: 0.1072 - val_accuracy: 0.9560\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1050 - accuracy: 0.9583 - val_loss: 0.1074 - val_accuracy: 0.9578\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1049 - accuracy: 0.9587 - val_loss: 0.1091 - val_accuracy: 0.9552\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1051 - accuracy: 0.9587 - val_loss: 0.1070 - val_accuracy: 0.9571\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1046 - accuracy: 0.9585 - val_loss: 0.1090 - val_accuracy: 0.9552\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9599 - val_loss: 0.1070 - val_accuracy: 0.9582\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1050 - accuracy: 0.9587 - val_loss: 0.1082 - val_accuracy: 0.9578\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1051 - accuracy: 0.9590 - val_loss: 0.1072 - val_accuracy: 0.9571\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1046 - accuracy: 0.9591 - val_loss: 0.1078 - val_accuracy: 0.9556\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1045 - accuracy: 0.9586 - val_loss: 0.1085 - val_accuracy: 0.9560\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1043 - accuracy: 0.9588 - val_loss: 0.1134 - val_accuracy: 0.9515\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1053 - accuracy: 0.9583 - val_loss: 0.1074 - val_accuracy: 0.9560\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1049 - accuracy: 0.9590 - val_loss: 0.1069 - val_accuracy: 0.9567\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1042 - accuracy: 0.9584 - val_loss: 0.1080 - val_accuracy: 0.9563\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1045 - accuracy: 0.9579 - val_loss: 0.1078 - val_accuracy: 0.9556\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1041 - accuracy: 0.9585 - val_loss: 0.1092 - val_accuracy: 0.9563\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1041 - accuracy: 0.9587 - val_loss: 0.1072 - val_accuracy: 0.9571\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1044 - accuracy: 0.9589 - val_loss: 0.1066 - val_accuracy: 0.9567\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1043 - accuracy: 0.9589 - val_loss: 0.1084 - val_accuracy: 0.9552\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1040 - accuracy: 0.9593 - val_loss: 0.1073 - val_accuracy: 0.9563\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1041 - accuracy: 0.9590 - val_loss: 0.1067 - val_accuracy: 0.9563\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1046 - accuracy: 0.9590 - val_loss: 0.1070 - val_accuracy: 0.9571\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1041 - accuracy: 0.9589 - val_loss: 0.1073 - val_accuracy: 0.9567\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 3s 17ms/step - loss: 0.1042 - accuracy: 0.9590 - val_loss: 0.1066 - val_accuracy: 0.9567\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1039 - accuracy: 0.9586 - val_loss: 0.1071 - val_accuracy: 0.9571\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1038 - accuracy: 0.9586 - val_loss: 0.1070 - val_accuracy: 0.9571\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1041 - accuracy: 0.9587 - val_loss: 0.1067 - val_accuracy: 0.9575\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1039 - accuracy: 0.9583 - val_loss: 0.1079 - val_accuracy: 0.9545\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1042 - accuracy: 0.9583 - val_loss: 0.1065 - val_accuracy: 0.9560\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1037 - accuracy: 0.9591 - val_loss: 0.1064 - val_accuracy: 0.9578\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1035 - accuracy: 0.9594 - val_loss: 0.1076 - val_accuracy: 0.9560\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1042 - accuracy: 0.9583 - val_loss: 0.1069 - val_accuracy: 0.9571\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 0.1065 - accuracy: 0.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                            | 1/10 [05:07<46:11, 307.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10648290812969208, 0.9571969509124756]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1184/40000 [00:00<00:03, 11832.96it/s]\u001b[A\n",
      "  6%|████▌                                                                        | 2368/40000 [00:00<00:03, 11762.67it/s]\u001b[A\n",
      "  9%|██████▊                                                                      | 3545/40000 [00:00<00:03, 11745.59it/s]\u001b[A\n",
      " 12%|█████████                                                                    | 4720/40000 [00:00<00:03, 11713.87it/s]\u001b[A\n",
      " 15%|███████████▎                                                                 | 5892/40000 [00:00<00:02, 11582.08it/s]\u001b[A\n",
      " 18%|█████████████▌                                                               | 7073/40000 [00:00<00:02, 11657.76it/s]\u001b[A\n",
      " 21%|███████████████▉                                                             | 8248/40000 [00:00<00:02, 11685.42it/s]\u001b[A\n",
      " 24%|██████████████████▏                                                          | 9417/40000 [00:00<00:02, 11539.32it/s]\u001b[A\n",
      " 26%|████████████████████▏                                                       | 10597/40000 [00:00<00:02, 11618.29it/s]\u001b[A\n",
      " 29%|██████████████████████▎                                                     | 11774/40000 [00:01<00:02, 11663.27it/s]\u001b[A\n",
      " 32%|████████████████████████▌                                                   | 12945/40000 [00:01<00:02, 11676.27it/s]\u001b[A\n",
      " 35%|██████████████████████████▊                                                 | 14122/40000 [00:01<00:02, 11703.78it/s]\u001b[A\n",
      " 38%|█████████████████████████████                                               | 15301/40000 [00:01<00:02, 11728.52it/s]\u001b[A\n",
      " 41%|███████████████████████████████▎                                            | 16480/40000 [00:01<00:02, 11744.79it/s]\u001b[A\n",
      " 44%|█████████████████████████████████▌                                          | 17655/40000 [00:01<00:01, 11595.65it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▊                                        | 18830/40000 [00:01<00:01, 11640.86it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████                                      | 20007/40000 [00:01<00:01, 11676.78it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▏                                   | 21175/40000 [00:01<00:01, 11674.79it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▍                                 | 22343/40000 [00:01<00:01, 11671.59it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▋                               | 23511/40000 [00:02<00:01, 11668.52it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▉                             | 24679/40000 [00:02<00:01, 11670.07it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████                           | 25847/40000 [00:02<00:01, 11667.24it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▎                        | 27017/40000 [00:02<00:01, 11676.17it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████▌                      | 28189/40000 [00:02<00:01, 11686.26it/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████▊                    | 29359/40000 [00:02<00:00, 11689.69it/s]\u001b[A\n",
      " 76%|██████████████████████████████████████████████████████████                  | 30532/40000 [00:02<00:00, 11700.68it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████▏               | 31707/40000 [00:02<00:00, 11713.55it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████▍             | 32881/40000 [00:02<00:00, 11719.30it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████▋           | 34053/40000 [00:02<00:00, 11713.73it/s]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████▉         | 35225/40000 [00:03<00:00, 11707.38it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████▏      | 36401/40000 [00:03<00:00, 11722.96it/s]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████▍    | 37575/40000 [00:03<00:00, 11726.37it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████████████████████████████████████▌  | 38748/40000 [00:03<00:00, 11721.59it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 11682.55it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 4.4670 - accuracy: 0.4300 - val_loss: 2.5851 - val_accuracy: 0.5836\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 2.0279 - accuracy: 0.6524 - val_loss: 1.5863 - val_accuracy: 0.6772\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 1.3203 - accuracy: 0.7117 - val_loss: 1.0480 - val_accuracy: 0.7347\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.9408 - accuracy: 0.7566 - val_loss: 0.7597 - val_accuracy: 0.7802\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.7047 - accuracy: 0.7911 - val_loss: 0.5706 - val_accuracy: 0.8022\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.5377 - accuracy: 0.8236 - val_loss: 0.4416 - val_accuracy: 0.8433\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.4245 - accuracy: 0.8555 - val_loss: 0.3572 - val_accuracy: 0.8832\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.3523 - accuracy: 0.8819 - val_loss: 0.3045 - val_accuracy: 0.9034\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.3057 - accuracy: 0.8969 - val_loss: 0.2699 - val_accuracy: 0.9071\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.2738 - accuracy: 0.9060 - val_loss: 0.2456 - val_accuracy: 0.9142\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.2515 - accuracy: 0.9102 - val_loss: 0.2285 - val_accuracy: 0.9194\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 4s 22ms/step - loss: 0.2364 - accuracy: 0.9139 - val_loss: 0.2160 - val_accuracy: 0.9246\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2260 - accuracy: 0.9173 - val_loss: 0.2088 - val_accuracy: 0.9250\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.2193 - accuracy: 0.9194 - val_loss: 0.2039 - val_accuracy: 0.9306\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.2136 - accuracy: 0.9224 - val_loss: 0.1995 - val_accuracy: 0.9299\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 3s 17ms/step - loss: 0.2092 - accuracy: 0.9245 - val_loss: 0.1977 - val_accuracy: 0.9265\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.2056 - accuracy: 0.9257 - val_loss: 0.1916 - val_accuracy: 0.9343\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2027 - accuracy: 0.9265 - val_loss: 0.1900 - val_accuracy: 0.9313\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1993 - accuracy: 0.9269 - val_loss: 0.1871 - val_accuracy: 0.9336\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1973 - accuracy: 0.9280 - val_loss: 0.1830 - val_accuracy: 0.9351\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1946 - accuracy: 0.9287 - val_loss: 0.1804 - val_accuracy: 0.9351\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1929 - accuracy: 0.9292 - val_loss: 0.1798 - val_accuracy: 0.9347\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1908 - accuracy: 0.9299 - val_loss: 0.1810 - val_accuracy: 0.9381\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1894 - accuracy: 0.9308 - val_loss: 0.1770 - val_accuracy: 0.9377\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1888 - accuracy: 0.9305 - val_loss: 0.1739 - val_accuracy: 0.9377\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1868 - accuracy: 0.9310 - val_loss: 0.1756 - val_accuracy: 0.9384\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1853 - accuracy: 0.9329 - val_loss: 0.1715 - val_accuracy: 0.9369\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1837 - accuracy: 0.9327 - val_loss: 0.1714 - val_accuracy: 0.9396\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1831 - accuracy: 0.9332 - val_loss: 0.1703 - val_accuracy: 0.9392\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1819 - accuracy: 0.9341 - val_loss: 0.1715 - val_accuracy: 0.9425\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1808 - accuracy: 0.9334 - val_loss: 0.1683 - val_accuracy: 0.9425\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1798 - accuracy: 0.9331 - val_loss: 0.1670 - val_accuracy: 0.9414\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1789 - accuracy: 0.9344 - val_loss: 0.1664 - val_accuracy: 0.9422\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1776 - accuracy: 0.9342 - val_loss: 0.1661 - val_accuracy: 0.9403\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1771 - accuracy: 0.9351 - val_loss: 0.1641 - val_accuracy: 0.9422\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1769 - accuracy: 0.9350 - val_loss: 0.1642 - val_accuracy: 0.9418\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9352 - val_loss: 0.1639 - val_accuracy: 0.9440\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1748 - accuracy: 0.9354 - val_loss: 0.1625 - val_accuracy: 0.9444\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1750 - accuracy: 0.9347 - val_loss: 0.1633 - val_accuracy: 0.9418\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1736 - accuracy: 0.9358 - val_loss: 0.1609 - val_accuracy: 0.9437\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1731 - accuracy: 0.9363 - val_loss: 0.1620 - val_accuracy: 0.9444\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1723 - accuracy: 0.9364 - val_loss: 0.1628 - val_accuracy: 0.9422\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1719 - accuracy: 0.9364 - val_loss: 0.1632 - val_accuracy: 0.9410\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1711 - accuracy: 0.9370 - val_loss: 0.1626 - val_accuracy: 0.9429\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1715 - accuracy: 0.9357 - val_loss: 0.1590 - val_accuracy: 0.9463\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1701 - accuracy: 0.9371 - val_loss: 0.1582 - val_accuracy: 0.9481\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1699 - accuracy: 0.9370 - val_loss: 0.1578 - val_accuracy: 0.9463\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1694 - accuracy: 0.9374 - val_loss: 0.1594 - val_accuracy: 0.9448\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1686 - accuracy: 0.9375 - val_loss: 0.1570 - val_accuracy: 0.9459\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1686 - accuracy: 0.9371 - val_loss: 0.1578 - val_accuracy: 0.9470\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1680 - accuracy: 0.9378 - val_loss: 0.1577 - val_accuracy: 0.9474\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1674 - accuracy: 0.9381 - val_loss: 0.1578 - val_accuracy: 0.9433\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1674 - accuracy: 0.9372 - val_loss: 0.1555 - val_accuracy: 0.9489\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1675 - accuracy: 0.9379 - val_loss: 0.1550 - val_accuracy: 0.9493\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1670 - accuracy: 0.9386 - val_loss: 0.1553 - val_accuracy: 0.9481\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1663 - accuracy: 0.9378 - val_loss: 0.1545 - val_accuracy: 0.9478\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1658 - accuracy: 0.9383 - val_loss: 0.1543 - val_accuracy: 0.9485\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1655 - accuracy: 0.9388 - val_loss: 0.1550 - val_accuracy: 0.9466\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1649 - accuracy: 0.9387 - val_loss: 0.1547 - val_accuracy: 0.9470\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1648 - accuracy: 0.9386 - val_loss: 0.1534 - val_accuracy: 0.9478\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1646 - accuracy: 0.9394 - val_loss: 0.1558 - val_accuracy: 0.9437\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1644 - accuracy: 0.9385 - val_loss: 0.1552 - val_accuracy: 0.9451\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1646 - accuracy: 0.9394 - val_loss: 0.1551 - val_accuracy: 0.9459\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1637 - accuracy: 0.9385 - val_loss: 0.1534 - val_accuracy: 0.9478\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1639 - accuracy: 0.9387 - val_loss: 0.1569 - val_accuracy: 0.9451\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1639 - accuracy: 0.9392 - val_loss: 0.1528 - val_accuracy: 0.9463\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1634 - accuracy: 0.9396 - val_loss: 0.1521 - val_accuracy: 0.9485\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1630 - accuracy: 0.9399 - val_loss: 0.1522 - val_accuracy: 0.9474\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1631 - accuracy: 0.9394 - val_loss: 0.1522 - val_accuracy: 0.9489\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1623 - accuracy: 0.9398 - val_loss: 0.1519 - val_accuracy: 0.9489\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1624 - accuracy: 0.9401 - val_loss: 0.1515 - val_accuracy: 0.9481\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1620 - accuracy: 0.9397 - val_loss: 0.1515 - val_accuracy: 0.9478\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1615 - accuracy: 0.9405 - val_loss: 0.1544 - val_accuracy: 0.9444\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1619 - accuracy: 0.9400 - val_loss: 0.1520 - val_accuracy: 0.9470\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1616 - accuracy: 0.9397 - val_loss: 0.1516 - val_accuracy: 0.9470\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1614 - accuracy: 0.9404 - val_loss: 0.1513 - val_accuracy: 0.9474\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1608 - accuracy: 0.9404 - val_loss: 0.1527 - val_accuracy: 0.9459\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1620 - accuracy: 0.9396 - val_loss: 0.1532 - val_accuracy: 0.9459\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1610 - accuracy: 0.9406 - val_loss: 0.1524 - val_accuracy: 0.9448\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1607 - accuracy: 0.9400 - val_loss: 0.1499 - val_accuracy: 0.9474\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1609 - accuracy: 0.9397 - val_loss: 0.1502 - val_accuracy: 0.9489\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1606 - accuracy: 0.9394 - val_loss: 0.1505 - val_accuracy: 0.9466\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1599 - accuracy: 0.9404 - val_loss: 0.1511 - val_accuracy: 0.9463\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1599 - accuracy: 0.9408 - val_loss: 0.1501 - val_accuracy: 0.9478\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1598 - accuracy: 0.9408 - val_loss: 0.1499 - val_accuracy: 0.9478\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1599 - accuracy: 0.9407 - val_loss: 0.1500 - val_accuracy: 0.9478\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1598 - accuracy: 0.9405 - val_loss: 0.1517 - val_accuracy: 0.9455\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1598 - accuracy: 0.9401 - val_loss: 0.1519 - val_accuracy: 0.9459\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1604 - accuracy: 0.9403 - val_loss: 0.1522 - val_accuracy: 0.9451\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1597 - accuracy: 0.9405 - val_loss: 0.1493 - val_accuracy: 0.9481\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1591 - accuracy: 0.9403 - val_loss: 0.1496 - val_accuracy: 0.9474\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1597 - accuracy: 0.9409 - val_loss: 0.1487 - val_accuracy: 0.9493\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1593 - accuracy: 0.9407 - val_loss: 0.1506 - val_accuracy: 0.9466\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1585 - accuracy: 0.9405 - val_loss: 0.1497 - val_accuracy: 0.9474\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1590 - accuracy: 0.9408 - val_loss: 0.1505 - val_accuracy: 0.9485\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1590 - accuracy: 0.9400 - val_loss: 0.1506 - val_accuracy: 0.9459\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1589 - accuracy: 0.9403 - val_loss: 0.1490 - val_accuracy: 0.9474\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1584 - accuracy: 0.9408 - val_loss: 0.1487 - val_accuracy: 0.9489\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1584 - accuracy: 0.9408 - val_loss: 0.1496 - val_accuracy: 0.9470\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1581 - accuracy: 0.9417 - val_loss: 0.1481 - val_accuracy: 0.9478\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1586 - accuracy: 0.9403 - val_loss: 0.1485 - val_accuracy: 0.9470\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1588 - accuracy: 0.9406 - val_loss: 0.1484 - val_accuracy: 0.9470\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1583 - accuracy: 0.9399 - val_loss: 0.1481 - val_accuracy: 0.9489\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1579 - accuracy: 0.9411 - val_loss: 0.1524 - val_accuracy: 0.9459\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1582 - accuracy: 0.9404 - val_loss: 0.1483 - val_accuracy: 0.9474\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1579 - accuracy: 0.9410 - val_loss: 0.1478 - val_accuracy: 0.9478\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1577 - accuracy: 0.9413 - val_loss: 0.1489 - val_accuracy: 0.9474\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1576 - accuracy: 0.9414 - val_loss: 0.1487 - val_accuracy: 0.9470\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1576 - accuracy: 0.9404 - val_loss: 0.1474 - val_accuracy: 0.9478\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1578 - accuracy: 0.9407 - val_loss: 0.1482 - val_accuracy: 0.9474\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1574 - accuracy: 0.9414 - val_loss: 0.1515 - val_accuracy: 0.9448\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1574 - accuracy: 0.9413 - val_loss: 0.1478 - val_accuracy: 0.9481\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1580 - accuracy: 0.9418 - val_loss: 0.1476 - val_accuracy: 0.9493\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1572 - accuracy: 0.9410 - val_loss: 0.1474 - val_accuracy: 0.9466\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1577 - accuracy: 0.9407 - val_loss: 0.1497 - val_accuracy: 0.9459\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1578 - accuracy: 0.9398 - val_loss: 0.1485 - val_accuracy: 0.9466\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1574 - accuracy: 0.9403 - val_loss: 0.1492 - val_accuracy: 0.9463\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1579 - accuracy: 0.9402 - val_loss: 0.1476 - val_accuracy: 0.9466\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1574 - accuracy: 0.9413 - val_loss: 0.1479 - val_accuracy: 0.9470\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1573 - accuracy: 0.9410 - val_loss: 0.1479 - val_accuracy: 0.9478\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1574 - accuracy: 0.9404 - val_loss: 0.1476 - val_accuracy: 0.9478\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1573 - accuracy: 0.9411 - val_loss: 0.1518 - val_accuracy: 0.9440\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1573 - accuracy: 0.9415 - val_loss: 0.1467 - val_accuracy: 0.9485\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1566 - accuracy: 0.9408 - val_loss: 0.1472 - val_accuracy: 0.9474\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1570 - accuracy: 0.9413 - val_loss: 0.1471 - val_accuracy: 0.9481\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1570 - accuracy: 0.9410 - val_loss: 0.1472 - val_accuracy: 0.9474\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1563 - accuracy: 0.9419 - val_loss: 0.1483 - val_accuracy: 0.9463\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1567 - accuracy: 0.9410 - val_loss: 0.1472 - val_accuracy: 0.9478\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1571 - accuracy: 0.9410 - val_loss: 0.1479 - val_accuracy: 0.9489\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1564 - accuracy: 0.9420 - val_loss: 0.1469 - val_accuracy: 0.9489\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1562 - accuracy: 0.9410 - val_loss: 0.1506 - val_accuracy: 0.9470\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1562 - accuracy: 0.9415 - val_loss: 0.1478 - val_accuracy: 0.9459\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1569 - accuracy: 0.9410 - val_loss: 0.1466 - val_accuracy: 0.9478\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1560 - accuracy: 0.9417 - val_loss: 0.1518 - val_accuracy: 0.9448\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1564 - accuracy: 0.9408 - val_loss: 0.1464 - val_accuracy: 0.9481\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1567 - accuracy: 0.9407 - val_loss: 0.1482 - val_accuracy: 0.9455\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1566 - accuracy: 0.9409 - val_loss: 0.1474 - val_accuracy: 0.9474\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1566 - accuracy: 0.9415 - val_loss: 0.1465 - val_accuracy: 0.9463\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1562 - accuracy: 0.9409 - val_loss: 0.1483 - val_accuracy: 0.9459\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1567 - accuracy: 0.9415 - val_loss: 0.1463 - val_accuracy: 0.9474\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 0.1562 - accuracy: 0.9409 - val_loss: 0.1476 - val_accuracy: 0.9496\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1562 - accuracy: 0.9412 - val_loss: 0.1467 - val_accuracy: 0.9466\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1563 - accuracy: 0.9405 - val_loss: 0.1478 - val_accuracy: 0.9455\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1561 - accuracy: 0.9417 - val_loss: 0.1507 - val_accuracy: 0.9433\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1566 - accuracy: 0.9405 - val_loss: 0.1461 - val_accuracy: 0.9485\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1559 - accuracy: 0.9415 - val_loss: 0.1463 - val_accuracy: 0.9489\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1555 - accuracy: 0.9416 - val_loss: 0.1472 - val_accuracy: 0.9504\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1559 - accuracy: 0.9410 - val_loss: 0.1473 - val_accuracy: 0.9478\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1560 - accuracy: 0.9417 - val_loss: 0.1474 - val_accuracy: 0.9466\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1564 - accuracy: 0.9414 - val_loss: 0.1460 - val_accuracy: 0.9493\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 0.1488 - accuracy: 0.9428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████                                                                    | 2/10 [10:30<42:11, 316.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14875975251197815, 0.9428030252456665]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1187/40000 [00:00<00:03, 11867.24it/s]\u001b[A\n",
      "  6%|████▌                                                                        | 2374/40000 [00:00<00:03, 11783.95it/s]\u001b[A\n",
      "  9%|██████▊                                                                      | 3557/40000 [00:00<00:03, 11802.01it/s]\u001b[A\n",
      " 12%|█████████                                                                    | 4738/40000 [00:00<00:02, 11802.63it/s]\u001b[A\n",
      " 15%|███████████▍                                                                 | 5919/40000 [00:00<00:02, 11804.34it/s]\u001b[A\n",
      " 18%|█████████████▋                                                               | 7101/40000 [00:00<00:02, 11806.56it/s]\u001b[A\n",
      " 21%|███████████████▉                                                             | 8283/40000 [00:00<00:02, 11808.80it/s]\u001b[A\n",
      " 24%|██████████████████▏                                                          | 9468/40000 [00:00<00:02, 11821.14it/s]\u001b[A\n",
      " 27%|████████████████████▏                                                       | 10651/40000 [00:00<00:02, 11812.63it/s]\u001b[A\n",
      " 30%|██████████████████████▍                                                     | 11833/40000 [00:01<00:02, 11810.63it/s]\u001b[A\n",
      " 33%|████████████████████████▋                                                   | 13020/40000 [00:01<00:02, 11826.45it/s]\u001b[A\n",
      " 36%|██████████████████████████▉                                                 | 14203/40000 [00:01<00:02, 11291.74it/s]\u001b[A\n",
      " 38%|█████████████████████████████▏                                              | 15383/40000 [00:01<00:02, 11440.21it/s]\u001b[A\n",
      " 41%|███████████████████████████████▍                                            | 16563/40000 [00:01<00:02, 11545.89it/s]\u001b[A\n",
      " 44%|█████████████████████████████████▋                                          | 17745/40000 [00:01<00:01, 11626.67it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▉                                        | 18921/40000 [00:01<00:01, 11664.78it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████▏                                     | 20103/40000 [00:01<00:01, 11708.19it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▍                                   | 21275/40000 [00:01<00:01, 11708.35it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▋                                 | 22447/40000 [00:01<00:01, 11701.80it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▊                               | 23618/40000 [00:02<00:01, 11684.49it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████                             | 24787/40000 [00:02<00:01, 11680.56it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▎                          | 25958/40000 [00:02<00:01, 11687.28it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▌                        | 27127/40000 [00:02<00:01, 11686.33it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▊                      | 28296/40000 [00:02<00:01, 11561.34it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████▉                    | 29467/40000 [00:02<00:00, 11604.33it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▏                 | 30639/40000 [00:02<00:00, 11636.21it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████▍               | 31811/40000 [00:02<00:00, 11660.11it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████▋             | 32985/40000 [00:02<00:00, 11683.77it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████▉           | 34160/40000 [00:02<00:00, 11700.93it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████▏        | 35339/40000 [00:03<00:00, 11725.85it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████▍      | 36519/40000 [00:03<00:00, 11746.68it/s]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████▌    | 37694/40000 [00:03<00:00, 11611.69it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 11684.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 7.4127 - accuracy: 0.3526 - val_loss: 3.6684 - val_accuracy: 0.5071\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 2.3755 - accuracy: 0.6118 - val_loss: 1.5668 - val_accuracy: 0.6933\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 1.1215 - accuracy: 0.7430 - val_loss: 0.8382 - val_accuracy: 0.7780\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 3s 18ms/step - loss: 0.6632 - accuracy: 0.8143 - val_loss: 0.5523 - val_accuracy: 0.8325\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.4669 - accuracy: 0.8490 - val_loss: 0.4232 - val_accuracy: 0.8515\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3795 - accuracy: 0.8686 - val_loss: 0.3686 - val_accuracy: 0.8705\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3390 - accuracy: 0.8807 - val_loss: 0.3385 - val_accuracy: 0.8795\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.3145 - accuracy: 0.8895 - val_loss: 0.3201 - val_accuracy: 0.8847\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2974 - accuracy: 0.8952 - val_loss: 0.3039 - val_accuracy: 0.8896\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.2833 - accuracy: 0.8989 - val_loss: 0.2953 - val_accuracy: 0.8910\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.2728 - accuracy: 0.9022 - val_loss: 0.2789 - val_accuracy: 0.8996\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.2631 - accuracy: 0.9047 - val_loss: 0.2708 - val_accuracy: 0.9034\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.2559 - accuracy: 0.9070 - val_loss: 0.2645 - val_accuracy: 0.9022\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.2484 - accuracy: 0.9074 - val_loss: 0.2540 - val_accuracy: 0.9052\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.2426 - accuracy: 0.9096 - val_loss: 0.2501 - val_accuracy: 0.9056\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.2369 - accuracy: 0.9106 - val_loss: 0.2446 - val_accuracy: 0.9090\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.2325 - accuracy: 0.9120 - val_loss: 0.2386 - val_accuracy: 0.9097\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2279 - accuracy: 0.9135 - val_loss: 0.2455 - val_accuracy: 0.9022\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.2248 - accuracy: 0.9146 - val_loss: 0.2279 - val_accuracy: 0.9134\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2216 - accuracy: 0.9145 - val_loss: 0.2254 - val_accuracy: 0.9138\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2187 - accuracy: 0.9164 - val_loss: 0.2291 - val_accuracy: 0.9101\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.2154 - accuracy: 0.9171 - val_loss: 0.2173 - val_accuracy: 0.9146\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.2130 - accuracy: 0.9173 - val_loss: 0.2217 - val_accuracy: 0.9134\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2107 - accuracy: 0.9188 - val_loss: 0.2148 - val_accuracy: 0.9160\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.2087 - accuracy: 0.9189 - val_loss: 0.2099 - val_accuracy: 0.9205\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2064 - accuracy: 0.9201 - val_loss: 0.2073 - val_accuracy: 0.9220\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 3s 17ms/step - loss: 0.2053 - accuracy: 0.9195 - val_loss: 0.2068 - val_accuracy: 0.9175\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2035 - accuracy: 0.9211 - val_loss: 0.2062 - val_accuracy: 0.9187\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.2015 - accuracy: 0.9212 - val_loss: 0.2030 - val_accuracy: 0.9228\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1992 - accuracy: 0.9216 - val_loss: 0.2019 - val_accuracy: 0.9179\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1978 - accuracy: 0.9229 - val_loss: 0.1997 - val_accuracy: 0.9187\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1965 - accuracy: 0.9223 - val_loss: 0.1964 - val_accuracy: 0.9220\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1953 - accuracy: 0.9224 - val_loss: 0.1947 - val_accuracy: 0.9257\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1940 - accuracy: 0.9242 - val_loss: 0.1931 - val_accuracy: 0.9250\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1924 - accuracy: 0.9233 - val_loss: 0.1960 - val_accuracy: 0.9239\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1918 - accuracy: 0.9239 - val_loss: 0.1914 - val_accuracy: 0.9243\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1905 - accuracy: 0.9248 - val_loss: 0.1895 - val_accuracy: 0.9224\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1900 - accuracy: 0.9248 - val_loss: 0.1954 - val_accuracy: 0.9183\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1885 - accuracy: 0.9250 - val_loss: 0.1911 - val_accuracy: 0.9213\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1872 - accuracy: 0.9252 - val_loss: 0.1862 - val_accuracy: 0.9254\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1869 - accuracy: 0.9260 - val_loss: 0.1864 - val_accuracy: 0.9235\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1859 - accuracy: 0.9260 - val_loss: 0.1847 - val_accuracy: 0.9257\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1847 - accuracy: 0.9257 - val_loss: 0.1846 - val_accuracy: 0.9254\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1851 - accuracy: 0.9264 - val_loss: 0.1822 - val_accuracy: 0.9276\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1830 - accuracy: 0.9268 - val_loss: 0.1821 - val_accuracy: 0.9265\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1833 - accuracy: 0.9267 - val_loss: 0.1809 - val_accuracy: 0.9276\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1820 - accuracy: 0.9277 - val_loss: 0.1803 - val_accuracy: 0.9276\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1811 - accuracy: 0.9276 - val_loss: 0.1855 - val_accuracy: 0.9250\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1809 - accuracy: 0.9276 - val_loss: 0.1775 - val_accuracy: 0.9291\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1800 - accuracy: 0.9277 - val_loss: 0.1783 - val_accuracy: 0.9291\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1797 - accuracy: 0.9273 - val_loss: 0.1851 - val_accuracy: 0.9224\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1792 - accuracy: 0.9284 - val_loss: 0.1798 - val_accuracy: 0.9265\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1787 - accuracy: 0.9273 - val_loss: 0.1818 - val_accuracy: 0.9265\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1780 - accuracy: 0.9280 - val_loss: 0.1753 - val_accuracy: 0.9295\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1774 - accuracy: 0.9292 - val_loss: 0.1791 - val_accuracy: 0.9265\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1767 - accuracy: 0.9301 - val_loss: 0.1739 - val_accuracy: 0.9306\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1766 - accuracy: 0.9294 - val_loss: 0.1730 - val_accuracy: 0.9291\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1763 - accuracy: 0.9302 - val_loss: 0.1769 - val_accuracy: 0.9299\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1756 - accuracy: 0.9301 - val_loss: 0.1728 - val_accuracy: 0.9313\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1750 - accuracy: 0.9295 - val_loss: 0.1747 - val_accuracy: 0.9287\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1748 - accuracy: 0.9289 - val_loss: 0.1736 - val_accuracy: 0.9310\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1747 - accuracy: 0.9291 - val_loss: 0.1733 - val_accuracy: 0.9306\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1744 - accuracy: 0.9302 - val_loss: 0.1722 - val_accuracy: 0.9287\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1741 - accuracy: 0.9299 - val_loss: 0.1743 - val_accuracy: 0.9284\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1739 - accuracy: 0.9299 - val_loss: 0.1705 - val_accuracy: 0.9321\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1735 - accuracy: 0.9301 - val_loss: 0.1734 - val_accuracy: 0.9272\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1732 - accuracy: 0.9303 - val_loss: 0.1722 - val_accuracy: 0.9313\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1728 - accuracy: 0.9299 - val_loss: 0.1687 - val_accuracy: 0.9321\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1726 - accuracy: 0.9305 - val_loss: 0.1711 - val_accuracy: 0.9306\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1718 - accuracy: 0.9313 - val_loss: 0.1705 - val_accuracy: 0.9325\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1715 - accuracy: 0.9318 - val_loss: 0.1703 - val_accuracy: 0.9325\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1712 - accuracy: 0.9314 - val_loss: 0.1675 - val_accuracy: 0.9340\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1712 - accuracy: 0.9312 - val_loss: 0.1703 - val_accuracy: 0.9336\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1709 - accuracy: 0.9320 - val_loss: 0.1678 - val_accuracy: 0.9321\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1705 - accuracy: 0.9314 - val_loss: 0.1676 - val_accuracy: 0.9328\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1709 - accuracy: 0.9304 - val_loss: 0.1675 - val_accuracy: 0.9332\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1705 - accuracy: 0.9318 - val_loss: 0.1723 - val_accuracy: 0.9302\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1705 - accuracy: 0.9314 - val_loss: 0.1669 - val_accuracy: 0.9332\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1697 - accuracy: 0.9316 - val_loss: 0.1676 - val_accuracy: 0.9295\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1701 - accuracy: 0.9313 - val_loss: 0.1658 - val_accuracy: 0.9347\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1694 - accuracy: 0.9314 - val_loss: 0.1665 - val_accuracy: 0.9295\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1695 - accuracy: 0.9312 - val_loss: 0.1671 - val_accuracy: 0.9343\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1696 - accuracy: 0.9308 - val_loss: 0.1661 - val_accuracy: 0.9325\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1691 - accuracy: 0.9319 - val_loss: 0.1652 - val_accuracy: 0.9306\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1692 - accuracy: 0.9321 - val_loss: 0.1663 - val_accuracy: 0.9340\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1693 - accuracy: 0.9309 - val_loss: 0.1645 - val_accuracy: 0.9347\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1688 - accuracy: 0.9320 - val_loss: 0.1656 - val_accuracy: 0.9328\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1691 - accuracy: 0.9318 - val_loss: 0.1778 - val_accuracy: 0.9257\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1683 - accuracy: 0.9320 - val_loss: 0.1645 - val_accuracy: 0.9377\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1683 - accuracy: 0.9328 - val_loss: 0.1638 - val_accuracy: 0.9340\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1678 - accuracy: 0.9325 - val_loss: 0.1690 - val_accuracy: 0.9332\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1675 - accuracy: 0.9320 - val_loss: 0.1633 - val_accuracy: 0.9358\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9329 - val_loss: 0.1648 - val_accuracy: 0.9343\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1672 - accuracy: 0.9334 - val_loss: 0.1667 - val_accuracy: 0.9362\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1675 - accuracy: 0.9323 - val_loss: 0.1637 - val_accuracy: 0.9340\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1667 - accuracy: 0.9336 - val_loss: 0.1658 - val_accuracy: 0.9328\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1670 - accuracy: 0.9322 - val_loss: 0.1644 - val_accuracy: 0.9362\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1664 - accuracy: 0.9325 - val_loss: 0.1624 - val_accuracy: 0.9377\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1671 - accuracy: 0.9334 - val_loss: 0.1637 - val_accuracy: 0.9340\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1667 - accuracy: 0.9330 - val_loss: 0.1639 - val_accuracy: 0.9351\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1666 - accuracy: 0.9335 - val_loss: 0.1645 - val_accuracy: 0.9340\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.9323 - val_loss: 0.1636 - val_accuracy: 0.9351\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1659 - accuracy: 0.9328 - val_loss: 0.1652 - val_accuracy: 0.9336\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1663 - accuracy: 0.9322 - val_loss: 0.1625 - val_accuracy: 0.9388\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1660 - accuracy: 0.9330 - val_loss: 0.1633 - val_accuracy: 0.9328\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1655 - accuracy: 0.9326 - val_loss: 0.1640 - val_accuracy: 0.9358\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1661 - accuracy: 0.9329 - val_loss: 0.1663 - val_accuracy: 0.9336\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1657 - accuracy: 0.9335 - val_loss: 0.1633 - val_accuracy: 0.9366\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1654 - accuracy: 0.9335 - val_loss: 0.1625 - val_accuracy: 0.9354\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1658 - accuracy: 0.9340 - val_loss: 0.1638 - val_accuracy: 0.9340\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1654 - accuracy: 0.9334 - val_loss: 0.1675 - val_accuracy: 0.9328\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1655 - accuracy: 0.9332 - val_loss: 0.1679 - val_accuracy: 0.9328\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1654 - accuracy: 0.9338 - val_loss: 0.1618 - val_accuracy: 0.9347\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1648 - accuracy: 0.9339 - val_loss: 0.1628 - val_accuracy: 0.9366\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.9333 - val_loss: 0.1624 - val_accuracy: 0.9351\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1649 - accuracy: 0.9339 - val_loss: 0.1606 - val_accuracy: 0.9392\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1650 - accuracy: 0.9336 - val_loss: 0.1616 - val_accuracy: 0.9362\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1647 - accuracy: 0.9343 - val_loss: 0.1602 - val_accuracy: 0.9384\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1650 - accuracy: 0.9322 - val_loss: 0.1625 - val_accuracy: 0.9354\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9336 - val_loss: 0.1606 - val_accuracy: 0.9373\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1646 - accuracy: 0.9329 - val_loss: 0.1602 - val_accuracy: 0.9366\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1642 - accuracy: 0.9346 - val_loss: 0.1604 - val_accuracy: 0.9388\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1654 - accuracy: 0.9325 - val_loss: 0.1603 - val_accuracy: 0.9369\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1649 - accuracy: 0.9335 - val_loss: 0.1613 - val_accuracy: 0.9381\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1644 - accuracy: 0.9335 - val_loss: 0.1643 - val_accuracy: 0.9366\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1649 - accuracy: 0.9336 - val_loss: 0.1605 - val_accuracy: 0.9377\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1637 - accuracy: 0.9338 - val_loss: 0.1606 - val_accuracy: 0.9362\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1641 - accuracy: 0.9343 - val_loss: 0.1627 - val_accuracy: 0.9343\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1643 - accuracy: 0.9337 - val_loss: 0.1664 - val_accuracy: 0.9332\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1640 - accuracy: 0.9342 - val_loss: 0.1624 - val_accuracy: 0.9369\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1643 - accuracy: 0.9337 - val_loss: 0.1594 - val_accuracy: 0.9388\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1639 - accuracy: 0.9345 - val_loss: 0.1594 - val_accuracy: 0.9381\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1638 - accuracy: 0.9332 - val_loss: 0.1594 - val_accuracy: 0.9384\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1641 - accuracy: 0.9339 - val_loss: 0.1616 - val_accuracy: 0.9381\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1636 - accuracy: 0.9336 - val_loss: 0.1627 - val_accuracy: 0.9336\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1636 - accuracy: 0.9340 - val_loss: 0.1598 - val_accuracy: 0.9377\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1638 - accuracy: 0.9335 - val_loss: 0.1602 - val_accuracy: 0.9384\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1636 - accuracy: 0.9344 - val_loss: 0.1598 - val_accuracy: 0.9392\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1636 - accuracy: 0.9343 - val_loss: 0.1607 - val_accuracy: 0.9366\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9344 - val_loss: 0.1607 - val_accuracy: 0.9369\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1635 - accuracy: 0.9340 - val_loss: 0.1614 - val_accuracy: 0.9366\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1629 - accuracy: 0.9345 - val_loss: 0.1608 - val_accuracy: 0.9351\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1631 - accuracy: 0.9336 - val_loss: 0.1603 - val_accuracy: 0.9354\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1631 - accuracy: 0.9336 - val_loss: 0.1616 - val_accuracy: 0.9343\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1637 - accuracy: 0.9344 - val_loss: 0.1602 - val_accuracy: 0.9396\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1630 - accuracy: 0.9342 - val_loss: 0.1605 - val_accuracy: 0.9384\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1632 - accuracy: 0.9343 - val_loss: 0.1598 - val_accuracy: 0.9369\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1629 - accuracy: 0.9349 - val_loss: 0.1594 - val_accuracy: 0.9362\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1629 - accuracy: 0.9345 - val_loss: 0.1589 - val_accuracy: 0.9388\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1630 - accuracy: 0.9344 - val_loss: 0.1583 - val_accuracy: 0.9384\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 0.1707 - accuracy: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▌                                                           | 3/10 [15:40<36:35, 313.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1707329899072647, 0.9321969747543335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1191/40000 [00:00<00:03, 11907.46it/s]\u001b[A\n",
      "  6%|████▌                                                                        | 2382/40000 [00:00<00:03, 11810.27it/s]\u001b[A\n",
      "  9%|██████▊                                                                      | 3564/40000 [00:00<00:03, 11811.05it/s]\u001b[A\n",
      " 12%|█████████▏                                                                   | 4746/40000 [00:00<00:02, 11776.71it/s]\u001b[A\n",
      " 15%|███████████▍                                                                 | 5930/40000 [00:00<00:02, 11796.34it/s]\u001b[A\n",
      " 18%|█████████████▋                                                               | 7111/40000 [00:00<00:02, 11798.09it/s]\u001b[A\n",
      " 21%|███████████████▉                                                             | 8291/40000 [00:00<00:02, 11795.19it/s]\u001b[A\n",
      " 24%|██████████████████▏                                                          | 9476/40000 [00:00<00:02, 11809.87it/s]\u001b[A\n",
      " 27%|████████████████████▏                                                       | 10657/40000 [00:00<00:02, 11804.20it/s]\u001b[A\n",
      " 30%|██████████████████████▍                                                     | 11838/40000 [00:01<00:02, 11801.46it/s]\u001b[A\n",
      " 33%|████████████████████████▋                                                   | 13019/40000 [00:01<00:02, 11430.33it/s]\u001b[A\n",
      " 35%|██████████████████████████▉                                                 | 14165/40000 [00:01<00:02, 11366.57it/s]\u001b[A\n",
      " 38%|█████████████████████████████                                               | 15325/40000 [00:01<00:02, 11428.62it/s]\u001b[A\n",
      " 41%|███████████████████████████████▎                                            | 16487/40000 [00:01<00:02, 11482.95it/s]\u001b[A\n",
      " 44%|█████████████████████████████████▌                                          | 17648/40000 [00:01<00:01, 11519.84it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▋                                        | 18801/40000 [00:01<00:01, 11381.97it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▉                                      | 19982/40000 [00:01<00:01, 11507.95it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▏                                   | 21162/40000 [00:01<00:01, 11594.01it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▍                                 | 22345/40000 [00:01<00:01, 11663.50it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▋                               | 23523/40000 [00:02<00:01, 11697.01it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▉                             | 24704/40000 [00:02<00:01, 11729.19it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▏                          | 25885/40000 [00:02<00:01, 11751.74it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▍                        | 27066/40000 [00:02<00:01, 11768.10it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▋                      | 28248/40000 [00:02<00:00, 11781.83it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████▉                    | 29429/40000 [00:02<00:00, 11788.20it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▏                 | 30613/40000 [00:02<00:00, 11800.78it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████▍               | 31795/40000 [00:02<00:00, 11804.07it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████▋             | 32976/40000 [00:02<00:00, 11797.08it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████▉           | 34156/40000 [00:02<00:00, 11795.62it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████▏        | 35336/40000 [00:03<00:00, 11793.66it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████▍      | 36520/40000 [00:03<00:00, 11805.25it/s]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████▋    | 37702/40000 [00:03<00:00, 11809.13it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 11708.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 10.4890 - accuracy: 0.2290 - val_loss: 6.3417 - val_accuracy: 0.3093\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 3.4109 - accuracy: 0.3774 - val_loss: 1.6906 - val_accuracy: 0.4970\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 1.2718 - accuracy: 0.6029 - val_loss: 1.0805 - val_accuracy: 0.6873\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.8944 - accuracy: 0.7217 - val_loss: 0.7973 - val_accuracy: 0.7507\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.6906 - accuracy: 0.7738 - val_loss: 0.6286 - val_accuracy: 0.7866\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.5610 - accuracy: 0.8056 - val_loss: 0.5144 - val_accuracy: 0.8142\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.4740 - accuracy: 0.8265 - val_loss: 0.4409 - val_accuracy: 0.8340\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.4154 - accuracy: 0.8431 - val_loss: 0.3928 - val_accuracy: 0.8567\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.3770 - accuracy: 0.8561 - val_loss: 0.3612 - val_accuracy: 0.8623\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.3496 - accuracy: 0.8669 - val_loss: 0.3401 - val_accuracy: 0.8660\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.3290 - accuracy: 0.8728 - val_loss: 0.3210 - val_accuracy: 0.8728\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.3130 - accuracy: 0.8783 - val_loss: 0.3053 - val_accuracy: 0.8776\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2986 - accuracy: 0.8828 - val_loss: 0.2951 - val_accuracy: 0.8832\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.2871 - accuracy: 0.8866 - val_loss: 0.2828 - val_accuracy: 0.8847\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.2770 - accuracy: 0.8897 - val_loss: 0.2763 - val_accuracy: 0.8907\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.2688 - accuracy: 0.8921 - val_loss: 0.2665 - val_accuracy: 0.8925\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2603 - accuracy: 0.8944 - val_loss: 0.2581 - val_accuracy: 0.8989\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.2539 - accuracy: 0.8977 - val_loss: 0.2570 - val_accuracy: 0.8933\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.2470 - accuracy: 0.8991 - val_loss: 0.2456 - val_accuracy: 0.9007\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.2414 - accuracy: 0.9016 - val_loss: 0.2409 - val_accuracy: 0.9022\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.2369 - accuracy: 0.9027 - val_loss: 0.2386 - val_accuracy: 0.9019\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2322 - accuracy: 0.9039 - val_loss: 0.2318 - val_accuracy: 0.9022\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.2279 - accuracy: 0.9051 - val_loss: 0.2307 - val_accuracy: 0.9060\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.2244 - accuracy: 0.9062 - val_loss: 0.2261 - val_accuracy: 0.9052\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.2210 - accuracy: 0.9081 - val_loss: 0.2217 - val_accuracy: 0.9082\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.2175 - accuracy: 0.9093 - val_loss: 0.2196 - val_accuracy: 0.9101\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.2152 - accuracy: 0.9111 - val_loss: 0.2165 - val_accuracy: 0.9097\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.2124 - accuracy: 0.9115 - val_loss: 0.2137 - val_accuracy: 0.9127\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.2099 - accuracy: 0.9131 - val_loss: 0.2109 - val_accuracy: 0.9112\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.2082 - accuracy: 0.9127 - val_loss: 0.2134 - val_accuracy: 0.9160\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.2068 - accuracy: 0.9130 - val_loss: 0.2093 - val_accuracy: 0.9157\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.2053 - accuracy: 0.9143 - val_loss: 0.2060 - val_accuracy: 0.9127\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.2032 - accuracy: 0.9163 - val_loss: 0.2047 - val_accuracy: 0.9157\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.2022 - accuracy: 0.9147 - val_loss: 0.2064 - val_accuracy: 0.9119\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.2007 - accuracy: 0.9164 - val_loss: 0.2034 - val_accuracy: 0.9149\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.2004 - accuracy: 0.9165 - val_loss: 0.2031 - val_accuracy: 0.9142\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1985 - accuracy: 0.9165 - val_loss: 0.1996 - val_accuracy: 0.9153\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1979 - accuracy: 0.9177 - val_loss: 0.2000 - val_accuracy: 0.9138\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1967 - accuracy: 0.9172 - val_loss: 0.1983 - val_accuracy: 0.9175\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1965 - accuracy: 0.9186 - val_loss: 0.1967 - val_accuracy: 0.9168\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1950 - accuracy: 0.9180 - val_loss: 0.1962 - val_accuracy: 0.9194\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1951 - accuracy: 0.9184 - val_loss: 0.1974 - val_accuracy: 0.9142\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1941 - accuracy: 0.9182 - val_loss: 0.1952 - val_accuracy: 0.9183\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1950 - accuracy: 0.9169 - val_loss: 0.1945 - val_accuracy: 0.9179\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1928 - accuracy: 0.9195 - val_loss: 0.1955 - val_accuracy: 0.9198\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1930 - accuracy: 0.9193 - val_loss: 0.1931 - val_accuracy: 0.9194\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1921 - accuracy: 0.9192 - val_loss: 0.1943 - val_accuracy: 0.9179\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1916 - accuracy: 0.9201 - val_loss: 0.1925 - val_accuracy: 0.9198\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1912 - accuracy: 0.9200 - val_loss: 0.1923 - val_accuracy: 0.9175\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1907 - accuracy: 0.9199 - val_loss: 0.1915 - val_accuracy: 0.9187\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1902 - accuracy: 0.9197 - val_loss: 0.1917 - val_accuracy: 0.9250\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1899 - accuracy: 0.9210 - val_loss: 0.1911 - val_accuracy: 0.9194\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1898 - accuracy: 0.9203 - val_loss: 0.1940 - val_accuracy: 0.9194\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1897 - accuracy: 0.9205 - val_loss: 0.1970 - val_accuracy: 0.9119\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1895 - accuracy: 0.9190 - val_loss: 0.1913 - val_accuracy: 0.9243\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1889 - accuracy: 0.9209 - val_loss: 0.1893 - val_accuracy: 0.9235\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1891 - accuracy: 0.9210 - val_loss: 0.1886 - val_accuracy: 0.9246\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1888 - accuracy: 0.9198 - val_loss: 0.1900 - val_accuracy: 0.9205\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1884 - accuracy: 0.9213 - val_loss: 0.1917 - val_accuracy: 0.9149\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1878 - accuracy: 0.9198 - val_loss: 0.1886 - val_accuracy: 0.9250\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1873 - accuracy: 0.9212 - val_loss: 0.1883 - val_accuracy: 0.9224\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1875 - accuracy: 0.9210 - val_loss: 0.1878 - val_accuracy: 0.9250\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1872 - accuracy: 0.9209 - val_loss: 0.1883 - val_accuracy: 0.9231\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1867 - accuracy: 0.9211 - val_loss: 0.1896 - val_accuracy: 0.9198\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1867 - accuracy: 0.9213 - val_loss: 0.1878 - val_accuracy: 0.9231\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1866 - accuracy: 0.9214 - val_loss: 0.1871 - val_accuracy: 0.9272\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1862 - accuracy: 0.9217 - val_loss: 0.1872 - val_accuracy: 0.9246\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1859 - accuracy: 0.9222 - val_loss: 0.1869 - val_accuracy: 0.9257\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1860 - accuracy: 0.9223 - val_loss: 0.1888 - val_accuracy: 0.9187\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1858 - accuracy: 0.9217 - val_loss: 0.1862 - val_accuracy: 0.9239\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1856 - accuracy: 0.9216 - val_loss: 0.1865 - val_accuracy: 0.9243\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1859 - accuracy: 0.9223 - val_loss: 0.1873 - val_accuracy: 0.9220\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1852 - accuracy: 0.9217 - val_loss: 0.1854 - val_accuracy: 0.9280\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1859 - accuracy: 0.9220 - val_loss: 0.1872 - val_accuracy: 0.9231\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1844 - accuracy: 0.9226 - val_loss: 0.1867 - val_accuracy: 0.9224\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1845 - accuracy: 0.9218 - val_loss: 0.1861 - val_accuracy: 0.9243\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1852 - accuracy: 0.9215 - val_loss: 0.1896 - val_accuracy: 0.9194\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1851 - accuracy: 0.9225 - val_loss: 0.1875 - val_accuracy: 0.9201\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1847 - accuracy: 0.9226 - val_loss: 0.1845 - val_accuracy: 0.9261\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1846 - accuracy: 0.9222 - val_loss: 0.1841 - val_accuracy: 0.9284\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1848 - accuracy: 0.9226 - val_loss: 0.1855 - val_accuracy: 0.9246\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1843 - accuracy: 0.9226 - val_loss: 0.1872 - val_accuracy: 0.9201\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1839 - accuracy: 0.9231 - val_loss: 0.1852 - val_accuracy: 0.9254\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1839 - accuracy: 0.9233 - val_loss: 0.1887 - val_accuracy: 0.9175\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1840 - accuracy: 0.9223 - val_loss: 0.1833 - val_accuracy: 0.9291\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1848 - accuracy: 0.9218 - val_loss: 0.1841 - val_accuracy: 0.9269\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1835 - accuracy: 0.9229 - val_loss: 0.1862 - val_accuracy: 0.9194\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1838 - accuracy: 0.9227 - val_loss: 0.1864 - val_accuracy: 0.9224\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1839 - accuracy: 0.9222 - val_loss: 0.1858 - val_accuracy: 0.9235\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 0.1835 - accuracy: 0.9234 - val_loss: 0.1840 - val_accuracy: 0.9239\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1832 - accuracy: 0.9224 - val_loss: 0.1833 - val_accuracy: 0.9261\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1829 - accuracy: 0.9225 - val_loss: 0.1879 - val_accuracy: 0.9175\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1827 - accuracy: 0.9231 - val_loss: 0.1832 - val_accuracy: 0.9261\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1824 - accuracy: 0.9236 - val_loss: 0.1873 - val_accuracy: 0.9265\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1832 - accuracy: 0.9232 - val_loss: 0.1836 - val_accuracy: 0.9231\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1830 - accuracy: 0.9231 - val_loss: 0.1852 - val_accuracy: 0.9209\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1828 - accuracy: 0.9228 - val_loss: 0.1864 - val_accuracy: 0.9187\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1832 - accuracy: 0.9228 - val_loss: 0.1858 - val_accuracy: 0.9228\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 3s 17ms/step - loss: 0.1822 - accuracy: 0.9235 - val_loss: 0.1827 - val_accuracy: 0.9265\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1827 - accuracy: 0.9229 - val_loss: 0.1834 - val_accuracy: 0.9239\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1824 - accuracy: 0.9235 - val_loss: 0.1824 - val_accuracy: 0.9276\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1824 - accuracy: 0.9228 - val_loss: 0.1833 - val_accuracy: 0.9243\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1832 - accuracy: 0.9227 - val_loss: 0.1816 - val_accuracy: 0.9284\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1821 - accuracy: 0.9240 - val_loss: 0.1834 - val_accuracy: 0.9254\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1835 - accuracy: 0.9221 - val_loss: 0.1857 - val_accuracy: 0.9235\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1825 - accuracy: 0.9223 - val_loss: 0.1815 - val_accuracy: 0.9291\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1817 - accuracy: 0.9239 - val_loss: 0.1832 - val_accuracy: 0.9246\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1822 - accuracy: 0.9236 - val_loss: 0.1821 - val_accuracy: 0.9299\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1816 - accuracy: 0.9247 - val_loss: 0.1816 - val_accuracy: 0.9261\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1824 - accuracy: 0.9221 - val_loss: 0.1831 - val_accuracy: 0.9257\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1816 - accuracy: 0.9232 - val_loss: 0.1820 - val_accuracy: 0.9284\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1820 - accuracy: 0.9226 - val_loss: 0.1812 - val_accuracy: 0.9276\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1812 - accuracy: 0.9235 - val_loss: 0.1875 - val_accuracy: 0.9168\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1818 - accuracy: 0.9227 - val_loss: 0.1808 - val_accuracy: 0.9291\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1817 - accuracy: 0.9241 - val_loss: 0.1819 - val_accuracy: 0.9250\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1813 - accuracy: 0.9240 - val_loss: 0.1804 - val_accuracy: 0.9291\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1814 - accuracy: 0.9243 - val_loss: 0.1816 - val_accuracy: 0.9261\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1810 - accuracy: 0.9243 - val_loss: 0.1821 - val_accuracy: 0.9257\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1815 - accuracy: 0.9229 - val_loss: 0.1805 - val_accuracy: 0.9306\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1816 - accuracy: 0.9248 - val_loss: 0.1804 - val_accuracy: 0.9295\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1811 - accuracy: 0.9238 - val_loss: 0.1801 - val_accuracy: 0.9306\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1814 - accuracy: 0.9237 - val_loss: 0.1807 - val_accuracy: 0.9295\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1806 - accuracy: 0.9239 - val_loss: 0.1816 - val_accuracy: 0.9254\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1818 - accuracy: 0.9235 - val_loss: 0.1820 - val_accuracy: 0.9287\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1806 - accuracy: 0.9246 - val_loss: 0.1803 - val_accuracy: 0.9269\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1811 - accuracy: 0.9235 - val_loss: 0.1810 - val_accuracy: 0.9284\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.9226 - val_loss: 0.1820 - val_accuracy: 0.9235\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1810 - accuracy: 0.9239 - val_loss: 0.1809 - val_accuracy: 0.9280\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1810 - accuracy: 0.9240 - val_loss: 0.1797 - val_accuracy: 0.9321\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1812 - accuracy: 0.9241 - val_loss: 0.1800 - val_accuracy: 0.9295\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1804 - accuracy: 0.9236 - val_loss: 0.1800 - val_accuracy: 0.9325\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1810 - accuracy: 0.9251 - val_loss: 0.1817 - val_accuracy: 0.9257\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1814 - accuracy: 0.9233 - val_loss: 0.1801 - val_accuracy: 0.9299\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1808 - accuracy: 0.9243 - val_loss: 0.1810 - val_accuracy: 0.9280\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1803 - accuracy: 0.9240 - val_loss: 0.1816 - val_accuracy: 0.9280\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1803 - accuracy: 0.9248 - val_loss: 0.1808 - val_accuracy: 0.9243\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1798 - accuracy: 0.9257 - val_loss: 0.1836 - val_accuracy: 0.9213\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1810 - accuracy: 0.9243 - val_loss: 0.1827 - val_accuracy: 0.9231\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1803 - accuracy: 0.9247 - val_loss: 0.1806 - val_accuracy: 0.9272\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1809 - accuracy: 0.9238 - val_loss: 0.1818 - val_accuracy: 0.9243\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1801 - accuracy: 0.9243 - val_loss: 0.1840 - val_accuracy: 0.9246\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1799 - accuracy: 0.9238 - val_loss: 0.1790 - val_accuracy: 0.9280\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1805 - accuracy: 0.9243 - val_loss: 0.1788 - val_accuracy: 0.9317\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1799 - accuracy: 0.9237 - val_loss: 0.1799 - val_accuracy: 0.9269\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1799 - accuracy: 0.9248 - val_loss: 0.1799 - val_accuracy: 0.9254\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1800 - accuracy: 0.9242 - val_loss: 0.1789 - val_accuracy: 0.9287\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1800 - accuracy: 0.9260 - val_loss: 0.1846 - val_accuracy: 0.9254\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1801 - accuracy: 0.9240 - val_loss: 0.1826 - val_accuracy: 0.9254\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1799 - accuracy: 0.9243 - val_loss: 0.1822 - val_accuracy: 0.9250\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1799 - accuracy: 0.9240 - val_loss: 0.1793 - val_accuracy: 0.9299\n",
      "413/413 [==============================] - 3s 6ms/step - loss: 0.1851 - accuracy: 0.9236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████                                                   | 4/10 [21:47<33:27, 334.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18505112826824188, 0.9236363768577576]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1174/40000 [00:00<00:03, 11734.36it/s]\u001b[A\n",
      "  6%|████▌                                                                        | 2348/40000 [00:00<00:03, 11625.58it/s]\u001b[A\n",
      "  9%|██████▊                                                                      | 3511/40000 [00:00<00:03, 11605.50it/s]\u001b[A\n",
      " 12%|█████████                                                                    | 4676/40000 [00:00<00:03, 11620.40it/s]\u001b[A\n",
      " 15%|███████████▏                                                                 | 5840/40000 [00:00<00:02, 11624.38it/s]\u001b[A\n",
      " 18%|█████████████▍                                                               | 7003/40000 [00:00<00:02, 11548.53it/s]\u001b[A\n",
      " 20%|███████████████▋                                                             | 8168/40000 [00:00<00:02, 11578.42it/s]\u001b[A\n",
      " 23%|█████████████████▉                                                           | 9333/40000 [00:00<00:02, 11599.86it/s]\u001b[A\n",
      " 26%|███████████████████▉                                                        | 10500/40000 [00:00<00:02, 11621.46it/s]\u001b[A\n",
      " 29%|██████████████████████▏                                                     | 11663/40000 [00:01<00:02, 11535.04it/s]\u001b[A\n",
      " 32%|████████████████████████▎                                                   | 12826/40000 [00:01<00:02, 11561.68it/s]\u001b[A\n",
      " 35%|██████████████████████████▌                                                 | 13990/40000 [00:01<00:02, 11583.96it/s]\u001b[A\n",
      " 38%|████████████████████████████▊                                               | 15151/40000 [00:01<00:02, 11590.59it/s]\u001b[A\n",
      " 41%|██████████████████████████████▉                                             | 16311/40000 [00:01<00:02, 11588.92it/s]\u001b[A\n",
      " 44%|█████████████████████████████████▏                                          | 17470/40000 [00:01<00:01, 11465.11it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▎                                        | 18617/40000 [00:01<00:01, 11426.58it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████▌                                      | 19760/40000 [00:01<00:01, 11375.17it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████▋                                    | 20903/40000 [00:01<00:01, 11391.07it/s]\u001b[A\n",
      " 55%|█████████████████████████████████████████▉                                  | 22062/40000 [00:01<00:01, 11449.39it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████                                | 23208/40000 [00:02<00:01, 11388.02it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████▎                             | 24364/40000 [00:02<00:01, 11437.22it/s]\u001b[A\n",
      " 64%|████████████████████████████████████████████████▍                           | 25508/40000 [00:02<00:01, 11257.72it/s]\u001b[A\n",
      " 67%|██████████████████████████████████████████████████▋                         | 26667/40000 [00:02<00:01, 11355.27it/s]\u001b[A\n",
      " 70%|████████████████████████████████████████████████████▊                       | 27804/40000 [00:02<00:01, 11353.80it/s]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████████▉                     | 28946/40000 [00:02<00:00, 11372.49it/s]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████▏                  | 30104/40000 [00:02<00:00, 11433.29it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████▎                | 31248/40000 [00:02<00:00, 11386.68it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████▌              | 32387/40000 [00:02<00:00, 11358.29it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████▋            | 33534/40000 [00:02<00:00, 11390.76it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████▉          | 34678/40000 [00:03<00:00, 11404.71it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████        | 35838/40000 [00:03<00:00, 11461.41it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████▎     | 36997/40000 [00:03<00:00, 11499.09it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████▌   | 38166/40000 [00:03<00:00, 11554.77it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 11489.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 22.0008 - accuracy: 0.1888 - val_loss: 12.7730 - val_accuracy: 0.3153\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 8.4665 - accuracy: 0.3364 - val_loss: 4.7257 - val_accuracy: 0.3940\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 3s 17ms/step - loss: 2.5104 - accuracy: 0.4400 - val_loss: 1.0968 - val_accuracy: 0.5955\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.7949 - accuracy: 0.7534 - val_loss: 0.5268 - val_accuracy: 0.8373\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.4544 - accuracy: 0.8535 - val_loss: 0.3534 - val_accuracy: 0.8836\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.3305 - accuracy: 0.8834 - val_loss: 0.2773 - val_accuracy: 0.9022\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.2685 - accuracy: 0.9034 - val_loss: 0.2335 - val_accuracy: 0.9209\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.2323 - accuracy: 0.9155 - val_loss: 0.2060 - val_accuracy: 0.9310\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.2082 - accuracy: 0.9227 - val_loss: 0.1867 - val_accuracy: 0.9343\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1907 - accuracy: 0.9290 - val_loss: 0.1726 - val_accuracy: 0.9407\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1781 - accuracy: 0.9339 - val_loss: 0.1622 - val_accuracy: 0.9410\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1676 - accuracy: 0.9371 - val_loss: 0.1557 - val_accuracy: 0.9433\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1601 - accuracy: 0.9400 - val_loss: 0.1481 - val_accuracy: 0.9451\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1527 - accuracy: 0.9431 - val_loss: 0.1401 - val_accuracy: 0.9485\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1471 - accuracy: 0.9447 - val_loss: 0.1350 - val_accuracy: 0.9515\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1424 - accuracy: 0.9469 - val_loss: 0.1321 - val_accuracy: 0.9507\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1390 - accuracy: 0.9478 - val_loss: 0.1284 - val_accuracy: 0.9500\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1353 - accuracy: 0.9491 - val_loss: 0.1244 - val_accuracy: 0.9534\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1319 - accuracy: 0.9501 - val_loss: 0.1219 - val_accuracy: 0.9545\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1302 - accuracy: 0.9512 - val_loss: 0.1186 - val_accuracy: 0.9556\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1269 - accuracy: 0.9522 - val_loss: 0.1171 - val_accuracy: 0.9552\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1243 - accuracy: 0.9528 - val_loss: 0.1140 - val_accuracy: 0.9586\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1223 - accuracy: 0.9530 - val_loss: 0.1122 - val_accuracy: 0.9582\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1204 - accuracy: 0.9541 - val_loss: 0.1120 - val_accuracy: 0.9571\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1179 - accuracy: 0.9548 - val_loss: 0.1073 - val_accuracy: 0.9616\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1167 - accuracy: 0.9553 - val_loss: 0.1062 - val_accuracy: 0.9616\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1148 - accuracy: 0.9562 - val_loss: 0.1055 - val_accuracy: 0.9616\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1138 - accuracy: 0.9565 - val_loss: 0.1045 - val_accuracy: 0.9623\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1127 - accuracy: 0.9567 - val_loss: 0.1077 - val_accuracy: 0.9612\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1110 - accuracy: 0.9570 - val_loss: 0.1026 - val_accuracy: 0.9646\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1105 - accuracy: 0.9569 - val_loss: 0.0998 - val_accuracy: 0.9642\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1100 - accuracy: 0.9570 - val_loss: 0.1022 - val_accuracy: 0.9649\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1080 - accuracy: 0.9585 - val_loss: 0.0993 - val_accuracy: 0.9657\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1068 - accuracy: 0.9580 - val_loss: 0.1086 - val_accuracy: 0.9634\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1067 - accuracy: 0.9593 - val_loss: 0.0960 - val_accuracy: 0.9634\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1052 - accuracy: 0.9581 - val_loss: 0.0991 - val_accuracy: 0.9646\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1040 - accuracy: 0.9600 - val_loss: 0.0962 - val_accuracy: 0.9631\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1036 - accuracy: 0.9593 - val_loss: 0.0945 - val_accuracy: 0.9660\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1025 - accuracy: 0.9593 - val_loss: 0.0926 - val_accuracy: 0.9653\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1021 - accuracy: 0.9603 - val_loss: 0.0934 - val_accuracy: 0.9657\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1019 - accuracy: 0.9608 - val_loss: 0.0922 - val_accuracy: 0.9649\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1014 - accuracy: 0.9606 - val_loss: 0.0929 - val_accuracy: 0.9646\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1010 - accuracy: 0.9606 - val_loss: 0.0907 - val_accuracy: 0.9660\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1005 - accuracy: 0.9607 - val_loss: 0.0912 - val_accuracy: 0.9646\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.0990 - accuracy: 0.9612 - val_loss: 0.0921 - val_accuracy: 0.9668\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0990 - accuracy: 0.9611 - val_loss: 0.0897 - val_accuracy: 0.9649\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0981 - accuracy: 0.9614 - val_loss: 0.0896 - val_accuracy: 0.9660\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0992 - accuracy: 0.9605 - val_loss: 0.0894 - val_accuracy: 0.9642\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0978 - accuracy: 0.9610 - val_loss: 0.0881 - val_accuracy: 0.9664\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0975 - accuracy: 0.9612 - val_loss: 0.0874 - val_accuracy: 0.9657\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0979 - accuracy: 0.9613 - val_loss: 0.0884 - val_accuracy: 0.9653\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0961 - accuracy: 0.9619 - val_loss: 0.0888 - val_accuracy: 0.9664\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.0958 - accuracy: 0.9623 - val_loss: 0.0878 - val_accuracy: 0.9660\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0953 - accuracy: 0.9625 - val_loss: 0.0869 - val_accuracy: 0.9660\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.0959 - accuracy: 0.9618 - val_loss: 0.0867 - val_accuracy: 0.9653\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0952 - accuracy: 0.9625 - val_loss: 0.0863 - val_accuracy: 0.9668\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0943 - accuracy: 0.9631 - val_loss: 0.0928 - val_accuracy: 0.9612\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0937 - accuracy: 0.9625 - val_loss: 0.0866 - val_accuracy: 0.9668\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0943 - accuracy: 0.9621 - val_loss: 0.0879 - val_accuracy: 0.9675\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0942 - accuracy: 0.9626 - val_loss: 0.0859 - val_accuracy: 0.9649\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0932 - accuracy: 0.9627 - val_loss: 0.0853 - val_accuracy: 0.9657\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0930 - accuracy: 0.9626 - val_loss: 0.0856 - val_accuracy: 0.9660\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0937 - accuracy: 0.9624 - val_loss: 0.0839 - val_accuracy: 0.9664\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0921 - accuracy: 0.9635 - val_loss: 0.0836 - val_accuracy: 0.9668\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0923 - accuracy: 0.9624 - val_loss: 0.0865 - val_accuracy: 0.9642\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0923 - accuracy: 0.9621 - val_loss: 0.0841 - val_accuracy: 0.9660\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0914 - accuracy: 0.9631 - val_loss: 0.0860 - val_accuracy: 0.9653\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0917 - accuracy: 0.9631 - val_loss: 0.0840 - val_accuracy: 0.9660\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0918 - accuracy: 0.9629 - val_loss: 0.0830 - val_accuracy: 0.9698\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0917 - accuracy: 0.9634 - val_loss: 0.0823 - val_accuracy: 0.9668\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0904 - accuracy: 0.9636 - val_loss: 0.0820 - val_accuracy: 0.9687\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0916 - accuracy: 0.9634 - val_loss: 0.0852 - val_accuracy: 0.9672\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0909 - accuracy: 0.9635 - val_loss: 0.0851 - val_accuracy: 0.9675\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.0909 - accuracy: 0.9630 - val_loss: 0.0820 - val_accuracy: 0.9683\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0904 - accuracy: 0.9633 - val_loss: 0.0812 - val_accuracy: 0.9675\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0916 - accuracy: 0.9620 - val_loss: 0.0841 - val_accuracy: 0.9646\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0895 - accuracy: 0.9629 - val_loss: 0.0820 - val_accuracy: 0.9679\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.0900 - accuracy: 0.9639 - val_loss: 0.0823 - val_accuracy: 0.9672\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0897 - accuracy: 0.9637 - val_loss: 0.0832 - val_accuracy: 0.9646\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0892 - accuracy: 0.9639 - val_loss: 0.0815 - val_accuracy: 0.9672\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0904 - accuracy: 0.9637 - val_loss: 0.0840 - val_accuracy: 0.9675\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0892 - accuracy: 0.9638 - val_loss: 0.0805 - val_accuracy: 0.9683\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0894 - accuracy: 0.9637 - val_loss: 0.0814 - val_accuracy: 0.9675\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0885 - accuracy: 0.9646 - val_loss: 0.0804 - val_accuracy: 0.9668\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.0890 - accuracy: 0.9632 - val_loss: 0.0808 - val_accuracy: 0.9668\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0893 - accuracy: 0.9641 - val_loss: 0.0812 - val_accuracy: 0.9638\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0888 - accuracy: 0.9635 - val_loss: 0.0827 - val_accuracy: 0.9664\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0883 - accuracy: 0.9639 - val_loss: 0.0800 - val_accuracy: 0.9694\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0886 - accuracy: 0.9641 - val_loss: 0.0797 - val_accuracy: 0.9679\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0888 - accuracy: 0.9643 - val_loss: 0.0828 - val_accuracy: 0.9683\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0884 - accuracy: 0.9641 - val_loss: 0.0802 - val_accuracy: 0.9657\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0877 - accuracy: 0.9642 - val_loss: 0.0792 - val_accuracy: 0.9683\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0884 - accuracy: 0.9641 - val_loss: 0.0843 - val_accuracy: 0.9675\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0879 - accuracy: 0.9636 - val_loss: 0.0798 - val_accuracy: 0.9705\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0876 - accuracy: 0.9635 - val_loss: 0.0789 - val_accuracy: 0.9668\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0882 - accuracy: 0.9646 - val_loss: 0.0810 - val_accuracy: 0.9687\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0882 - accuracy: 0.9643 - val_loss: 0.0787 - val_accuracy: 0.9690\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0878 - accuracy: 0.9641 - val_loss: 0.0830 - val_accuracy: 0.9683\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0876 - accuracy: 0.9638 - val_loss: 0.0787 - val_accuracy: 0.9694\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0873 - accuracy: 0.9642 - val_loss: 0.0791 - val_accuracy: 0.9694\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0881 - accuracy: 0.9633 - val_loss: 0.0795 - val_accuracy: 0.9642\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0873 - accuracy: 0.9647 - val_loss: 0.0811 - val_accuracy: 0.9672\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0868 - accuracy: 0.9646 - val_loss: 0.0785 - val_accuracy: 0.9694\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0858 - accuracy: 0.9646 - val_loss: 0.0789 - val_accuracy: 0.9701\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0862 - accuracy: 0.9638 - val_loss: 0.0778 - val_accuracy: 0.9690\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0868 - accuracy: 0.9647 - val_loss: 0.0793 - val_accuracy: 0.9683\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0866 - accuracy: 0.9650 - val_loss: 0.0781 - val_accuracy: 0.9687\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0863 - accuracy: 0.9641 - val_loss: 0.0782 - val_accuracy: 0.9672\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0869 - accuracy: 0.9646 - val_loss: 0.0805 - val_accuracy: 0.9657\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0872 - accuracy: 0.9646 - val_loss: 0.0786 - val_accuracy: 0.9653\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0858 - accuracy: 0.9649 - val_loss: 0.0789 - val_accuracy: 0.9701\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0870 - accuracy: 0.9641 - val_loss: 0.0805 - val_accuracy: 0.9638\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.0857 - accuracy: 0.9652 - val_loss: 0.0798 - val_accuracy: 0.9657\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 0.0863 - accuracy: 0.9643 - val_loss: 0.0778 - val_accuracy: 0.9668\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.0861 - accuracy: 0.9647 - val_loss: 0.0774 - val_accuracy: 0.9690\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0859 - accuracy: 0.9649 - val_loss: 0.0840 - val_accuracy: 0.9649\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0863 - accuracy: 0.9643 - val_loss: 0.0773 - val_accuracy: 0.9672\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0858 - accuracy: 0.9643 - val_loss: 0.0776 - val_accuracy: 0.9698\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0856 - accuracy: 0.9647 - val_loss: 0.0779 - val_accuracy: 0.9657\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 3s 17ms/step - loss: 0.0860 - accuracy: 0.9643 - val_loss: 0.0793 - val_accuracy: 0.9653\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0861 - accuracy: 0.9648 - val_loss: 0.0797 - val_accuracy: 0.9646\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.0857 - accuracy: 0.9652 - val_loss: 0.0771 - val_accuracy: 0.9664\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0863 - accuracy: 0.9643 - val_loss: 0.0780 - val_accuracy: 0.9653\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.0853 - accuracy: 0.9652 - val_loss: 0.0783 - val_accuracy: 0.9698\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.0856 - accuracy: 0.9651 - val_loss: 0.0779 - val_accuracy: 0.9672\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.0858 - accuracy: 0.9646 - val_loss: 0.0776 - val_accuracy: 0.9698\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0854 - accuracy: 0.9648 - val_loss: 0.0784 - val_accuracy: 0.9675\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0850 - accuracy: 0.9656 - val_loss: 0.0804 - val_accuracy: 0.9683\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0854 - accuracy: 0.9652 - val_loss: 0.0773 - val_accuracy: 0.9679\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0852 - accuracy: 0.9651 - val_loss: 0.0790 - val_accuracy: 0.9642\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0857 - accuracy: 0.9648 - val_loss: 0.0862 - val_accuracy: 0.9653\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0847 - accuracy: 0.9649 - val_loss: 0.0765 - val_accuracy: 0.9683\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.0864 - accuracy: 0.9645 - val_loss: 0.0768 - val_accuracy: 0.9672\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0853 - accuracy: 0.9651 - val_loss: 0.0766 - val_accuracy: 0.9694\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0847 - accuracy: 0.9646 - val_loss: 0.0775 - val_accuracy: 0.9690\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.0848 - accuracy: 0.9651 - val_loss: 0.0776 - val_accuracy: 0.9653\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0856 - accuracy: 0.9648 - val_loss: 0.0776 - val_accuracy: 0.9668\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0850 - accuracy: 0.9647 - val_loss: 0.0783 - val_accuracy: 0.9690\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0850 - accuracy: 0.9652 - val_loss: 0.0777 - val_accuracy: 0.9701\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0851 - accuracy: 0.9640 - val_loss: 0.0804 - val_accuracy: 0.9660\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0862 - accuracy: 0.9644 - val_loss: 0.0769 - val_accuracy: 0.9660\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.0858 - accuracy: 0.9649 - val_loss: 0.0761 - val_accuracy: 0.9683\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0847 - accuracy: 0.9646 - val_loss: 0.0769 - val_accuracy: 0.9683\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0844 - accuracy: 0.9656 - val_loss: 0.0784 - val_accuracy: 0.9701\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0843 - accuracy: 0.9656 - val_loss: 0.0771 - val_accuracy: 0.9664\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0853 - accuracy: 0.9654 - val_loss: 0.0824 - val_accuracy: 0.9642\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0846 - accuracy: 0.9655 - val_loss: 0.0768 - val_accuracy: 0.9679\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0846 - accuracy: 0.9650 - val_loss: 0.0763 - val_accuracy: 0.9679\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0847 - accuracy: 0.9656 - val_loss: 0.0758 - val_accuracy: 0.9683\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0847 - accuracy: 0.9654 - val_loss: 0.0784 - val_accuracy: 0.9698\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 0.0857 - accuracy: 0.9657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████▌                                          | 5/10 [26:56<27:06, 325.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08572588115930557, 0.965681791305542]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▏                                                                          | 1165/40000 [00:00<00:03, 11641.02it/s]\u001b[A\n",
      "  6%|████▍                                                                        | 2333/40000 [00:00<00:03, 11662.87it/s]\u001b[A\n",
      "  9%|██████▊                                                                      | 3510/40000 [00:00<00:03, 11708.68it/s]\u001b[A\n",
      " 12%|█████████                                                                    | 4684/40000 [00:00<00:03, 11719.70it/s]\u001b[A\n",
      " 15%|███████████▎                                                                 | 5861/40000 [00:00<00:02, 11737.03it/s]\u001b[A\n",
      " 18%|█████████████▌                                                               | 7041/40000 [00:00<00:02, 11756.14it/s]\u001b[A\n",
      " 21%|███████████████▊                                                             | 8220/40000 [00:00<00:02, 11765.21it/s]\u001b[A\n",
      " 23%|██████████████████                                                           | 9397/40000 [00:00<00:02, 11759.20it/s]\u001b[A\n",
      " 26%|████████████████████                                                        | 10574/40000 [00:00<00:02, 11761.78it/s]\u001b[A\n",
      " 29%|██████████████████████▎                                                     | 11752/40000 [00:01<00:02, 11765.97it/s]\u001b[A\n",
      " 32%|████████████████████████▌                                                   | 12929/40000 [00:01<00:02, 11763.64it/s]\u001b[A\n",
      " 35%|██████████████████████████▊                                                 | 14108/40000 [00:01<00:02, 11769.05it/s]\u001b[A\n",
      " 38%|█████████████████████████████                                               | 15287/40000 [00:01<00:02, 11772.49it/s]\u001b[A\n",
      " 41%|███████████████████████████████▎                                            | 16466/40000 [00:01<00:01, 11775.91it/s]\u001b[A\n",
      " 44%|█████████████████████████████████▌                                          | 17644/40000 [00:01<00:01, 11769.90it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▊                                        | 18824/40000 [00:01<00:01, 11777.37it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████                                      | 20005/40000 [00:01<00:01, 11785.43it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▎                                   | 21185/40000 [00:01<00:01, 11787.66it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▍                                 | 22365/40000 [00:01<00:01, 11789.09it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▋                               | 23544/40000 [00:02<00:01, 11663.65it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▉                             | 24721/40000 [00:02<00:01, 11695.02it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████▏                          | 25896/40000 [00:02<00:01, 11710.04it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▍                        | 27074/40000 [00:02<00:01, 11729.46it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████▋                      | 28252/40000 [00:02<00:01, 11743.33it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████▉                    | 29429/40000 [00:02<00:00, 11748.89it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████▏                 | 30608/40000 [00:02<00:00, 11758.88it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████▍               | 31788/40000 [00:02<00:00, 11770.03it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████▋             | 32967/40000 [00:02<00:00, 11774.98it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████▉           | 34145/40000 [00:02<00:00, 11775.77it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████         | 35323/40000 [00:03<00:00, 11622.58it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████▎      | 36503/40000 [00:03<00:00, 11674.34it/s]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████▌    | 37682/40000 [00:03<00:00, 11705.98it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 11728.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 12.5554 - accuracy: 0.2893 - val_loss: 5.5306 - val_accuracy: 0.4246\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 3.3072 - accuracy: 0.5270 - val_loss: 1.5250 - val_accuracy: 0.6679\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 1.0791 - accuracy: 0.7425 - val_loss: 0.6344 - val_accuracy: 0.8183\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.5447 - accuracy: 0.8357 - val_loss: 0.3846 - val_accuracy: 0.8769\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.3742 - accuracy: 0.8741 - val_loss: 0.2878 - val_accuracy: 0.9037\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.2976 - accuracy: 0.8949 - val_loss: 0.2425 - val_accuracy: 0.9134\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.2563 - accuracy: 0.9059 - val_loss: 0.2162 - val_accuracy: 0.9235\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.2325 - accuracy: 0.9133 - val_loss: 0.1987 - val_accuracy: 0.9325\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.2167 - accuracy: 0.9201 - val_loss: 0.1892 - val_accuracy: 0.9366\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.2056 - accuracy: 0.9228 - val_loss: 0.1821 - val_accuracy: 0.9377\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1973 - accuracy: 0.9267 - val_loss: 0.1754 - val_accuracy: 0.9373\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1909 - accuracy: 0.9281 - val_loss: 0.1705 - val_accuracy: 0.9429\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1852 - accuracy: 0.9299 - val_loss: 0.1677 - val_accuracy: 0.9425\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1800 - accuracy: 0.9318 - val_loss: 0.1623 - val_accuracy: 0.9418\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1754 - accuracy: 0.9325 - val_loss: 0.1599 - val_accuracy: 0.9444\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1714 - accuracy: 0.9339 - val_loss: 0.1565 - val_accuracy: 0.9429\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1675 - accuracy: 0.9346 - val_loss: 0.1534 - val_accuracy: 0.9451\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 0.1635 - accuracy: 0.9372 - val_loss: 0.1512 - val_accuracy: 0.9459\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1607 - accuracy: 0.9370 - val_loss: 0.1481 - val_accuracy: 0.9459\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1573 - accuracy: 0.9377 - val_loss: 0.1487 - val_accuracy: 0.9455\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1545 - accuracy: 0.9384 - val_loss: 0.1433 - val_accuracy: 0.9474\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1518 - accuracy: 0.9399 - val_loss: 0.1408 - val_accuracy: 0.9493\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1494 - accuracy: 0.9409 - val_loss: 0.1430 - val_accuracy: 0.9463\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1473 - accuracy: 0.9412 - val_loss: 0.1381 - val_accuracy: 0.9507\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1456 - accuracy: 0.9410 - val_loss: 0.1372 - val_accuracy: 0.9493\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1427 - accuracy: 0.9415 - val_loss: 0.1349 - val_accuracy: 0.9489\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1409 - accuracy: 0.9425 - val_loss: 0.1340 - val_accuracy: 0.9489\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1389 - accuracy: 0.9431 - val_loss: 0.1318 - val_accuracy: 0.9504\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1374 - accuracy: 0.9433 - val_loss: 0.1304 - val_accuracy: 0.9526\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1358 - accuracy: 0.9446 - val_loss: 0.1295 - val_accuracy: 0.9526\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1350 - accuracy: 0.9446 - val_loss: 0.1279 - val_accuracy: 0.9511\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1333 - accuracy: 0.9444 - val_loss: 0.1268 - val_accuracy: 0.9526\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1319 - accuracy: 0.9448 - val_loss: 0.1295 - val_accuracy: 0.9522\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1304 - accuracy: 0.9456 - val_loss: 0.1237 - val_accuracy: 0.9530\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1291 - accuracy: 0.9454 - val_loss: 0.1243 - val_accuracy: 0.9534\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1279 - accuracy: 0.9470 - val_loss: 0.1233 - val_accuracy: 0.9522\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1269 - accuracy: 0.9478 - val_loss: 0.1219 - val_accuracy: 0.9526\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 3s 18ms/step - loss: 0.1268 - accuracy: 0.9477 - val_loss: 0.1223 - val_accuracy: 0.9563\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1250 - accuracy: 0.9472 - val_loss: 0.1195 - val_accuracy: 0.9563\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1243 - accuracy: 0.9489 - val_loss: 0.1191 - val_accuracy: 0.9526\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1234 - accuracy: 0.9486 - val_loss: 0.1202 - val_accuracy: 0.9552\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 0.1224 - accuracy: 0.9490 - val_loss: 0.1170 - val_accuracy: 0.9563\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1216 - accuracy: 0.9493 - val_loss: 0.1181 - val_accuracy: 0.9534\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1215 - accuracy: 0.9499 - val_loss: 0.1155 - val_accuracy: 0.9578\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1199 - accuracy: 0.9505 - val_loss: 0.1150 - val_accuracy: 0.9578\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1197 - accuracy: 0.9502 - val_loss: 0.1156 - val_accuracy: 0.9541\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1189 - accuracy: 0.9507 - val_loss: 0.1150 - val_accuracy: 0.9545\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1183 - accuracy: 0.9506 - val_loss: 0.1134 - val_accuracy: 0.9582\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1180 - accuracy: 0.9512 - val_loss: 0.1146 - val_accuracy: 0.9552\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1177 - accuracy: 0.9510 - val_loss: 0.1145 - val_accuracy: 0.9545\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1175 - accuracy: 0.9515 - val_loss: 0.1137 - val_accuracy: 0.9571\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1170 - accuracy: 0.9515 - val_loss: 0.1116 - val_accuracy: 0.9590\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1162 - accuracy: 0.9514 - val_loss: 0.1179 - val_accuracy: 0.9519\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1162 - accuracy: 0.9517 - val_loss: 0.1106 - val_accuracy: 0.9582\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1157 - accuracy: 0.9522 - val_loss: 0.1153 - val_accuracy: 0.9567\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1147 - accuracy: 0.9520 - val_loss: 0.1142 - val_accuracy: 0.9541\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1146 - accuracy: 0.9526 - val_loss: 0.1119 - val_accuracy: 0.9578\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1140 - accuracy: 0.9529 - val_loss: 0.1099 - val_accuracy: 0.9590\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1133 - accuracy: 0.9519 - val_loss: 0.1114 - val_accuracy: 0.9556\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1131 - accuracy: 0.9530 - val_loss: 0.1121 - val_accuracy: 0.9530\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1136 - accuracy: 0.9524 - val_loss: 0.1088 - val_accuracy: 0.9586\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1128 - accuracy: 0.9534 - val_loss: 0.1129 - val_accuracy: 0.9556\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1125 - accuracy: 0.9522 - val_loss: 0.1083 - val_accuracy: 0.9597\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1116 - accuracy: 0.9541 - val_loss: 0.1076 - val_accuracy: 0.9586\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1116 - accuracy: 0.9529 - val_loss: 0.1099 - val_accuracy: 0.9560\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1116 - accuracy: 0.9536 - val_loss: 0.1074 - val_accuracy: 0.9563\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1111 - accuracy: 0.9534 - val_loss: 0.1097 - val_accuracy: 0.9556\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1105 - accuracy: 0.9544 - val_loss: 0.1092 - val_accuracy: 0.9578\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9536 - val_loss: 0.1147 - val_accuracy: 0.9549\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1116 - accuracy: 0.9529 - val_loss: 0.1068 - val_accuracy: 0.9590\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1098 - accuracy: 0.9547 - val_loss: 0.1067 - val_accuracy: 0.9608\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1099 - accuracy: 0.9543 - val_loss: 0.1066 - val_accuracy: 0.9578\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1097 - accuracy: 0.9542 - val_loss: 0.1069 - val_accuracy: 0.9571\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1095 - accuracy: 0.9541 - val_loss: 0.1066 - val_accuracy: 0.9604\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1094 - accuracy: 0.9543 - val_loss: 0.1071 - val_accuracy: 0.9597\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1092 - accuracy: 0.9544 - val_loss: 0.1050 - val_accuracy: 0.9619\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1091 - accuracy: 0.9544 - val_loss: 0.1062 - val_accuracy: 0.9563\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1090 - accuracy: 0.9550 - val_loss: 0.1045 - val_accuracy: 0.9608\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1085 - accuracy: 0.9540 - val_loss: 0.1048 - val_accuracy: 0.9601\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1086 - accuracy: 0.9547 - val_loss: 0.1093 - val_accuracy: 0.9567\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1086 - accuracy: 0.9538 - val_loss: 0.1042 - val_accuracy: 0.9597\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1083 - accuracy: 0.9545 - val_loss: 0.1067 - val_accuracy: 0.9586\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 0.1078 - accuracy: 0.9542 - val_loss: 0.1058 - val_accuracy: 0.9590\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1080 - accuracy: 0.9543 - val_loss: 0.1054 - val_accuracy: 0.9590\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1083 - accuracy: 0.9549 - val_loss: 0.1081 - val_accuracy: 0.9560\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1079 - accuracy: 0.9551 - val_loss: 0.1059 - val_accuracy: 0.9586\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1075 - accuracy: 0.9546 - val_loss: 0.1059 - val_accuracy: 0.9567\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1072 - accuracy: 0.9548 - val_loss: 0.1034 - val_accuracy: 0.9593\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1074 - accuracy: 0.9549 - val_loss: 0.1076 - val_accuracy: 0.9571\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1069 - accuracy: 0.9564 - val_loss: 0.1049 - val_accuracy: 0.9575\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1073 - accuracy: 0.9543 - val_loss: 0.1062 - val_accuracy: 0.9567\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1070 - accuracy: 0.9550 - val_loss: 0.1033 - val_accuracy: 0.9604\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1069 - accuracy: 0.9546 - val_loss: 0.1049 - val_accuracy: 0.9619\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1070 - accuracy: 0.9552 - val_loss: 0.1053 - val_accuracy: 0.9582\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1065 - accuracy: 0.9558 - val_loss: 0.1047 - val_accuracy: 0.9597\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1063 - accuracy: 0.9554 - val_loss: 0.1038 - val_accuracy: 0.9586\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 3s 17ms/step - loss: 0.1066 - accuracy: 0.9549 - val_loss: 0.1029 - val_accuracy: 0.9634\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1062 - accuracy: 0.9559 - val_loss: 0.1032 - val_accuracy: 0.9582\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1068 - accuracy: 0.9549 - val_loss: 0.1120 - val_accuracy: 0.9552\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9552 - val_loss: 0.1028 - val_accuracy: 0.9646\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1061 - accuracy: 0.9558 - val_loss: 0.1031 - val_accuracy: 0.9593\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1061 - accuracy: 0.9564 - val_loss: 0.1045 - val_accuracy: 0.9597\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1059 - accuracy: 0.9550 - val_loss: 0.1044 - val_accuracy: 0.9563\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1049 - accuracy: 0.9562 - val_loss: 0.1067 - val_accuracy: 0.9608\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1060 - accuracy: 0.9551 - val_loss: 0.1062 - val_accuracy: 0.9612\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1062 - accuracy: 0.9554 - val_loss: 0.1033 - val_accuracy: 0.9616\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1050 - accuracy: 0.9565 - val_loss: 0.1035 - val_accuracy: 0.9575\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1052 - accuracy: 0.9563 - val_loss: 0.1055 - val_accuracy: 0.9556\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1056 - accuracy: 0.9552 - val_loss: 0.1018 - val_accuracy: 0.9590\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.1054 - accuracy: 0.9556 - val_loss: 0.1047 - val_accuracy: 0.9563\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1052 - accuracy: 0.9554 - val_loss: 0.1044 - val_accuracy: 0.9563\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1049 - accuracy: 0.9557 - val_loss: 0.1011 - val_accuracy: 0.9638\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1047 - accuracy: 0.9566 - val_loss: 0.1028 - val_accuracy: 0.9575\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1050 - accuracy: 0.9560 - val_loss: 0.1033 - val_accuracy: 0.9593\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1047 - accuracy: 0.9554 - val_loss: 0.1039 - val_accuracy: 0.9586\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1047 - accuracy: 0.9554 - val_loss: 0.1024 - val_accuracy: 0.9590\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1044 - accuracy: 0.9559 - val_loss: 0.1049 - val_accuracy: 0.9563\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1045 - accuracy: 0.9558 - val_loss: 0.1011 - val_accuracy: 0.9627\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1045 - accuracy: 0.9559 - val_loss: 0.1011 - val_accuracy: 0.9634\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1049 - accuracy: 0.9561 - val_loss: 0.1032 - val_accuracy: 0.9590\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1044 - accuracy: 0.9563 - val_loss: 0.1017 - val_accuracy: 0.9601\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9562 - val_loss: 0.1025 - val_accuracy: 0.9571\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1044 - accuracy: 0.9554 - val_loss: 0.1007 - val_accuracy: 0.9601\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1045 - accuracy: 0.9563 - val_loss: 0.1038 - val_accuracy: 0.9575\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1038 - accuracy: 0.9568 - val_loss: 0.1017 - val_accuracy: 0.9586\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1040 - accuracy: 0.9566 - val_loss: 0.1004 - val_accuracy: 0.9634\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1045 - accuracy: 0.9566 - val_loss: 0.1006 - val_accuracy: 0.9601\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1045 - accuracy: 0.9562 - val_loss: 0.1054 - val_accuracy: 0.9567\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1042 - accuracy: 0.9563 - val_loss: 0.1013 - val_accuracy: 0.9631\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1047 - accuracy: 0.9553 - val_loss: 0.1012 - val_accuracy: 0.9627\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1040 - accuracy: 0.9561 - val_loss: 0.1006 - val_accuracy: 0.9631\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1042 - accuracy: 0.9558 - val_loss: 0.1004 - val_accuracy: 0.9623\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.1036 - accuracy: 0.9563 - val_loss: 0.1008 - val_accuracy: 0.9604\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1037 - accuracy: 0.9565 - val_loss: 0.1008 - val_accuracy: 0.9604\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1035 - accuracy: 0.9564 - val_loss: 0.1018 - val_accuracy: 0.9601\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1036 - accuracy: 0.9564 - val_loss: 0.1027 - val_accuracy: 0.9571\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1039 - accuracy: 0.9563 - val_loss: 0.1009 - val_accuracy: 0.9601\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1032 - accuracy: 0.9563 - val_loss: 0.1013 - val_accuracy: 0.9590\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1036 - accuracy: 0.9563 - val_loss: 0.1011 - val_accuracy: 0.9593\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1035 - accuracy: 0.9563 - val_loss: 0.1019 - val_accuracy: 0.9586\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1039 - accuracy: 0.9560 - val_loss: 0.1011 - val_accuracy: 0.9593\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1034 - accuracy: 0.9570 - val_loss: 0.1015 - val_accuracy: 0.9619\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1032 - accuracy: 0.9567 - val_loss: 0.1022 - val_accuracy: 0.9575\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1039 - accuracy: 0.9559 - val_loss: 0.1016 - val_accuracy: 0.9612\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1037 - accuracy: 0.9556 - val_loss: 0.1029 - val_accuracy: 0.9575\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1035 - accuracy: 0.9562 - val_loss: 0.0999 - val_accuracy: 0.9619\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1037 - accuracy: 0.9570 - val_loss: 0.1006 - val_accuracy: 0.9601\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1033 - accuracy: 0.9561 - val_loss: 0.0997 - val_accuracy: 0.9619\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1038 - accuracy: 0.9567 - val_loss: 0.1014 - val_accuracy: 0.9578\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1033 - accuracy: 0.9573 - val_loss: 0.1017 - val_accuracy: 0.9586\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 0.1079 - accuracy: 0.9530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████                                  | 6/10 [32:08<21:24, 321.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10788358002901077, 0.9530302882194519]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/40000 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                          | 1182/40000 [00:00<00:03, 11813.45it/s]\u001b[A\n",
      "  6%|████▌                                                                        | 2364/40000 [00:00<00:03, 11758.53it/s]\u001b[A\n",
      "  9%|██████▊                                                                      | 3540/40000 [00:00<00:03, 11738.29it/s]\u001b[A\n",
      " 12%|█████████                                                                    | 4714/40000 [00:00<00:03, 11734.36it/s]\u001b[A\n",
      " 15%|███████████▎                                                                 | 5888/40000 [00:00<00:02, 11730.21it/s]\u001b[A\n",
      " 18%|█████████████▌                                                               | 7063/40000 [00:00<00:02, 11734.90it/s]\u001b[A\n",
      " 21%|███████████████▊                                                             | 8237/40000 [00:00<00:02, 11725.63it/s]\u001b[A\n",
      " 24%|██████████████████                                                           | 9410/40000 [00:00<00:02, 11724.70it/s]\u001b[A\n",
      " 26%|████████████████████                                                        | 10583/40000 [00:00<00:02, 11724.61it/s]\u001b[A\n",
      " 29%|██████████████████████▎                                                     | 11756/40000 [00:01<00:02, 11722.05it/s]\u001b[A\n",
      " 32%|████████████████████████▌                                                   | 12929/40000 [00:01<00:02, 11591.52it/s]\u001b[A\n",
      " 35%|██████████████████████████▊                                                 | 14105/40000 [00:01<00:02, 11642.13it/s]\u001b[A\n",
      " 38%|█████████████████████████████                                               | 15279/40000 [00:01<00:02, 11669.00it/s]\u001b[A\n",
      " 41%|███████████████████████████████▎                                            | 16452/40000 [00:01<00:02, 11684.95it/s]\u001b[A\n",
      " 44%|█████████████████████████████████▍                                          | 17623/40000 [00:01<00:01, 11691.76it/s]\u001b[A\n",
      " 47%|███████████████████████████████████▋                                        | 18799/40000 [00:01<00:01, 11709.27it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████▉                                      | 19971/40000 [00:01<00:01, 11711.44it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████▏                                   | 21143/40000 [00:01<00:01, 11713.42it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████▍                                 | 22315/40000 [00:01<00:01, 11704.55it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████████▌                               | 23486/40000 [00:02<00:01, 11705.32it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████▊                             | 24657/40000 [00:02<00:01, 11692.25it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████                           | 25830/40000 [00:02<00:01, 11700.86it/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████████▎                        | 27003/40000 [00:02<00:01, 11706.78it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████▌                      | 28178/40000 [00:02<00:01, 11717.96it/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████▊                    | 29354/40000 [00:02<00:00, 11728.47it/s]\u001b[A\n",
      " 76%|██████████████████████████████████████████████████████████                  | 30527/40000 [00:02<00:00, 11726.87it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████▏               | 31702/40000 [00:02<00:00, 11733.21it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████▍             | 32881/40000 [00:02<00:00, 11749.60it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████▋           | 34062/40000 [00:02<00:00, 11765.71it/s]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████▉         | 35241/40000 [00:03<00:00, 11771.07it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████▏      | 36419/40000 [00:03<00:00, 11761.98it/s]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████▍    | 37596/40000 [00:03<00:00, 11735.40it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████████████████████████████████████▋  | 38772/40000 [00:03<00:00, 11742.29it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:03<00:00, 11713.78it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(40000, 16, 256, 1)\n",
      "(40000, 10)\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 24.6173 - accuracy: 0.2673 - val_loss: 8.1958 - val_accuracy: 0.3261\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 3.6889 - accuracy: 0.5055 - val_loss: 1.6376 - val_accuracy: 0.6690\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 1.0474 - accuracy: 0.7752 - val_loss: 0.6544 - val_accuracy: 0.8716\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.4920 - accuracy: 0.8854 - val_loss: 0.3374 - val_accuracy: 0.9108\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.2963 - accuracy: 0.9220 - val_loss: 0.2310 - val_accuracy: 0.9332\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.2367 - accuracy: 0.9382 - val_loss: 0.2067 - val_accuracy: 0.9377\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.2148 - accuracy: 0.9442 - val_loss: 0.1874 - val_accuracy: 0.9489\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.2014 - accuracy: 0.9484 - val_loss: 0.1795 - val_accuracy: 0.9571\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.1906 - accuracy: 0.9504 - val_loss: 0.1702 - val_accuracy: 0.9590\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1811 - accuracy: 0.9525 - val_loss: 0.1611 - val_accuracy: 0.9563\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1725 - accuracy: 0.9535 - val_loss: 0.1569 - val_accuracy: 0.9496\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1645 - accuracy: 0.9554 - val_loss: 0.1466 - val_accuracy: 0.9582\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1567 - accuracy: 0.9575 - val_loss: 0.1409 - val_accuracy: 0.9627\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1493 - accuracy: 0.9584 - val_loss: 0.1351 - val_accuracy: 0.9649\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1431 - accuracy: 0.9597 - val_loss: 0.1310 - val_accuracy: 0.9657\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1368 - accuracy: 0.9609 - val_loss: 0.1245 - val_accuracy: 0.9646\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1310 - accuracy: 0.9631 - val_loss: 0.1223 - val_accuracy: 0.9616\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1260 - accuracy: 0.9643 - val_loss: 0.1167 - val_accuracy: 0.9683\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1215 - accuracy: 0.9657 - val_loss: 0.1120 - val_accuracy: 0.9672\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1176 - accuracy: 0.9672 - val_loss: 0.1095 - val_accuracy: 0.9679\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1141 - accuracy: 0.9673 - val_loss: 0.1072 - val_accuracy: 0.9690\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.1105 - accuracy: 0.9685 - val_loss: 0.1064 - val_accuracy: 0.9694\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 0.1082 - accuracy: 0.9692 - val_loss: 0.1014 - val_accuracy: 0.9701\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.1053 - accuracy: 0.9700 - val_loss: 0.0996 - val_accuracy: 0.9694\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.1026 - accuracy: 0.9711 - val_loss: 0.0973 - val_accuracy: 0.9705\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 3s 15ms/step - loss: 0.1010 - accuracy: 0.9713 - val_loss: 0.1002 - val_accuracy: 0.9694\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0987 - accuracy: 0.9720 - val_loss: 0.0948 - val_accuracy: 0.9705\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0971 - accuracy: 0.9722 - val_loss: 0.0921 - val_accuracy: 0.9720\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0957 - accuracy: 0.9724 - val_loss: 0.0913 - val_accuracy: 0.9728\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0935 - accuracy: 0.9726 - val_loss: 0.0905 - val_accuracy: 0.9705\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0916 - accuracy: 0.9735 - val_loss: 0.0882 - val_accuracy: 0.9724\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0920 - accuracy: 0.9729 - val_loss: 0.0872 - val_accuracy: 0.9743\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0900 - accuracy: 0.9733 - val_loss: 0.0869 - val_accuracy: 0.9724\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0888 - accuracy: 0.9736 - val_loss: 0.0852 - val_accuracy: 0.9735\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0886 - accuracy: 0.9740 - val_loss: 0.0833 - val_accuracy: 0.9735\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0870 - accuracy: 0.9741 - val_loss: 0.0853 - val_accuracy: 0.9720\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0857 - accuracy: 0.9747 - val_loss: 0.0873 - val_accuracy: 0.9720\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0847 - accuracy: 0.9747 - val_loss: 0.0819 - val_accuracy: 0.9731\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0832 - accuracy: 0.9750 - val_loss: 0.0814 - val_accuracy: 0.9743\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.0829 - accuracy: 0.9748 - val_loss: 0.0827 - val_accuracy: 0.9739\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0822 - accuracy: 0.9751 - val_loss: 0.0794 - val_accuracy: 0.9743\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0817 - accuracy: 0.9755 - val_loss: 0.0791 - val_accuracy: 0.9746\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0808 - accuracy: 0.9747 - val_loss: 0.0774 - val_accuracy: 0.9746\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0805 - accuracy: 0.9757 - val_loss: 0.0776 - val_accuracy: 0.9739\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0801 - accuracy: 0.9756 - val_loss: 0.0824 - val_accuracy: 0.9746\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.0795 - accuracy: 0.9764 - val_loss: 0.0759 - val_accuracy: 0.9757\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0793 - accuracy: 0.9757 - val_loss: 0.0797 - val_accuracy: 0.9739\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0788 - accuracy: 0.9762 - val_loss: 0.0747 - val_accuracy: 0.9757\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.0774 - val_accuracy: 0.9743\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0782 - accuracy: 0.9761 - val_loss: 0.0743 - val_accuracy: 0.9754\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.0772 - accuracy: 0.9765 - val_loss: 0.0757 - val_accuracy: 0.9757\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0771 - accuracy: 0.9765 - val_loss: 0.0759 - val_accuracy: 0.9743\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0770 - accuracy: 0.9757 - val_loss: 0.0806 - val_accuracy: 0.9750\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.0776 - accuracy: 0.9759 - val_loss: 0.0757 - val_accuracy: 0.9746\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0774 - accuracy: 0.9765 - val_loss: 0.0738 - val_accuracy: 0.9750\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0756 - accuracy: 0.9770 - val_loss: 0.0738 - val_accuracy: 0.9739\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0749 - accuracy: 0.9772 - val_loss: 0.0728 - val_accuracy: 0.9746\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0747 - accuracy: 0.9771 - val_loss: 0.0726 - val_accuracy: 0.9750\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.0747 - accuracy: 0.9769 - val_loss: 0.0718 - val_accuracy: 0.9757\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0759 - accuracy: 0.9765 - val_loss: 0.0757 - val_accuracy: 0.9750\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0746 - accuracy: 0.9768 - val_loss: 0.0707 - val_accuracy: 0.9765\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0752 - accuracy: 0.9768 - val_loss: 0.0706 - val_accuracy: 0.9757\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0744 - accuracy: 0.9762 - val_loss: 0.0752 - val_accuracy: 0.9746\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0742 - accuracy: 0.9767 - val_loss: 0.0747 - val_accuracy: 0.9739\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0739 - accuracy: 0.9772 - val_loss: 0.0701 - val_accuracy: 0.9754\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0734 - accuracy: 0.9774 - val_loss: 0.0711 - val_accuracy: 0.9746\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0737 - accuracy: 0.9770 - val_loss: 0.0698 - val_accuracy: 0.9769\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 3s 16ms/step - loss: 0.0728 - accuracy: 0.9771 - val_loss: 0.0724 - val_accuracy: 0.9754\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.0743 - accuracy: 0.9772 - val_loss: 0.0739 - val_accuracy: 0.9757\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.0735 - accuracy: 0.9774 - val_loss: 0.0696 - val_accuracy: 0.9757\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0732 - accuracy: 0.9770 - val_loss: 0.0689 - val_accuracy: 0.9765\n",
      "Epoch 72/150\n",
      " 60/189 [========>.....................] - ETA: 0s - loss: 0.0669 - accuracy: 0.9792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████                                  | 6/10 [35:04<23:23, 350.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m linear\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m4\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer2\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     22\u001b[0m linear\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m \u001b[43mlinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m results \u001b[38;5;241m=\u001b[39m linear\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m~/.conda/envs/blpc3_new/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/blpc3_new/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/blpc3_new/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/blpc3_new/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/blpc3_new/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/blpc3_new/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/blpc3_new/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/blpc3_new/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.conda/envs/blpc3_new/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow      WARNING  Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).cluster_loss_tracker.total\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).cluster_loss_tracker.count\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.89\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.90\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.91\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.92\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.93\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.94\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.95\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.96\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.97\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.98\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.99\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.100\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.101\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.102\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.103\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.104\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.105\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.106\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.107\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.108\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.109\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.110\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.111\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.112\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.113\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.114\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.115\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.116\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.117\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.118\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.119\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.120\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.121\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.122\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.123\n",
      "tensorflow      WARNING  Value in checkpoint could not be found in the restored object: (root).optimizer._variables.124\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "total_scores = []\n",
    "for i in tqdm(range(10)):\n",
    "    idealized_signals, labels = idealized(num = 10_000)\n",
    "    input_data = np.expand_dims(normalize_data(idealized_signals), axis = -1)\n",
    "    print(input_data[0,:,:].max(), input_data[0,:,:].min())\n",
    "    splits = input_data.shape[0]//1_000\n",
    "    X = []\n",
    "    print(input_data.shape)\n",
    "    for i in range(splits):\n",
    "        tensor = tf.convert_to_tensor(input_data[i*1_000:(i+1)*1_000, :,:,:], dtype=tf.float32)\n",
    "        X.append(autoencoder.encoder(tensor))\n",
    "    X = np.vstack(X)\n",
    "    print(X.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "    linear = keras.Sequential(name=\"my_sequential\")\n",
    "    linear.add(layers.Dense(4, activation=\"sigmoid\", name=\"layer2\"))\n",
    "\n",
    "    linear.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    linear.fit(X_train, y_train, epochs=150, batch_size=128, validation_split = 0.1, shuffle=True)\n",
    "    results = linear.evaluate(X_test, y_test)\n",
    "    print(results)\n",
    "    total_scores.append(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6bd8485-e07e-4a7e-adaf-6709461d3e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9686893999576569\n",
      "0.008975483173492603\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(total_scores))\n",
    "print(np.std(total_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
