{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f9dff0-556f-4594-9c52-5a480a1312b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 21:38:30.361986: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from blimpy import Waterfall\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36af4e-2740-4881-bd07-28aa322af0bb",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4af98f-7b2a-4887-9f21-b860af6933df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16, 256, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 256, 16)       160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 128, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 128, 16)      64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 128, 32)       4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 64, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 64, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 8, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 8, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                131104    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " latent (Dense)              (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,012\n",
      "Trainable params: 164,628\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                160       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              135168    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 8, 32)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 16, 32)       9248      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 16, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 32)       9248      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 16, 32, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 64, 32)       9248      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 16, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 16, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 32, 128, 32)      9248      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 128, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 16, 128, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 32, 256, 16)      4624      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 16, 256, 16)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 16, 256, 16)      64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 16, 256, 1)       145       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,177\n",
      "Trainable params: 185,633\n",
      "Non-trainable params: 8,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 4\n",
    "time_samples = 16\n",
    "freq_sample =  256\n",
    "encoder_inputs = keras.Input(shape=(time_samples, freq_sample, 1))\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\", strides=1, padding=\"same\")(encoder_inputs)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(1, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x_shape = x.shape\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "z = layers.Dense(latent_dim, name=\"latent\")(x)\n",
    "encoder = keras.Model(encoder_inputs, z, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(32, activation=\"relu\")(latent_inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(x_shape[1]* x_shape[2]* x_shape[3], activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Reshape((x_shape[1], x_shape[2], x_shape[3]))(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"linear\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0135a7-95a7-4aa7-bb5c-c04048341748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f228f119f60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from AE import AE\n",
    "\n",
    "autoencoder = AE(encoder, decoder)\\\n",
    "autoencoder.load_weights(\"../autoencoder/models/full-weights-\"+'12-15-2022-15-37-53')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7df1c2-3b12-4a78-a30e-f41d3a88c9c9",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6bf3a0-8dca-450a-b838-a7a08f5fc514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt_blpd7/datax/dl/GBT_57511_62599_HIP6344_fine.h5\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data_generator/untouched_list.csv\")\n",
    "directory_list = df['HIP6344-0'].to_list()\n",
    "file = directory_list[0]\n",
    "print(file)\n",
    "\n",
    "data = Waterfall(\"../../../../../../../\"+file, max_load=False).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c40d59f-e62c-4d14-a6e1-ff46f91820a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1, 318230528)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5bab8d3-e7f2-4533-999d-f80fa084c6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1243088/1243088 [01:01<00:00, 20090.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def normalize(data):\n",
    "    epsilon = 0.001\n",
    "    min_val = data.min()\n",
    "    # data = data - min_val + epsilon\n",
    "    # new_data = np.log(data)\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    final_data = (data - min_val) / (max_val - min_val)\n",
    "    return final_data\n",
    "    \n",
    "def normalize_data(data):\n",
    "    new_data = np.zeros((data.shape[-1]//256, 16, 256,1))\n",
    "    for i in tqdm(range(new_data.shape[0])):\n",
    "        new_data[i,:,:, 0] = normalize(data[:,0, i*256:(i+1)*256])\n",
    "    return new_data\n",
    "\n",
    "preprocessed_data = normalize_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f240b2-98b8-4521-b3d5-76a53f73a9da",
   "metadata": {},
   "source": [
    "# Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3de08fe-3b18-4bc0-9e1f-cdb71c8486b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 22:12:06.301630: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20366753792 exceeds 10% of free system memory.\n",
      "2022-12-15 22:12:30.722152: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 18.97GiB (rounded to 20366753792)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-12-15 22:12:30.722713: W tensorflow/core/common_runtime/bfc_allocator.cc:491] *___________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m key_features \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mpredict(preprocessed_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(key_features\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/ml_jax/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/ml_jax/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "key_features = autoencoder.encoder.predict(preprocessed_data, batch_size=32)\n",
    "print(key_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d8616-e5cf-496d-9122-7329741691ce",
   "metadata": {},
   "source": [
    "# Frequency Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c7920fb-4603-4a63-a479-fc002215e03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1243088\n"
     ]
    }
   ],
   "source": [
    "print(data.shape[-1]//256)\n",
    "data = np.zeros((1243088, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6302ecd-cb2b-4a88-9c70-e91eceab4baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 1009/1009 [00:00<00:00, 5621.32it/s]\n"
     ]
    }
   ],
   "source": [
    "def getFrequencyEncoding(seq_len, d, n=10000):\n",
    "    P = np.zeros((seq_len, d))\n",
    "    for k in range(seq_len):\n",
    "        for i in np.arange(int(d/2)):\n",
    "            denominator = np.power(n, 2*i/d)\n",
    "            P[k, 2*i] = np.sin(k/denominator)\n",
    "            P[k, 2*i+1] = np.cos(k/denominator)\n",
    "    return P\n",
    " \n",
    "F = getFrequencyEncoding(seq_len=1009, d=4, n=100)\n",
    "print(F.shape)\n",
    "\n",
    "for i in tqdm(range(F.shape[0])):\n",
    "    for k in range(112):\n",
    "        data[(i*112)+k,:] += F[i,:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba55bf4c-6db9-4f54-b236-f8ec569aa324",
   "metadata": {},
   "source": [
    "# Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0ea3981-55f9-4b1a-a93c-a1f69296907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999385 0.77822627 0.31071927 ... 0.         0.         0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   600,    977,    223,    286,    663,    537,    914, 109493,\n",
       "       109494, 109495])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0.001\n",
    "SOI_feature = data[0:1, :]\n",
    "SOI_feature = np.swapaxes(SOI_feature, 0, -1)\n",
    "SOI_norm = np.linalg.norm(SOI_feature)\n",
    "data_norm = np.linalg.norm(data, axis = 1) + eps\n",
    "\n",
    "similarity = np.matmul(data, SOI_feature)[:,0]\n",
    "similarity = np.divide(similarity, data_norm)/SOI_norm\n",
    "print(similarity)\n",
    "similarity.argsort()[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
